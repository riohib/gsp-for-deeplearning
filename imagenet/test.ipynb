{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models')\n",
    "\n",
    "\n",
    "from main_model import *\n",
    "import sys \n",
    "sys.path.append('/data/users2/rohib/github/testing')\n",
    "import utils_gsp.sps_tools as sps_tools\n",
    "import utils_gsp.gpu_projection as gsp_gpu\n",
    "\n",
    "import sys\n",
    "sys.path.append('./models')\n",
    "import models.resnet_torch as ResNet\n",
    "\n",
    "\n",
    "from models.finetuners import *\n",
    "from apply_gsp import GSP_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.__dict__['resnet18'](pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    data = '/data/users2/rohib/github/imagenet-data'\n",
    "    arch = 'resnet50'\n",
    "    workers = 4\n",
    "    epochs = 1\n",
    "    start_epoch = 0\n",
    "    batch_size = 16\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay = 1e-4\n",
    "    print_freq = 10\n",
    "    resume = ''\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    world_size = -1\n",
    "    dist_url = 'tcp://224.66.41.62:23456'\n",
    "    dist_backend = 'nccl'\n",
    "    seed = None\n",
    "    gpu = None\n",
    "    multiprocessing_distributed = False\n",
    "\n",
    "args = Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.multiprocessing_distributed\n",
    "gsp_func = gsp_gpu\n",
    "sps = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet50'\n",
      "Created model from PyTorch Models! \n",
      "\n",
      "In final Clause!\n"
     ]
    }
   ],
   "source": [
    "def get_model(args):\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                        'This will turn on the CUDNN deterministic setting, '\n",
    "                        'which can slow down your training considerably! '\n",
    "                        'You may see unexpected behavior when restarting '\n",
    "                        'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                        'disable data parallelism.')\n",
    "\n",
    "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    if args.multiprocessing_distributed:\n",
    "        # Since we have ngpus_per_node processes per node, the total world_size\n",
    "        # needs to be adjusted accordingly\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "        # main_worker process function\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "    else:\n",
    "        # Simply call main_worker function\n",
    "        \n",
    "        model, train_loader, optimizer, criterion = main_worker(args.gpu, ngpus_per_node, args)\n",
    "    return model, train_loader, optimizer, criterion\n",
    "\n",
    "model, train_loader, optimizer, criterion = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning with threshold: 0.0\n"
     ]
    }
   ],
   "source": [
    "model_gsp = GSP_Model(model) # Make a GSP Model\n",
    "\n",
    "sps_tools.prune_with_sps(model_gsp.model.module, sparsity = 0.8)\n",
    "masks_d, masks_l = sps_tools.get_conv_linear_mask(model_gsp.model.module)\n",
    "model_gsp.register_pre_hook_mask(masks_d) # This for forward pre hook mask registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for name, layer in model.named_parameters():\n",
    "    names.append(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(['mask' in x for x, _ in model.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename, epoch, is_best=False):\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, args, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './results/gsp_S80/model_best.pth.tar'\n",
      "=> loaded checkpoint './results/gsp_S80/model_best.pth.tar' (epoch 125)\n",
      "Loaded State Dict: LR: 0.00400 |Best @acc1: 78.52799987792969\n"
     ]
    }
   ],
   "source": [
    "args.resume = './results/gsp_S80/model_best.pth.tar'\n",
    "\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        if args.gpu is None:\n",
    "            checkpoint = torch.load(args.resume)\n",
    "        else:\n",
    "            # Map model to be loaded to specified single gpu.\n",
    "            loc = 'cuda:{}'.format(args.gpu)\n",
    "            checkpoint = torch.load(args.resume, map_location=loc)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        if args.gpu is not None:\n",
    "            # best_acc1 may be from a checkpoint from a different GPU\n",
    "            best_acc1 = best_acc1.to(args.gpu)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        print(f\"=> loaded checkpoint '{args.resume}' (epoch {checkpoint['epoch']})\")\n",
    "        print(f\"Loaded State Dict: LR: {optimizer.param_groups[0]['lr']:.5f} |\" \\\n",
    "                                f\"Best @acc1: {checkpoint['best_acc1']}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()\n",
    "print(args.gpu)\n",
    "# print(ngpus_per_node)\n",
    "print(args.multiprocessing_distributed)\n",
    "print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp_model = GSP_Model(model)\n",
    "gsp_model.curr_epoch = 1\n",
    "gsp_model.curr_iter = 0\n",
    "gsp_model.gsp_int = 2\n",
    "gsp_model.sps = 0.95\n",
    "gsp_model.gsp_training_mode=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" ## Model SPS: {gsp_model.get_model_sps():.3f}\")\n",
    "print(f\" ## Epoch: {gsp_model.curr_epoch} | Start Epoch: {gsp_model.start_gsp_epoch} | iter: {gsp_model.curr_iter} | TMode: {gsp_model.gsp_training_mode} | gsp_int: {gsp_model.gsp_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp_model.apply_gsp_to_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, layer in model.named_modules():\n",
    "#     if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "#         print(f\"name: {name} | shape: {layer.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Current Epoch: {gsp_model.curr_epoch}')\n",
    "print(f'Current iter: {gsp_model.curr_iter}')\n",
    "\n",
    "images, target = next(iter(train_loader))\n",
    "images = images.cuda(args.gpu, non_blocking=True)\n",
    "target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "output = gsp_model.model(images)\n",
    "# gsp_model.apply_gsp()\n",
    "\n",
    "\n",
    "gsp_model.curr_iter += 1\n",
    "\n",
    "print(f\" ## Epoch: {gsp_model.curr_epoch} | Start Epoch: {gsp_model.start_gsp_epoch} | iter: {gsp_model.curr_iter} | TMode: {gsp_model.gsp_training_mode} | gsp_int: {gsp_model.gsp_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sps_tools.get_abs_sps(model)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def prune_with_sps(model, sparsity):\n",
    "    weight_d = {}\n",
    "    shape_list = []\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    weight_tensor = torch.empty(0, device=device)\n",
    "    for name, param in model.named_parameters(): \n",
    "        weight_tensor = torch.cat((weight_tensor, param.data.detach().flatten()))\n",
    "\n",
    "    wpct_val =  len(weight_tensor) * sparsity\n",
    "    sorted_weights, indices = torch.sort(weight_tensor.abs())\n",
    "    threshold = sorted_weights[:math.ceil(wpct_val)+1][-1]\n",
    "\n",
    "    for name, p in model.named_parameters():\n",
    "        tensor = p.data\n",
    "        # print(f'Pruning with threshold : {threshold} for layer {name}')\n",
    "        sparse_w = torch.where(abs(tensor) < threshold, torch.tensor(0.0, device=device), tensor)\n",
    "        p.data = sparse_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_with_sps(gsp_model.model, sparsity = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_linear_mask(model, threshold=1e-8, device=device):\n",
    "    masks = dict()\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            tensor = layer.weight.data\n",
    "            # Force Values smaller than threshold to 0\n",
    "            masked_tensor = torch.where(abs(tensor) < threshold, torch.tensor(0.0, device=device), tensor) \n",
    "            \n",
    "            mask = torch.where(abs(tensor) < threshold, torch.tensor(0.0, device=device), torch.tensor(1.0, device=device))\n",
    "            masks[layer] = mask\n",
    "            layer.weight.data = masked_tensor\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = get_conv_linear_mask(gsp_model.model)\n",
    "# list(masks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pre_hook(module, x):\n",
    "    module.mask.requires_grad_(False)\n",
    "    mask = module.mask\n",
    "    module.weight.data.mul_(mask.to(module.weight.get_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp_model.register_mask(masks)\n",
    "# list(masks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Current Epoch: {gsp_model.curr_epoch}')\n",
    "print(f'Current iter: {gsp_model.curr_iter}')\n",
    "\n",
    "images, target = next(iter(train_loader))\n",
    "images = images.cuda(args.gpu, non_blocking=True)\n",
    "target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "output = gsp_model.model(images)\n",
    "\n",
    "gsp_model.curr_iter += 1\n",
    "\n",
    "# print(sps_tools.get_abs_sps(model)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute output\n",
    "loss = criterion(output, target)\n",
    "\n",
    "\n",
    "# compute gradient and do SGD step\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" SPS Model: {sps_tools.get_abs_sps(model)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a80be99c85f7168e962cfd15ef8eaee54987e9a808a4cfe4ee99a80cb38466"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
