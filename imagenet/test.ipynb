{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import sys\n",
    "sys.path.append('./models')\n",
    "\n",
    "\n",
    "from main_model import *\n",
    "import sys \n",
    "sys.path.append('/data/users2/rohib/github/testing')\n",
    "import utils_gsp.sps_tools as sps_tools\n",
    "import utils_gsp.gpu_projection as gsp_gpu\n",
    "\n",
    "import sys\n",
    "sys.path.append('./models')\n",
    "import models.resnet_torch as ResNet\n",
    "\n",
    "\n",
    "from models.finetuners import *\n",
    "from apply_gsp import GSP_Model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# model = models.__dict__['resnet18'](pretrained=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Args:\n",
    "    data = '/data/users2/rohib/github/imagenet-data'\n",
    "    arch = 'resnet18'\n",
    "    workers = 4\n",
    "    epochs = 1\n",
    "    start_epoch = 0\n",
    "    batch_size = 16\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay = 1e-4\n",
    "    print_freq = 10\n",
    "    resume = ''\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    world_size = -1\n",
    "    dist_url = 'tcp://224.66.41.62:23456'\n",
    "    dist_backend = 'nccl'\n",
    "    seed = None\n",
    "    gpu = None\n",
    "    multiprocessing_distributed = False\n",
    "\n",
    "args = Args"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "args.multiprocessing_distributed\n",
    "gsp_func = gsp_gpu\n",
    "sps = 0.8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_model(args):\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                        'This will turn on the CUDNN deterministic setting, '\n",
    "                        'which can slow down your training considerably! '\n",
    "                        'You may see unexpected behavior when restarting '\n",
    "                        'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                        'disable data parallelism.')\n",
    "\n",
    "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    if args.multiprocessing_distributed:\n",
    "        # Since we have ngpus_per_node processes per node, the total world_size\n",
    "        # needs to be adjusted accordingly\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "        # main_worker process function\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "    else:\n",
    "        # Simply call main_worker function\n",
    "        \n",
    "        model, train_loader, optimizer, criterion = main_worker(args.gpu, ngpus_per_node, args)\n",
    "    return model, train_loader, optimizer, criterion\n",
    "\n",
    "model, train_loader, optimizer, criterion = get_model(args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=> creating model 'resnet18'\n",
      "Created model from PyTorch Models! \n",
      "\n",
      "In final Clause!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "torch.cuda.device_count()\n",
    "print(args.gpu)\n",
    "# print(ngpus_per_node)\n",
    "print(args.multiprocessing_distributed)\n",
    "print(optimizer.param_groups[0]['lr'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "False\n",
      "0.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "gsp_model = GSP_Model(model)\n",
    "gsp_model.curr_epoch = 1\n",
    "gsp_model.curr_iter = 0\n",
    "gsp_model.gsp_int = 2\n",
    "gsp_model.sps = 0.9\n",
    "gsp_model.gsp_training_mode=True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(f\" ## Model SPS: {gsp_model.get_model_sps()[0]:.3f}\")\n",
    "print(f\" ## Epoch: {gsp_model.curr_epoch} | Start Epoch: {gsp_model.start_gsp_epoch} | iter: {gsp_model.curr_iter} | TMode: {gsp_model.gsp_training_mode} | gsp_int: {gsp_model.gsp_int}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " ## Model SPS: 0.041\n",
      " ## Epoch: 1 | Start Epoch: 0 | iter: 0 | TMode: True | gsp_int: 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(f'Current Epoch: {gsp_model.curr_epoch}')\n",
    "print(f'Current iter: {gsp_model.curr_iter}')\n",
    "\n",
    "images, target = next(iter(train_loader))\n",
    "images = images.cuda(args.gpu, non_blocking=True)\n",
    "target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "output = gsp_model.model(images)\n",
    "gsp_model.apply_gsp()\n",
    "\n",
    "\n",
    "gsp_model.curr_iter += 1\n",
    "\n",
    "print(f\" ## Epoch: {gsp_model.curr_epoch} | Start Epoch: {gsp_model.start_gsp_epoch} | iter: {gsp_model.curr_iter} | TMode: {gsp_model.gsp_training_mode} | gsp_int: {gsp_model.gsp_int}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Epoch: 1\n",
      "Current iter: 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/users/rohib/anaconda3/envs/imagenet/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Applying GSP!!\n",
      "Sparsity of layer: module.conv1: 0.8305147886276245\n",
      "Sparsity of layer: module.layer1.0.conv1: 0.8629357218742371\n",
      "Sparsity of layer: module.layer1.0.conv2: 0.8665708899497986\n",
      "Sparsity of layer: module.layer1.1.conv1: 0.8702505826950073\n",
      "Sparsity of layer: module.layer1.1.conv2: 0.8688033223152161\n",
      "Sparsity of layer: module.layer2.0.conv1: 0.8350777626037598\n",
      "Sparsity of layer: module.layer2.0.conv2: 0.8448184132575989\n",
      "Sparsity of layer: module.layer2.0.downsample.0: 0.7633143663406372\n",
      "Sparsity of layer: module.layer2.1.conv1: 0.8452965617179871\n",
      "Sparsity of layer: module.layer2.1.conv2: 0.8443495035171509\n",
      "Sparsity of layer: module.layer3.0.conv1: 0.8247154355049133\n",
      "Sparsity of layer: module.layer3.0.conv2: 0.8320018649101257\n",
      "Sparsity of layer: module.layer3.0.downsample.0: 0.7752252817153931\n",
      "Sparsity of layer: module.layer3.1.conv1: 0.8316736221313477\n",
      "Sparsity of layer: module.layer3.1.conv2: 0.8320711851119995\n",
      "Sparsity of layer: module.layer4.0.conv1: 0.817760705947876\n",
      "Sparsity of layer: module.layer4.0.conv2: 0.8228091597557068\n",
      "Sparsity of layer: module.layer4.0.downsample.0: 0.7826054692268372\n",
      "Sparsity of layer: module.layer4.1.conv1: 0.8227148652076721\n",
      "Sparsity of layer: module.layer4.1.conv2: 0.8228315711021423\n",
      "Sparsity of layer: module.fc: 0.7890475988388062\n",
      "Applied GSP to all Layers!\n",
      " ## Epoch: 1 | Start Epoch: 0 | iter: 1 | TMode: True | gsp_int: 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(sps_tools.get_abs_sps(model)[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "91.70716450780837\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# gsp_in_d = dict()\n",
    "# for name, layer in model.named_modules():\n",
    "#     if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "#         w_shape = layer.weight.shape\n",
    "\n",
    "#         gsp_in_d[name] = layer.weight.data.detach().reshape(layer.weight.shape[0], -1)\n",
    "        \n",
    "#         layer.weight.data = gsp_gpu.groupedsparseproj(gsp_in_d[name].T, sps=0.8).T.reshape(w_shape)\n",
    "#         print(f\"Sparsity of layer: {name}: {sps_tools.sparsity(layer.weight.data)}\")\n",
    "\n",
    "# print(f\"MODEL SPS: {sps_tools.get_abs_sps(model)[0]}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def get_conv_linear_mask(model, threshold=1e-8, device=device):\n",
    "    masks = dict()\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            tensor = layer.weight.data\n",
    "            # Force Values smaller than threshold to 0\n",
    "            masked_tensor = torch.where(abs(tensor) < threshold, torch.tensor(0.0, device=device), tensor) \n",
    "            \n",
    "            mask = torch.where(abs(tensor) < threshold, torch.tensor(0.0, device=device), torch.tensor(1.0, device=device))\n",
    "            masks[layer] = mask\n",
    "            layer.weight.data = masked_tensor\n",
    "    return masks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "masks = get_conv_linear_mask(gsp_model.model)\n",
    "# list(masks.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# def forward_pre_hook(module, x):\n",
    "#     module.mask.requires_grad_(False)\n",
    "#     mask = module.mask\n",
    "#     module.weight.data.mul_(mask.to(module.weight.get_device()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "gsp_model.register_mask(masks)\n",
    "# list(masks.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "        module.mask = nn.Parameter(masks[module]).requires_grad_(False).to(module.weight.get_device())\n",
    "        module.register_forward_pre_hook(forward_pre_hook)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model = gsp_model.model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.nn.parallel.data_parallel.DataParallel"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "#         print(module.mask)\n",
    "#         break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(f'Current Epoch: {gsp_model.curr_epoch}')\n",
    "print(f'Current iter: {gsp_model.curr_iter}')\n",
    "\n",
    "images, target = next(iter(train_loader))\n",
    "images = images.cuda(args.gpu, non_blocking=True)\n",
    "target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "output = gsp_model.model(images)\n",
    "\n",
    "gsp_model.curr_iter += 1\n",
    "\n",
    "# print(sps_tools.get_abs_sps(model)[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Epoch: 1\n",
      "Current iter: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# compute output\n",
    "loss = criterion(output, target)\n",
    "\n",
    "\n",
    "# compute gradient and do SGD step\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(f\" SPS Model: {sps_tools.get_abs_sps(model)[0]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " SPS Model: 91.70768212695901\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45e16559b97ae70bf8d810f94860f8482f9a4cb519f6949425ba42eb446cb034"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}