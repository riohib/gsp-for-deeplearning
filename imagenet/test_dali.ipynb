{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import sys\n",
    "sys.path.append('./models')\n",
    "\n",
    "\n",
    "from main_model import *\n",
    "import sys \n",
    "sys.path.append('/data/users2/rohib/github/testing')\n",
    "import utils_gsp.sps_tools as sps_tools\n",
    "import utils_gsp.gpu_projection as gsp_gpu\n",
    "\n",
    "import sys\n",
    "sys.path.append('./models')\n",
    "# import models.resnet_torch as ResNet\n",
    "import dali_loader.dali_loaders as Dali"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Args:\n",
    "    data = '/data/users2/rohib/github/imagenet-data'\n",
    "    data_backend = 'dali-cpu'\n",
    "    interpolation = 'bilinear'\n",
    "    image_size = 224\n",
    "    mixup = 0.0\n",
    "    num_classes = 1000\n",
    "    augmentation = None\n",
    "    memory_format = \"nchw\"\n",
    "    arch = 'resnet18'\n",
    "    workers = 4\n",
    "    epochs = 1\n",
    "    start_epoch = 0\n",
    "    batch_size = 16\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay = 1e-4\n",
    "    print_freq = 10\n",
    "    resume = ''\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    world_size = -1\n",
    "    dist_url = 'tcp://224.66.41.62:23456'\n",
    "    dist_backend = 'nccl'\n",
    "    seed = None\n",
    "    gpu = None\n",
    "    multiprocessing_distributed = False\n",
    "\n",
    "args = Args"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_loader, train_loader_len, val_loader, val_loader_len = Dali.get_dali_loaders(args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `file_reader` is now deprecated. Use `readers.file` instead.\n",
      "In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.\n",
      "In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/plugin/pytorch.py:166: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.\n",
      "  _DaliBaseIterator.__init__(self,\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `file_reader` is now deprecated. Use `readers.file` instead.\n",
      "In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.\n",
      "In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/plugin/pytorch.py:166: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.\n",
      "  _DaliBaseIterator.__init__(self,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "args.multiprocessing_distributed"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from dali_loader.dataloaders import *\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_model(args):\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                        'This will turn on the CUDNN deterministic setting, '\n",
    "                        'which can slow down your training considerably! '\n",
    "                        'You may see unexpected behavior when restarting '\n",
    "                        'from checkpoints.')\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                        'disable data parallelism.')\n",
    "\n",
    "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    if args.multiprocessing_distributed:\n",
    "        # Since we have ngpus_per_node processes per node, the total world_size\n",
    "        # needs to be adjusted accordingly\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        # Use torch.multiprocessing.spawn to launch distributed processes: the\n",
    "        # main_worker process function\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "    else:\n",
    "        # Simply call main_worker function\n",
    "        model, train_loader = main_worker(args.gpu, ngpus_per_node, args)\n",
    "    return model, train_loader\n",
    "\n",
    "model, train_loader = get_model(args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-7-9c72efcadaf6>:13: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
      "  warnings.warn('You have chosen a specific GPU. This will completely '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Use GPU: 0 for training\n",
      "=> creating model 'resnet18'\n",
      "Created model from local file!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# memory_format = (\n",
    "#     torch.channels_last if args.memory_format == \"nhwc\" else torch.contiguous_format\n",
    "# )\n",
    "# image_size = (\n",
    "#     args.image_size\n",
    "#     if args.image_size is not None\n",
    "#     else model.arch.default_image_size\n",
    "# )\n",
    "# # Create data loaders and optimizers as needed\n",
    "# if args.data_backend == \"pytorch\":\n",
    "#     get_train_loader = get_pytorch_train_loader\n",
    "#     get_val_loader = get_pytorch_val_loader\n",
    "# elif args.data_backend == \"dali-gpu\":\n",
    "#     get_train_loader = get_dali_train_loader(dali_cpu=False)\n",
    "#     get_val_loader = get_dali_val_loader()\n",
    "# elif args.data_backend == \"dali-cpu\":\n",
    "#     get_train_loader = get_dali_train_loader(dali_cpu=True)\n",
    "#     get_val_loader = get_dali_val_loader()\n",
    "# elif args.data_backend == \"syntetic\":\n",
    "#     get_val_loader = get_syntetic_loader\n",
    "#     get_train_loader = get_syntetic_loader\n",
    "# else:\n",
    "#     print(\"Bad databackend picked\")\n",
    "#     exit(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# train_loader, train_loader_len = get_train_loader(\n",
    "#     args.data,\n",
    "#     image_size,\n",
    "#     args.batch_size,\n",
    "#     args.num_classes,\n",
    "#     args.mixup > 0.0,\n",
    "#     interpolation = args.interpolation,\n",
    "#     augmentation=args.augmentation,\n",
    "#     start_epoch=start_epoch,\n",
    "#     workers=args.workers,\n",
    "#     memory_format=memory_format,\n",
    "# )\n",
    "# if args.mixup != 0.0:\n",
    "#     train_loader = MixUpWrapper(args.mixup, train_loader)\n",
    "\n",
    "# val_loader, val_loader_len = get_val_loader(\n",
    "#     args.data,\n",
    "#     image_size,\n",
    "#     args.batch_size,\n",
    "#     args.num_classes,\n",
    "#     False,\n",
    "#     interpolation = args.interpolation,\n",
    "#     workers=args.workers,\n",
    "#     memory_format=memory_format,\n",
    "# )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `file_reader` is now deprecated. Use `readers.file` instead.\n",
      "In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.\n",
      "In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/plugin/pytorch.py:166: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.\n",
      "  _DaliBaseIterator.__init__(self,\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `file_reader` is now deprecated. Use `readers.file` instead.\n",
      "In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.\n",
      "In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`\n",
      "submodule and renamed to follow a common pattern. This is a placeholder operator with identical\n",
      "functionality to allow for backward compatibility.\n",
      "  op_instances.append(_OperatorInstance(input_set, self, **kwargs))\n",
      "/home/users/rohib/anaconda3/envs/nv-imagenet/lib/python3.8/site-packages/nvidia/dali/plugin/pytorch.py:166: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.\n",
      "  _DaliBaseIterator.__init__(self,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import utils_gsp.gpu_projection as gsp_gpu\n",
    "gsp_func = gsp_gpu\n",
    "sps = 0.8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model.curr_iter = 0 \n",
    "model.every_steps = 4\n",
    "\n",
    "def forward_pre_hook_gsp(m, x):\n",
    "    if (self.curr_iter % self.every_steps) == 0:\n",
    "        print(f\"Applying GSP Hook at step: {self.curr_iter} on layer: {m.name} | device: {torch.cuda.current_device()}\")\n",
    "        apply_hook_gsp(m, sps=0.8)\n",
    "    else:\n",
    "        pass\n",
    "        print(f\"Current Step: {self.curr_iter} from device: {torch.cuda.current_device()}\")\n",
    "    # print(f\"Layer: current iter: {curr_iter}\")\n",
    "    self.steps += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# class GSP_Hook():\n",
    "#     def __init__(self, name, every_steps=1):\n",
    "#         self.name = name\n",
    "#         self.every_steps = every_steps\n",
    "#         self.steps = 0\n",
    "    \n",
    "#     # def hook(self, model, input, output):\n",
    "#     #     if (self.steps % self.every_steps) == 0:\n",
    "#     #         self.activation[self.name] = output.detach()\n",
    "#     #     self.steps += 1\n",
    "    \n",
    "#     def forward_pre_hook_gsp(self, m, x):\n",
    "#         if (self.steps % self.every_steps) == 0:\n",
    "#             print(f\"Applying GSP Hook at step: {self.steps} on layer: {m.name} | device: {torch.cuda.current_device()}\")\n",
    "#             apply_hook_gsp(m, sps=0.8)\n",
    "#         else:\n",
    "#             pass\n",
    "#             print(f\"Current Step: {self.steps} from device: {torch.cuda.current_device()}\")\n",
    "#         print(f\"Layer: current iter: {curr_iter}\")\n",
    "#         self.steps += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model.curr_iter = 0\n",
    "\n",
    "sps_tools.get_abs_sps(model)\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        layer.name = name\n",
    "        layer.curr_iter = model.curr_iter\n",
    "        # gsp_hook = GSP_Hook(name, every_steps=4)\n",
    "        # layer.register_forward_pre_hook(gsp_hook.forward_pre_hook_gsp)\n",
    "        layer.register_forward_pre_hook(forward_pre_hook_gsp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def apply_hook_gsp(layer, sps):\n",
    "    count =0\n",
    "    layer_d = {}\n",
    "    gsp_in_d = {}\n",
    "\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        # layer_d[name] = layer\n",
    "        w_shape = layer.weight.shape\n",
    "\n",
    "        if 'downsample' in layer.name:\n",
    "            # print(layer.weight.shape)\n",
    "            dim_1 ,  dim_2 = layer.weight.shape[0], layer.weight.shape[1]\n",
    "            gsp_in_d[name] = layer.weight.detach().reshape(dim_1, -1)\n",
    "        else:\n",
    "            # print(layer.weight.shape[0])\n",
    "            gsp_in_d[name] = layer.weight.detach().reshape(layer.weight.shape[0], -1)\n",
    "        \n",
    "        layer.weight.data = gsp_gpu.groupedsparseproj(gsp_in_d[name].T, sps=0.8).T.reshape(w_shape)\n",
    "    \n",
    "    # del gsp_in_d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model.sps = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model.curr_epoch = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(model.curr_iter)\n",
    "print(model.curr_epoch)\n",
    "\n",
    "images, target = next(iter(train_loader))\n",
    "images = images.cuda(args.gpu, non_blocking=True)\n",
    "target = target.cuda(args.gpu, non_blocking=True)\n",
    "output = model(images)\n",
    "\n",
    "model.curr_iter += 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n",
      "1\n",
      "Current iter: 4\n",
      "Module | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Layer | requires_grad: True\n",
      "Module | requires_grad: True\n",
      "GSP applied to all layers!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "sps_tools.get_layerwise_sps(model)\n",
    "# sps_tools.get_model_layers(model)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'conv1.weight': tensor(0.7871, device='cuda:0'),\n",
       " 'bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer1.0.conv1.weight': tensor(0.7782, device='cuda:0'),\n",
       " 'layer1.0.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer1.0.conv2.weight': tensor(0.7776, device='cuda:0'),\n",
       " 'layer1.0.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'layer1.1.conv1.weight': tensor(0.7780, device='cuda:0'),\n",
       " 'layer1.1.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer1.1.conv2.weight': tensor(0.7783, device='cuda:0'),\n",
       " 'layer1.1.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'layer2.0.conv1.weight': tensor(0.7746, device='cuda:0'),\n",
       " 'layer2.0.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer2.0.conv2.weight': tensor(0.7822, device='cuda:0'),\n",
       " 'layer2.0.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'layer2.0.downsample.0.weight': tensor(0.7049, device='cuda:0'),\n",
       " 'layer2.0.downsample.1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer2.1.conv1.weight': tensor(0.7823, device='cuda:0'),\n",
       " 'layer2.1.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer2.1.conv2.weight': tensor(0.7822, device='cuda:0'),\n",
       " 'layer2.1.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'layer3.0.conv1.weight': tensor(0.7804, device='cuda:0'),\n",
       " 'layer3.0.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer3.0.conv2.weight': tensor(0.7862, device='cuda:0'),\n",
       " 'layer3.0.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'layer3.0.downsample.0.weight': tensor(0.7316, device='cuda:0'),\n",
       " 'layer3.0.downsample.1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer3.1.conv1.weight': tensor(0.7862, device='cuda:0'),\n",
       " 'layer3.1.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer3.1.conv2.weight': tensor(0.7862, device='cuda:0'),\n",
       " 'layer3.1.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'layer4.0.conv1.weight': tensor(0.7853, device='cuda:0'),\n",
       " 'layer4.0.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer4.0.conv2.weight': tensor(0.7897, device='cuda:0'),\n",
       " 'layer4.0.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'layer4.0.downsample.0.weight': tensor(0.7510, device='cuda:0'),\n",
       " 'layer4.0.downsample.1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer4.1.conv1.weight': tensor(0.7897, device='cuda:0'),\n",
       " 'layer4.1.bn1.weight': tensor(0., device='cuda:0'),\n",
       " 'layer4.1.conv2.weight': tensor(0.7897, device='cuda:0'),\n",
       " 'layer4.1.bn2.weight': tensor(0., device='cuda:0'),\n",
       " 'fc.weight': tensor(0.7890, device='cuda:0')}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# # print(model.curr_iter)\n",
    "# # compute output\n",
    "# # output = model(images)\n",
    "# # loss = criterion(output, target)\n",
    "\n",
    "count = 0\n",
    "for name, layer in model.named_modules():\n",
    "    # layer_d[name] = layer\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        # print(name)\n",
    "        count +=1\n",
    "print(count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# compute output\n",
    "output = model(images)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# measure accuracy and record loss\n",
    "acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "losses.update(loss.item(), images.size(0))\n",
    "top1.update(acc1[0], images.size(0))\n",
    "top5.update(acc5[0], images.size(0))\n",
    "\n",
    "# compute gradient and do SGD step\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        count+=1\n",
    "print(count)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sps_tools.get_abs_sps(model)\n",
    "# model, train_loader = get_model(args)\n",
    "model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count =0\n",
    "orig_shape={}\n",
    "layer_d = {}\n",
    "gsp_in_d = {}\n",
    "post_gsp_shp = {}\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        layer_d[name] = layer\n",
    "        orig_shape[name] = layer.weight.shape\n",
    "        w_shape = layer.weight.shape\n",
    "        \n",
    "        if 'downsample' in name:\n",
    "            # print(layer.weight.shape)\n",
    "            dim_1 ,  dim_2 = layer.weight.shape[0], layer.weight.shape[1]\n",
    "            gsp_in_d[name] = layer.weight.detach().reshape(dim_1, -1)\n",
    "        else:\n",
    "            # print(layer.weight.shape[0])\n",
    "            gsp_in_d[name] = layer.weight.detach().reshape(layer.weight.shape[0], -1)\n",
    "        \n",
    "        # print(gsp_in_d[name].shape)\n",
    "        # sparse_l = gsp_gpu.groupedsparseproj(gsp_in_d[name].T, sps=0.8).T\n",
    "        # print(sparse_l.shape)\n",
    "        layer.weight.data = gsp_gpu.groupedsparseproj(gsp_in_d[name].T, sps=0.8).T.reshape(w_shape)\n",
    "        post_gsp_shp[name] = layer.weight.shape\n",
    "        \n",
    "# gsp_shape_d = [x.shape for x in gsp_in_d.values()]\n",
    "# list(gsp_shape_d)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# gsp_shape_d = [x.shape for x in gsp_in_d.values()]\n",
    "# list(post_gsp_shp.values())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(layer_d['module.layer2.0.downsample.0'].weight.shape)\n",
    "print(layer_d['module.layer3.0.downsample.0'].weight.reshape(128, -1).shape)\n",
    "# list(gsp_in_d.keys())\n",
    "# gsp_shape_d = [x.shape for x in gsp_in_d.values()]\n",
    "\n",
    "# list(gsp_shape_d)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(layer.weight.shape)\n",
    "sparse_weight.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"The total model sparsity is: {sps_tools.get_abs_sps(model)[0].item()}\")\n",
    "sps_tools.gsp_conv_linear(model, sps=0.9)\n",
    "print(f\"The total model sparsity after GSP: {sps_tools.get_abs_sps(model)[0].item()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model_test = nn.Sequential(\n",
    "          nn.Conv2d(1,20,5),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(20,64,5),\n",
    "          nn.ReLU()\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for name, param in model_test.named_parameters():\n",
    "    print(name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "2.weight\n",
      "2.bias\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d05cc80b9d10f7e2f9383da42a9a71bdc0f65d5f668fef46c05db91793c7970c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('nv-imagenet': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}