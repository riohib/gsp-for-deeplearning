{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from models.vgg import VGG\n",
    "from models.vgg_sps import SUBVGG\n",
    "from gsp_methods import *\n",
    "import statistics\n",
    "\n",
    "import utils.ipynb_funcs as utilfuncs\n",
    "\n",
    "import math\n",
    "import sys \n",
    "sys.path.append('/data/users2/rohib/github/testing')\n",
    "import utils_gsp.sps_tools as sps_tools\n",
    "import utils_gsp.padded_gsp as gsp_pad\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Args:\n",
    "    lr = 0.1\n",
    "    resume = False\n",
    "    gsp_sps = 0.8\n",
    "    gsp_int = 3\n",
    "    start_epoch = -1\n",
    "\n",
    "args = Args\n",
    "\n",
    "writer = SummaryWriter()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==> Preparing data..\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c9b2e0cac5047ea81cd5956bb95f98f"
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG(depth=16, dataset='cifar10', batchnorm=True)\n",
    "model = VGG('VGG19')\n",
    "model = model.to(device)\n",
    "model.gsp_training_mode = False\n",
    "# model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "names, weight_l, shape_l, weight_d, layers = utilfuncs.get_model_layers(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "bind_new_gsp_methods_to_model(model, args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# chk_name = 'gsp_gates_1'\n",
    "chk_name = 'gate_finetune'\n",
    "args.resume = True\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./checkpoint/{chk_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==> Resuming from checkpoint..\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# import gate_methods\n",
    "# gate_methods.prune_gates(model)\n",
    "utilfuncs.test(model, criterion, testloader, 1, args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 92.72\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(f\"Sparsity of Model: {sps_tools.get_abs_sps(model)[0]:.2f}\")\n",
    "utilfuncs.zero_filters(model)\n",
    "print(f\"Sparsity of Model: {sps_tools.get_abs_sps(model)[0]:.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sparsity of Model: 0.02\n",
      "Sparsity of Model: 86.30\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_sub_network(model):\n",
    "    gate_d = dict()\n",
    "    nz_filters = list()\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            gate_d[name] = layer.gsp_gate.flatten()\n",
    "            nz_filters.append(layer.gsp_gate.flatten().nonzero().numel() )\n",
    "            \n",
    "    pos = [2, 5, 10, 15, 20]\n",
    "    val = 'M'\n",
    "    for elem in pos:\n",
    "        nz_filters.insert(elem, val)\n",
    "    nz_filters.pop()\n",
    "\n",
    "    return nz_filters\n",
    "\n",
    "cfg_layers = create_sub_network(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vgg19 =  [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "print(cfg_layers)\n",
    "print(vgg19)\n",
    "print(len(vgg19))\n",
    "print(len(cfg_layers))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cfg_d = {'SUBVGG19':cfg_layers}\n",
    "sub_model = SUBVGG('SUBVGG19', cfg=cfg_d)\n",
    "sub_model = sub_model.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "names, weight_l, shape_l, weight_d, layers = utilfuncs.get_model_layers(model)\n",
    "_, _, shape_l, _, _ = utilfuncs.get_model_layers(sub_model)\n",
    "# shape_l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "layers[names[0]].bias.nonzero().numel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gates_d = dict()\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        gates_d[name] = layer.gsp_gate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(gates_d[names[0]].dtype)\n",
    "print(weight_d[names[0]].dtype)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def mask_bias(model):\n",
    "    # value_l = list()\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            keep_bias = layer.gsp_gate.flatten().detach().type(torch.bool)\n",
    "            mask_bias = torch.zeros_like(layer.bias.data)\n",
    "            mask_bias[keep_bias] = layer.bias.data[keep_bias]\n",
    "            layer.bias.data = mask_bias\n",
    "            # value_l.append(layer.bias.data.nonzero().numel())\n",
    "mask_bias(model)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nz_filt_ind = list()\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        nz_filt_ind.append(layer.gsp_gate.flatten().nonzero().flatten())\n",
    "\n",
    "in_channel_keep_filters = [torch.tensor([0,1,2], device=nz_filt_ind[0].device)]\n",
    "\n",
    "print(len(nz_filt_ind))\n",
    "nz_filt_ind = in_channel_keep_filters + nz_filt_ind\n",
    "print(len(nz_filt_ind))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "l_weight = weight_d[names[1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nz_filts = l_weight[nz_filt_ind[1], :, :, :]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dense_filters = dict()\n",
    "dense_filter_shp = list()\n",
    "\n",
    "lct = 1 # Layer Count\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        # print(layer.weight.shape)\n",
    "        # print(nz_filt_ind[lct])\n",
    "        # print(nz_filt_ind[lct-1])\n",
    "\n",
    "        l_weight = layer.weight.detach().clone()\n",
    "        temp_filts = layer.weight.detach().clone()[nz_filt_ind[lct], :,:,:]\n",
    "        dense_filters[name] = temp_filts[:, nz_filt_ind[lct-1],:,:]\n",
    "        print(dense_filters[name].shape)\n",
    "        lct += 1 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in sub_model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        layer.weight.data = dense_filters[name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sub_model.classifier.weight.data = model.classifier.weight.data[:, nz_filt_ind[-1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nz_filt_ind[-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sub_model.classifier.weight"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "utilfuncs.test(sub_model, criterion, testloader, 1, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "utilfuncs.train(model, criterion, testloader, 10, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.features[0].bias"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "out1 = model.features[0](images)\n",
    "print(f\"images: {images.shape} || layer1: {model.features[0].weight.shape } || out: {out1.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "out1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.features[0].weight[1,:,:,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dense_filter_shp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ================================================= TEST A MINIBATCH =================================================\n",
    "# model.gsp_training_mode = True\n",
    "# model.start_gsp_epoch = -1\n",
    "# print(f\"gsp start epoch: {model.start_gsp_epoch}\")\n",
    "# print(f\"epoch: {model.curr_epoch} | iter: {model.curr_iter} | gsp_int: {model.gsp_int}\")\n",
    "\n",
    "sub_model.train()\n",
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = sub_model(images)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# model.curr_iter += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "utilfuncs.test(model, criterion, testloader, 1, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# a = torch.ones((2,3,3,3))\n",
    "# a[0,1,:,:] = a[0,1,:,:] * 2\n",
    "# a[0,2,:,:] = a[0,2,:,:] * 3\n",
    "\n",
    "# a[1,0,:,:] = a[1,0,:,:] * 4\n",
    "# a[1,1,:,:] = a[1,1,:,:] * 5\n",
    "# a[1,2,:,:] = a[1,2,:,:] * 6"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# a[:,[1,2],:,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------------------------\n",
    "## Filter Plotting and Pruning\n",
    "-------------------------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ========= Filter Prune after Training ===========\n",
    "\n",
    "def zero_filters(model):\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.weight.data = layer.weight.data * layer.gsp_gate.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gate_methods\n",
    "gate_methods.prune_gates(model, prune_sps=0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.style.use('seaborn')\n",
    "fig, ax = plt.subplots(nrows=4, ncols=5)\n",
    "\n",
    "shapes_l = list()\n",
    "gates_l = list()\n",
    "gates_norm = list()\n",
    "gate_cat = np.array([])\n",
    "gate_cat_torch = torch.tensor([]).cuda()\n",
    "\n",
    "\n",
    "count = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "\n",
    "        # data = np.abs(layer.gsp_gate.detach().clone().flatten().cpu().numpy())\n",
    "        data_torch = torch.abs(layer.gsp_gate.detach().clone().flatten())\n",
    "        # data = data_torch.cpu().numpy()\n",
    "\n",
    "        # shapes_l.append(data_torch.shape[0])\n",
    "        # dmin = data_torch.min(); dmax= data_torch.max()\n",
    "        # data_torch -= dmin\n",
    "        # data_torch /= (dmax - dmin)\n",
    "\n",
    "        data = data_torch.cpu().numpy()\n",
    "        gates_l.append(data)\n",
    "        gates_norm.append(data)\n",
    "\n",
    "        # gate_cat = np.concatenate((gate_cat, data))\n",
    "        # if 'classifier' not in name:\n",
    "        gate_cat_torch = torch.cat( (gate_cat_torch, data_torch) )\n",
    "\n",
    "        x_vals = list(range(data.shape[0]))\n",
    "        ax.reshape(-1)[count].bar( x_vals , data)\n",
    "        ax.reshape(-1)[count].set_title(name)\n",
    "        count += 1\n",
    "\n",
    "fig.set_size_inches(17, 16)\n",
    "fig.suptitle(\"Trained Gate Magnitude (y-axis) corresponding to each filter (x-axis) of VGG-16.\" \\\n",
    "            \"One subplot per layer!\", fontsize=18)\n",
    "plt.savefig('gate_bar.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fig.set_size_inches(18, 16)\n",
    "\n",
    "fig.set_size_inches(17, 16)\n",
    "fig\n",
    "# plt.savefig('gate_bar.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "total = gate_cat_torch.numel()\n",
    "nonzero = torch.nonzero(gate_cat_torch).numel()\n",
    "(total-nonzero)/total"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def keep_topk( gate_cat_torch, prune_sps=0.8):\n",
    "    mask_gate_cat = torch.zeros_like(gate_cat_torch, device=gate_cat_torch.device)\n",
    "    k = math.floor(gate_cat_torch.shape[0] * (1 - prune_sps))\n",
    "    # print(k)\n",
    "    vals, ind = torch.topk(gate_cat_torch, k=k)\n",
    "    # mask_gate_cat[ind] = torch.ones_like(vals, device=vals.device)\n",
    "    mask_gate_cat[ind] = vals\n",
    "    return mask_gate_cat\n",
    "\n",
    "mask_gate_cat = keep_topk(gate_cat_torch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_masked_gate_list(shapes_l, names):\n",
    "    shapes_l = list()\n",
    "    names = list()\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            shapes_l.append(layer.gsp_gate.shape[0])\n",
    "            names.append(name)\n",
    "            \n",
    "    masked_gate_d = dict()\n",
    "    start = 0\n",
    "    for i, shape in enumerate(shapes_l):\n",
    "        masked_gate_d[names[i]] = mask_gate_cat[ start:(start+shape)]\n",
    "        start += shape\n",
    "        # print(start)\n",
    "    return masked_gate_d\n",
    "\n",
    "masked_gate_d = get_masked_gate_list(shapes_l, names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shapes_l\n",
    "# masked_gate_d.keys()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        mask_gates = masked_gate_d[name].reshape(layer.gsp_gate.shape)\n",
    "        \n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            assert (layer.gsp_gate.shape == mask_gates.shape), \"Shape Mismatch in masked gate re-insertion\"\n",
    "            layer.gsp_gate.data = masked_gate_d[name].reshape(layer.gsp_gate.shape)\n",
    "            layer.gsp_gate.requires_grad = False\n",
    "        # if isinstance(layer, nn.Linear):\n",
    "        #     assert (layer.gsp_gate.shape == mask_gates.shape), \"Shape Mismatch in masked gate re-insertion\"\n",
    "        #     layer.gsp_gate.data = torch.ones_like(layer.gsp_gate, device=layer.gsp_gate.device)\n",
    "        #     layer.gsp_gate.requires_grad = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# STANDARAD DEVIATION\n",
    "tensor = np.abs(gates_l[13])\n",
    "threshold = np.std(tensor)*0\n",
    "new_mask = np.where(abs(tensor) < threshold, 0, tensor)\n",
    "x_values = list(range(tensor.shape[0]))\n",
    "print(np.std(tensor))\n",
    "# plt.bar(x_values , new_mask)\n",
    "plt.bar(x_values , tensor)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filters to Keep\n",
    "layer_sps = 0.8\n",
    "num_keep_filter = int(np.ceil(tensor.shape[0] * (1-layer_sps)))\n",
    "print(num_keep_filter)\n",
    "\n",
    "# Get TopK and create vector with topk values and zeros rest\n",
    "ind = np.argpartition(tensor, -num_keep_filter)[-num_keep_filter:]\n",
    "mask_tensor = np.zeros_like(tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask_tensor[ind] = tensor[ind]\n",
    "plt.bar(x_values , mask_tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data.max()\n",
    "# data.min()\n",
    "print(data.shape)\n",
    "bins = np.linspace(-data.max(), data.max(), data.shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.style.use('seaborn')\n",
    "data = np.abs(layers[names[1]].gsp_gate.detach().clone().flatten().cpu().numpy())\n",
    "x_vals = data.shape[0]\n",
    "# sns.barplot(data=data)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.bar(list(range(x_vals)), data)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sps_tools.sparsity(layers[names[9]].gsp_gate.flatten())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gate_d = model.gate_d\n",
    "matrix, ni_list = gsp_pad.pad_input_dict(gate_d)\n",
    "len(gate_d)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cnt = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        trimmed_gate = gate_d[cnt][0:ni_list[cnt]]\n",
    "        layer.gsp_gate.data = trimmed_gate\n",
    "        # print(trimmed_gate.shape)\n",
    "        cnt += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sps_tools.padded_sparsity(matrix, ni_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xp_mat, ni_list = gsp_pad.groupedsparseproj(gate_d, 0.85, precision=1e-6, linrat=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sps_tools.padded_sparsity(xp_mat, ni_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "------------------\n",
    "## Flow Through Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "print(images.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model(images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model.features(images)\n",
    "out1 = model.features[0](images)\n",
    "print(f\"images: {images.shape} || layer1: {model.features[0].weight.shape } || out: {out1.shape}\")\n",
    "\n",
    "out2 = model.features[3](out1)\n",
    "print(f\"inputs: {out1.shape} || layer2: {model.features[3].weight.shape} || out: {out2.shape}\")\n",
    "\n",
    "out3 = model.features[7](out2)\n",
    "print(f\"inputs: {out2.shape} || layer3: {model.features[7].weight.shape} || out: {out3.shape}\")\n",
    "\n",
    "out4 = model.features[10](out3)\n",
    "print(f\"inputs: {out3.shape} || layer4: {model.features[10].weight.shape} || out: {out4.shape}\")\n",
    "\n",
    "out5 = model.features[14](out4)\n",
    "print(f\"inputs: {out4.shape} || layer5: {model.features[14].weight.shape} || out: {out5.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.features[14].weight.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# images, target = next(iter(trainloader))\n",
    "\n",
    "# images = images.cuda('cuda:0', non_blocking=True)\n",
    "# target = target.cuda('cuda:0', non_blocking=True)\n",
    "# print(images.shape)\n",
    "\n",
    "# model(images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.ones(2,2,4,2)\n",
    "print(a)\n",
    "b = torch.ones(2,2,2,1) * 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(a @ b)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------\n",
    "## Setup Training and related functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training\n",
    "def train(epoch, mode=True):\n",
    "    model.gsp_training_mode = mode\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            # print( f\"[{batch_idx}/{len(trainloader)}], Loss: {(train_loss/(batch_idx+1))} | Acc: {100.*correct/total} \" \\\n",
    "            #        f\"grad norm-7: {torch.norm(model.features[7].gsp_gate.grad):.3f} | w_norm: {torch.norm(model.features[7].gsp_gate):.3f}\")\n",
    "            print( f\"[{batch_idx}/{len(trainloader)}], Loss: {(train_loss/(batch_idx+1))} | Acc: {100.*correct/total}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.gsp_training_mode = False\n",
    "def test(model, criterion, testloader, epoch, args):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    model.gsp_training_mode = False\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "test(model, criterion, testloader, 1, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(10):\n",
    "    train(i, mode=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_topk_gates(model, prune_sps=0.8):\n",
    "    pruned_gates = dict()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'gsp_gate' in name:\n",
    "            gate_vec = param.detach()\n",
    "            k = math.floor(gate_vec.shape[0] * (1-prune_sps))\n",
    "            val, ind = torch.topk(gate_vec, k=k)\n",
    "\n",
    "            pruned_gates[name] = torch.zeros_like(gate_vec)\n",
    "            pruned_gates[name][ind] = val\n",
    "\n",
    "            pruned_gates[name] -= pruned_gates[name].min()\n",
    "            pruned_gates[name] /= pruned_gates[name].max()\n",
    "    # [x.shape for x in gates.values()]\n",
    "    return pruned_gates"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_topk_act(model, prune_sps=0.8):\n",
    "    pruned_gates = dict()\n",
    "    pruned_gates_l = list()\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            gate_vec = layer.reshaped_act.detach().flatten()\n",
    "            k = math.floor(gate_vec.shape[0] * (1-prune_sps))\n",
    "            val, ind = torch.topk(gate_vec, k=k)\n",
    "\n",
    "            pruned_gates[name] = torch.zeros_like(gate_vec)\n",
    "            pruned_gates[name][ind] = val\n",
    "\n",
    "            pruned_gates[name] -= pruned_gates[name].min()\n",
    "            pruned_gates[name] /= pruned_gates[name].max()\n",
    "            pruned_gates_l.append(pruned_gates[name])\n",
    "    # [x.shape for x in gates.values()]\n",
    "    return pruned_gates, pruned_gates_l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pruned_gates, pruned_gates_l = get_topk_act(model)\n",
    "pruned_gates = get_topk_gates(model)\n",
    "# [x.shape for x in pruned_gates.values()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_abs_sps(model):\n",
    "    nonzero = total = 0\n",
    "    # print(f\"TYPE: {type(model)}\")\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            # print(name)\n",
    "            tensor = layer.weight.detach().clone()\n",
    "            # nz_count.append(torch.count_nonzero(tensor))\n",
    "            nz_count = torch.count_nonzero(tensor).item()\n",
    "            total_params = tensor.numel()\n",
    "            nonzero += nz_count\n",
    "            total += total_params\n",
    "    \n",
    "    # print(f\"TOTAL: {total}\")\n",
    "    abs_sps = 100 * (total-nonzero) / total\n",
    "\n",
    "    return abs_sps, total, (total-nonzero)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# layer_d = dict()\n",
    "def prune_filters(model):\n",
    "    prod_l = list()\n",
    "    act_mat_d = dict()\n",
    "    prune_sps = 0.80\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            # layer_d[name] = layer\n",
    "            prod = torch.abs(layer.gsp_w @ layer.gsp_gate)\n",
    "            # Normalize\n",
    "            prod -= prod.min()\n",
    "            prod /= prod.max()\n",
    "            # print(f\" gsp_w: {layer.gsp_w.shape} | gate: {layer.gsp_gate.shape} | prod: {prod.shape}\")\n",
    "            prod_l.append(prod)\n",
    "            \n",
    "            # Get TopK and create vector with topk values and zeros rest\n",
    "            act_mat = torch.zeros_like(prod)\n",
    "            k = math.floor(prod.shape[0] * (1 - prune_sps))\n",
    "            vals, ind = torch.topk(prod, k=k)\n",
    "            act_mat[ind] = vals\n",
    "\n",
    "            if isinstance(layer, nn.Conv2d): \n",
    "                reshaped_act = act_mat.reshape(act_mat.shape[0],1,1,1)\n",
    "                layer.weight.data = layer.weight.data * reshaped_act\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                reshaped_act = act_mat.reshape(act_mat.shape[0],1)\n",
    "                layer.weight.data = layer.weight.data * reshaped_act\n",
    "            print(f\"LayerShp: {layer.weight.shape} | prod: {prod.shape} | act_mat: {reshaped_act.shape}\")\n",
    "            # print(f\"Layer Data Shape: {}\")\n",
    "            act_mat_d[name] = act_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_parameters():\n",
    "    print(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "setup_pruning_exp(model, prune_sps = 0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_parameters():\n",
    "    print(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prune_filters(model)\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "masks_d, masks_l = sps_tools.get_conv_linear_mask(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "apply_prune_mask(model, masks_l)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----------\n",
    "-----------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pass Minibatch to test GSP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.gsp_training_mode = True\n",
    "model.start_gsp_epoch = -1\n",
    "\n",
    "print(f\"gsp start epoch: {model.start_gsp_epoch}\")\n",
    "print(f\"epoch: {model.curr_epoch} | iter: {model.curr_iter} | gsp_int: {model.gsp_int}\")\n",
    "\n",
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = model(images)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "model.curr_iter += 1\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(model.features[0].weight.grad)\n",
    "# print(torch.norm(model.features[7].gsp_gate.grad))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(torch.norm(model.features[7].gsp_gate.grad))\n",
    "print(torch.norm(model.features[7].gsp_gate))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sps_tools.get_layerwise_sps(net)\n",
    "# sps_tools.get_abs_sps(net)a\n",
    "\n",
    "images, target = next(iter(trainloader))\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "# writer.add_graph(model, images)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)"
  },
  "interpreter": {
   "hash": "45e16559b97ae70bf8d810f94860f8482f9a4cb519f6949425ba42eb446cb034"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}