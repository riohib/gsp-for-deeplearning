{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from models.vgg import VGG\n",
    "from models.vgg_sps import SUBVGG\n",
    "from gsp_methods import *\n",
    "import statistics\n",
    "\n",
    "import utils.ipynb_funcs as utilfuncs\n",
    "\n",
    "import math\n",
    "import sys \n",
    "sys.path.append('/data/users2/rohib/github/testing')\n",
    "import utils_gsp.sps_tools as sps_tools\n",
    "import utils_gsp.padded_gsp as gsp_pad\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Args:\n",
    "    lr = 0.1\n",
    "    resume = False\n",
    "    gsp_sps = 0.8\n",
    "    gsp_int = 3\n",
    "    start_epoch = -1\n",
    "\n",
    "args = Args\n",
    "\n",
    "writer = SummaryWriter()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG(depth=16, dataset='cifar10', batchnorm=True)\n",
    "model = VGG('VGG19')\n",
    "model = model.to(device)\n",
    "model.gsp_training_mode = False\n",
    "# model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bind_new_gsp_methods_to_model(model, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# chk_name = 'gsp_gates_1'\n",
    "chk_name = 'gate_finetune'\n",
    "args.resume = True\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./checkpoint/{chk_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import gate_methods\n",
    "# gate_methods.prune_gates(model)\n",
    "utilfuncs.test(model, criterion, testloader, 1, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(f\"Sparsity of Model: {sps_tools.get_abs_sps(model)[0]:.2f}\")\n",
    "utilfuncs.zero_filters(model)\n",
    "print(f\"Sparsity of Model: {sps_tools.get_abs_sps(model)[0]:.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sparsity of Model: 0.02\n",
      "Sparsity of Model: 86.30\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "vgg19 =  [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "cfg_layers = utilfuncs.create_sub_network(model)\n",
    "\n",
    "print(cfg_layers)\n",
    "print(vgg19)\n",
    "print(len(vgg19))\n",
    "print(len(cfg_layers))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12, 42, 'M', 65, 59, 'M', 129, 146, 100, 120, 'M', 145, 58, 42, 14, 'M', 37, 18, 94, 12, 'M']\n",
      "[64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
      "21\n",
      "21\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cfg_d = {'SUBVGG19':cfg_layers}\n",
    "sub_model = SUBVGG('SUBVGG19', cfg=cfg_d)\n",
    "sub_model = sub_model.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "names, weight_l, shape_l, weight_d, layers = utilfuncs.get_model_layers(model)\n",
    "_, _, sub_shape_l, _, _ = utilfuncs.get_model_layers(sub_model)\n",
    "\n",
    "gates_d = dict()\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        gates_d[name] = layer.gsp_gate.flatten()\n",
    "\n",
    "nz_filt_ind = utilfuncs.create_nonzero_filter_ind(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nz_prev = gates_d[names[0]].detach().type(torch.bool)\n",
    "nz_f = gates_d[names[1]].detach().type(torch.bool)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "gate = gates_d[names[1]]\n",
    "layer_w = weight_d[names[1]]\n",
    "layer_w.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "nz_filt_ind, zero_filt_ind = utilfuncs.create_nonzero_filter_ind(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "weight_d[names[1]][zero_filt_ind[names[1]],:,:,:].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([22, 64, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# FIX SECOND DIMENSION\n",
    "dense_filters = dict()\n",
    "dense_filter_shp = list()\n",
    "prev_key = 'in_channel'\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        conv_mask = torch.zeros_like(layer.weight.data, device=device)\n",
    "        \n",
    "        temp_dim = conv_mask[nz_filt_ind[name], :,:,:]\n",
    "        temp_dim[:, nz_filt_ind[prev_key],:,:]\n",
    "        \n",
    "\n",
    "        prev_key = name\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        l_weight = layer.weight.detach().clone()\n",
    "        # temp_filts = l_weight[nz_filt_ind[name], :,:,:]\n",
    "        dense_filters[name] = l_weight[:, nz_filt_ind[prev_key]]\n",
    "        prev_key = name"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'nz_filt_ind' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32624/321025610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# print(name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0ml_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtemp_filts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnz_filt_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdense_filters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_filts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz_filt_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nz_filt_ind' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fs = weight_d[names[1]][nz_f,:,:,:]\n",
    "print(fs.shape)\n",
    "fs[1,1,:,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def mask_bias(model):\n",
    "    # Mask out the bias values not corresponding to active gates\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            keep_bias = layer.gsp_gate.flatten().detach().type(torch.bool)\n",
    "            mask_bias = torch.zeros_like(layer.bias.data)\n",
    "            mask_bias[keep_bias] = layer.bias.data[keep_bias]\n",
    "            layer.bias.data = mask_bias\n",
    "            # value_l.append(layer.bias.data.nonzero().numel())\n",
    "mask_bias(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_nonzero_filter_ind(model)\n",
    "    nz_filt_ind = dict()\n",
    "    nz_filt_ind['in_channel'] = torch.tensor([0,1,2], device=next(model.parameters()).device )\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            nz_filt_ind[name] = layer.gsp_gate.flatten().nonzero().flatten()\n",
    "    return nz_filt_ind"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# layer_n = names[1]\n",
    "# l_weight = weight_d[layer_n]\n",
    "# nz_filt_ind[layer_n]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# nz_filts = l_weight[nz_filt_ind[layer_n], :, :, :]\n",
    "# nz_filt_ind.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def accumulate_dense_filters(model):\n",
    "    dense_filters = dict()\n",
    "    dense_filter_shp = list()\n",
    "    prev_key = 'in_channel'\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            # print(name)\n",
    "            l_weight = layer.weight.detach().clone()\n",
    "            temp_filts = l_weight[nz_filt_ind[name], :,:,:]\n",
    "            dense_filters[name] = temp_filts[:, nz_filt_ind[prev_key],:,:]\n",
    "\n",
    "            prev_key = name\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            l_weight = layer.weight.detach().clone()\n",
    "            # temp_filts = l_weight[nz_filt_ind[name], :,:,:]\n",
    "            dense_filters[name] = l_weight[:, nz_filt_ind[prev_key]]\n",
    "            prev_key = name\n",
    "    return dense_filters"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dense_filters.keys()\n",
    "[x.shape for x in dense_filters.values()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in sub_model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        layer.weight.data = dense_filters[name]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nz_weights = list()\n",
    "z_weights = list()\n",
    "for name, layer in sub_model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        nz_weights.append(layer.weight.numel())\n",
    "        z_weights.append(layer.weight.numel())\n",
    "        \n",
    "print(nz_weights)\n",
    "print(sum(nz_weights))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "utilfuncs.zero_filters(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nz_weights_orig = list()\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        nz_weights_orig.append(layer.weight.count_nonzero().item())\n",
    "\n",
    "print(nz_weights_orig)\n",
    "print(sum(nz_weights_orig))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "layer.weight.count_nonzero()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "utilfuncs.test(sub_model, criterion, testloader, 1, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "utilfuncs.train(model, criterion, testloader, 10, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.features[0].bias"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "out1 = model.features[0](images)\n",
    "print(f\"images: {images.shape} || layer1: {model.features[0].weight.shape } || out: {out1.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "out1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.features[0].weight[1,:,:,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dense_filter_shp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ================================================= TEST A MINIBATCH =================================================\n",
    "# model.gsp_training_mode = True\n",
    "# model.start_gsp_epoch = -1\n",
    "# print(f\"gsp start epoch: {model.start_gsp_epoch}\")\n",
    "# print(f\"epoch: {model.curr_epoch} | iter: {model.curr_iter} | gsp_int: {model.gsp_int}\")\n",
    "\n",
    "sub_model.train()\n",
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = sub_model(images)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# model.curr_iter += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "utilfuncs.test(model, criterion, testloader, 1, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# a = torch.ones((3,3,2,2))\n",
    "# a[0,1,:,:] = a[0,1,:,:] * 2\n",
    "# a[0,2,:,:] = a[0,2,:,:] * 3\n",
    "\n",
    "# a[1,0,:,:] = a[1,0,:,:] * 4\n",
    "# a[1,1,:,:] = a[1,1,:,:] * 5\n",
    "# a[1,2,:,:] = a[1,2,:,:] * 6\n",
    "# a"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# # a[[1,2],[0,2],:,:]# Does not work\n",
    "\n",
    "# # But works when done in sequence\n",
    "# b = a[[1,2],:,:,:] \n",
    "# b[:,[0,2],:,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------------------------\n",
    "## Filter Plotting and Pruning\n",
    "-------------------------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ========= Filter Prune after Training ===========\n",
    "\n",
    "def zero_filters(model):\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.weight.data = layer.weight.data * layer.gsp_gate.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gate_methods\n",
    "gate_methods.prune_gates(model, prune_sps=0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.style.use('seaborn')\n",
    "fig, ax = plt.subplots(nrows=4, ncols=5)\n",
    "\n",
    "shapes_l = list()\n",
    "gates_l = list()\n",
    "gates_norm = list()\n",
    "gate_cat = np.array([])\n",
    "gate_cat_torch = torch.tensor([]).cuda()\n",
    "\n",
    "\n",
    "count = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "\n",
    "        # data = np.abs(layer.gsp_gate.detach().clone().flatten().cpu().numpy())\n",
    "        data_torch = torch.abs(layer.gsp_gate.detach().clone().flatten())\n",
    "        # data = data_torch.cpu().numpy()\n",
    "\n",
    "        # shapes_l.append(data_torch.shape[0])\n",
    "        # dmin = data_torch.min(); dmax= data_torch.max()\n",
    "        # data_torch -= dmin\n",
    "        # data_torch /= (dmax - dmin)\n",
    "\n",
    "        data = data_torch.cpu().numpy()\n",
    "        gates_l.append(data)\n",
    "        gates_norm.append(data)\n",
    "\n",
    "        # gate_cat = np.concatenate((gate_cat, data))\n",
    "        # if 'classifier' not in name:\n",
    "        gate_cat_torch = torch.cat( (gate_cat_torch, data_torch) )\n",
    "\n",
    "        x_vals = list(range(data.shape[0]))\n",
    "        ax.reshape(-1)[count].bar( x_vals , data)\n",
    "        ax.reshape(-1)[count].set_title(name)\n",
    "        count += 1\n",
    "\n",
    "fig.set_size_inches(17, 16)\n",
    "fig.suptitle(\"Trained Gate Magnitude (y-axis) corresponding to each filter (x-axis) of VGG-16.\" \\\n",
    "            \"One subplot per layer!\", fontsize=18)\n",
    "plt.savefig('gate_bar.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fig.set_size_inches(18, 16)\n",
    "\n",
    "fig.set_size_inches(17, 16)\n",
    "fig\n",
    "# plt.savefig('gate_bar.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "total = gate_cat_torch.numel()\n",
    "nonzero = torch.nonzero(gate_cat_torch).numel()\n",
    "(total-nonzero)/total"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def keep_topk( gate_cat_torch, prune_sps=0.8):\n",
    "    mask_gate_cat = torch.zeros_like(gate_cat_torch, device=gate_cat_torch.device)\n",
    "    k = math.floor(gate_cat_torch.shape[0] * (1 - prune_sps))\n",
    "    # print(k)\n",
    "    vals, ind = torch.topk(gate_cat_torch, k=k)\n",
    "    # mask_gate_cat[ind] = torch.ones_like(vals, device=vals.device)\n",
    "    mask_gate_cat[ind] = vals\n",
    "    return mask_gate_cat\n",
    "\n",
    "mask_gate_cat = keep_topk(gate_cat_torch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_masked_gate_list(shapes_l, names):\n",
    "    shapes_l = list()\n",
    "    names = list()\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            shapes_l.append(layer.gsp_gate.shape[0])\n",
    "            names.append(name)\n",
    "            \n",
    "    masked_gate_d = dict()\n",
    "    start = 0\n",
    "    for i, shape in enumerate(shapes_l):\n",
    "        masked_gate_d[names[i]] = mask_gate_cat[ start:(start+shape)]\n",
    "        start += shape\n",
    "        # print(start)\n",
    "    return masked_gate_d\n",
    "\n",
    "masked_gate_d = get_masked_gate_list(shapes_l, names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shapes_l\n",
    "# masked_gate_d.keys()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        mask_gates = masked_gate_d[name].reshape(layer.gsp_gate.shape)\n",
    "        \n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            assert (layer.gsp_gate.shape == mask_gates.shape), \"Shape Mismatch in masked gate re-insertion\"\n",
    "            layer.gsp_gate.data = masked_gate_d[name].reshape(layer.gsp_gate.shape)\n",
    "            layer.gsp_gate.requires_grad = False\n",
    "        # if isinstance(layer, nn.Linear):\n",
    "        #     assert (layer.gsp_gate.shape == mask_gates.shape), \"Shape Mismatch in masked gate re-insertion\"\n",
    "        #     layer.gsp_gate.data = torch.ones_like(layer.gsp_gate, device=layer.gsp_gate.device)\n",
    "        #     layer.gsp_gate.requires_grad = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# STANDARAD DEVIATION\n",
    "tensor = np.abs(gates_l[13])\n",
    "threshold = np.std(tensor)*0\n",
    "new_mask = np.where(abs(tensor) < threshold, 0, tensor)\n",
    "x_values = list(range(tensor.shape[0]))\n",
    "print(np.std(tensor))\n",
    "# plt.bar(x_values , new_mask)\n",
    "plt.bar(x_values , tensor)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filters to Keep\n",
    "layer_sps = 0.8\n",
    "num_keep_filter = int(np.ceil(tensor.shape[0] * (1-layer_sps)))\n",
    "print(num_keep_filter)\n",
    "\n",
    "# Get TopK and create vector with topk values and zeros rest\n",
    "ind = np.argpartition(tensor, -num_keep_filter)[-num_keep_filter:]\n",
    "mask_tensor = np.zeros_like(tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mask_tensor[ind] = tensor[ind]\n",
    "plt.bar(x_values , mask_tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data.max()\n",
    "# data.min()\n",
    "print(data.shape)\n",
    "bins = np.linspace(-data.max(), data.max(), data.shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.style.use('seaborn')\n",
    "data = np.abs(layers[names[1]].gsp_gate.detach().clone().flatten().cpu().numpy())\n",
    "x_vals = data.shape[0]\n",
    "# sns.barplot(data=data)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.bar(list(range(x_vals)), data)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sps_tools.sparsity(layers[names[9]].gsp_gate.flatten())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gate_d = model.gate_d\n",
    "matrix, ni_list = gsp_pad.pad_input_dict(gate_d)\n",
    "len(gate_d)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cnt = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        trimmed_gate = gate_d[cnt][0:ni_list[cnt]]\n",
    "        layer.gsp_gate.data = trimmed_gate\n",
    "        # print(trimmed_gate.shape)\n",
    "        cnt += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sps_tools.padded_sparsity(matrix, ni_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xp_mat, ni_list = gsp_pad.groupedsparseproj(gate_d, 0.85, precision=1e-6, linrat=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sps_tools.padded_sparsity(xp_mat, ni_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "------------------\n",
    "## Flow Through Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "print(images.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model(images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fs = weight_d[names[1]][nz_f,:,:,:]\n",
    "print(fs.shape)\n",
    "fs[1,1,:,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gates_d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "act0 = model.features[0](images)\n",
    "print(f\"images: {images.shape} || layer1: {model.features[0].weight.shape } || out: {out1.shape}\")\n",
    "act1 = model.features[3](out1)\n",
    "print(f\"inputs: {out1.shape} || layer2: {model.features[3].weight.shape} || out: {out2.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "act2[3,1,:,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model.features(images)\n",
    "out1 = model.features[0](images)\n",
    "print(f\"images: {images.shape} || layer1: {model.features[0].weight.shape } || out: {out1.shape}\")\n",
    "\n",
    "out2 = model.features[3](out1)\n",
    "print(f\"inputs: {out1.shape} || layer2: {model.features[3].weight.shape} || out: {out2.shape}\")\n",
    "\n",
    "out3 = model.features[7](out2)\n",
    "print(f\"inputs: {out2.shape} || layer3: {model.features[7].weight.shape} || out: {out3.shape}\")\n",
    "\n",
    "out4 = model.features[10](out3)\n",
    "print(f\"inputs: {out3.shape} || layer4: {model.features[10].weight.shape} || out: {out4.shape}\")\n",
    "\n",
    "out5 = model.features[14](out4)\n",
    "print(f\"inputs: {out4.shape} || layer5: {model.features[14].weight.shape} || out: {out5.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.features[14].weight.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.ones(2,2,4,2)\n",
    "print(a)\n",
    "b = torch.ones(2,2,2,1) * 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(a @ b)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------\n",
    "## Setup Training and related functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training\n",
    "def train(epoch, mode=True):\n",
    "    model.gsp_training_mode = mode\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            # print( f\"[{batch_idx}/{len(trainloader)}], Loss: {(train_loss/(batch_idx+1))} | Acc: {100.*correct/total} \" \\\n",
    "            #        f\"grad norm-7: {torch.norm(model.features[7].gsp_gate.grad):.3f} | w_norm: {torch.norm(model.features[7].gsp_gate):.3f}\")\n",
    "            print( f\"[{batch_idx}/{len(trainloader)}], Loss: {(train_loss/(batch_idx+1))} | Acc: {100.*correct/total}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.gsp_training_mode = False\n",
    "def test(model, criterion, testloader, epoch, args):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    model.gsp_training_mode = False\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "test(model, criterion, testloader, 1, args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(10):\n",
    "    train(i, mode=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_topk_gates(model, prune_sps=0.8):\n",
    "    pruned_gates = dict()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'gsp_gate' in name:\n",
    "            gate_vec = param.detach()\n",
    "            k = math.floor(gate_vec.shape[0] * (1-prune_sps))\n",
    "            val, ind = torch.topk(gate_vec, k=k)\n",
    "\n",
    "            pruned_gates[name] = torch.zeros_like(gate_vec)\n",
    "            pruned_gates[name][ind] = val\n",
    "\n",
    "            pruned_gates[name] -= pruned_gates[name].min()\n",
    "            pruned_gates[name] /= pruned_gates[name].max()\n",
    "    # [x.shape for x in gates.values()]\n",
    "    return pruned_gates"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_topk_act(model, prune_sps=0.8):\n",
    "    pruned_gates = dict()\n",
    "    pruned_gates_l = list()\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            gate_vec = layer.reshaped_act.detach().flatten()\n",
    "            k = math.floor(gate_vec.shape[0] * (1-prune_sps))\n",
    "            val, ind = torch.topk(gate_vec, k=k)\n",
    "\n",
    "            pruned_gates[name] = torch.zeros_like(gate_vec)\n",
    "            pruned_gates[name][ind] = val\n",
    "\n",
    "            pruned_gates[name] -= pruned_gates[name].min()\n",
    "            pruned_gates[name] /= pruned_gates[name].max()\n",
    "            pruned_gates_l.append(pruned_gates[name])\n",
    "    # [x.shape for x in gates.values()]\n",
    "    return pruned_gates, pruned_gates_l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pruned_gates, pruned_gates_l = get_topk_act(model)\n",
    "pruned_gates = get_topk_gates(model)\n",
    "# [x.shape for x in pruned_gates.values()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_abs_sps(model):\n",
    "    nonzero = total = 0\n",
    "    # print(f\"TYPE: {type(model)}\")\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            # print(name)\n",
    "            tensor = layer.weight.detach().clone()\n",
    "            # nz_count.append(torch.count_nonzero(tensor))\n",
    "            nz_count = torch.count_nonzero(tensor).item()\n",
    "            total_params = tensor.numel()\n",
    "            nonzero += nz_count\n",
    "            total += total_params\n",
    "    \n",
    "    # print(f\"TOTAL: {total}\")\n",
    "    abs_sps = 100 * (total-nonzero) / total\n",
    "\n",
    "    return abs_sps, total, (total-nonzero)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# layer_d = dict()\n",
    "def prune_filters(model):\n",
    "    prod_l = list()\n",
    "    act_mat_d = dict()\n",
    "    prune_sps = 0.80\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            # layer_d[name] = layer\n",
    "            prod = torch.abs(layer.gsp_w @ layer.gsp_gate)\n",
    "            # Normalize\n",
    "            prod -= prod.min()\n",
    "            prod /= prod.max()\n",
    "            # print(f\" gsp_w: {layer.gsp_w.shape} | gate: {layer.gsp_gate.shape} | prod: {prod.shape}\")\n",
    "            prod_l.append(prod)\n",
    "            \n",
    "            # Get TopK and create vector with topk values and zeros rest\n",
    "            act_mat = torch.zeros_like(prod)\n",
    "            k = math.floor(prod.shape[0] * (1 - prune_sps))\n",
    "            vals, ind = torch.topk(prod, k=k)\n",
    "            act_mat[ind] = vals\n",
    "\n",
    "            if isinstance(layer, nn.Conv2d): \n",
    "                reshaped_act = act_mat.reshape(act_mat.shape[0],1,1,1)\n",
    "                layer.weight.data = layer.weight.data * reshaped_act\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                reshaped_act = act_mat.reshape(act_mat.shape[0],1)\n",
    "                layer.weight.data = layer.weight.data * reshaped_act\n",
    "            print(f\"LayerShp: {layer.weight.shape} | prod: {prod.shape} | act_mat: {reshaped_act.shape}\")\n",
    "            # print(f\"Layer Data Shape: {}\")\n",
    "            act_mat_d[name] = act_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_parameters():\n",
    "    print(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "setup_pruning_exp(model, prune_sps = 0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_parameters():\n",
    "    print(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prune_filters(model)\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "masks_d, masks_l = sps_tools.get_conv_linear_mask(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "apply_prune_mask(model, masks_l)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----------\n",
    "-----------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pass Minibatch to test GSP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.gsp_training_mode = True\n",
    "model.start_gsp_epoch = -1\n",
    "\n",
    "print(f\"gsp start epoch: {model.start_gsp_epoch}\")\n",
    "print(f\"epoch: {model.curr_epoch} | iter: {model.curr_iter} | gsp_int: {model.gsp_int}\")\n",
    "\n",
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = model(images)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "model.curr_iter += 1\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(model.features[0].weight.grad)\n",
    "# print(torch.norm(model.features[7].gsp_gate.grad))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(torch.norm(model.features[7].gsp_gate.grad))\n",
    "print(torch.norm(model.features[7].gsp_gate))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sps_tools.get_layerwise_sps(net)\n",
    "# sps_tools.get_abs_sps(net)a\n",
    "\n",
    "images, target = next(iter(trainloader))\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "# writer.add_graph(model, images)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)"
  },
  "interpreter": {
   "hash": "45e16559b97ae70bf8d810f94860f8482f9a4cb519f6949425ba42eb446cb034"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}