{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models.vgg import VGG\n",
    "from gsp_methods import *\n",
    "\n",
    "import math\n",
    "import sys \n",
    "sys.path.append('/data/users2/rohib/github/testing')\n",
    "import utils_gsp.sps_tools as sps_tools\n",
    "import utils_gsp.padded_gsp as gsp_pad\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Args:\n",
    "    lr = 0.1\n",
    "    resume = False\n",
    "    gsp_sps = 0.8\n",
    "    gsp_int = 3\n",
    "    start_epoch = -1\n",
    "\n",
    "args = Args\n",
    "\n",
    "writer = SummaryWriter()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG(depth=16, dataset='cifar10', batchnorm=True)\n",
    "model = VGG('VGG19')\n",
    "model = model.to(device)\n",
    "model.gsp_training_mode = False\n",
    "# model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_model_layers(model):\n",
    "    names = list()\n",
    "    weight_l = list()\n",
    "    shape_l = list()\n",
    "    weight_d = dict()\n",
    "    layers = dict()\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            weight_d[name] = layer.weight\n",
    "            weight_l.append(layer.weight)\n",
    "            shape_l.append(layer.weight.shape)\n",
    "            layers[name] = layer\n",
    "            names.append(name)\n",
    "            \n",
    "    return names, weight_l, shape_l, weight_d, layers\n",
    "\n",
    "best_acc\n",
    "def gsp_sparse_training(model, args):\n",
    "    # Additional Class Variables for GSP\n",
    "    print(f\"ARGS GSP INT: {args.gsp_int}\")\n",
    "    model.sps = args.gsp_sps\n",
    "    model.curr_iter = 0\n",
    "    model.start_gsp_epoch = -1\n",
    "    model.gsp_int = args.gsp_int\n",
    "    model.logger = None\n",
    "    model.gsp_training_mode = True\n",
    "\n",
    "    if args.resume:\n",
    "        model.curr_epoch = args.start_epoch\n",
    "        print(f\"Current Epoch: {args.start_epoch}\")\n",
    "    else:\n",
    "        model.curr_epoch = 0\n",
    "\n",
    "gsp_sparse_training(model, args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARGS GSP INT: 3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "names, weight_l, shape_l, weight_d, layers = get_model_layers(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "bind_new_gsp_methods_to_model(model, args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n",
      "Binding the NEW forward layers!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "chk_name = 'gsp_block'\n",
    "args.resume = False\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load(f'./checkpoint/{chk_name}.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.gsp_training_mode = True\n",
    "model.start_gsp_epoch = -1\n",
    "\n",
    "print(f\"gsp start epoch: {model.start_gsp_epoch}\")\n",
    "print(f\"epoch: {model.curr_epoch} | iter: {model.curr_iter} | gsp_int: {model.gsp_int}\")\n",
    "\n",
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = model(images)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "model.curr_iter += 1\n",
    "# get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sps_tools.sparsity(layers[names[9]].gsp_gate.flatten())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gate_d = model.gate_d\n",
    "matrix, ni_list = gsp_pad.pad_input_dict(gate_d)\n",
    "len(gate_d)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# gate_d[15][0:ni_list[15]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cnt = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        trimmed_gate = gate_d[cnt][0:ni_list[cnt]]\n",
    "        layer.gsp_gate.data = trimmed_gate\n",
    "        # print(trimmed_gate.shape)\n",
    "        cnt += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "layer.gsp_gate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sps_tools.padded_sparsity(matrix, ni_list))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xp_mat, ni_list = gsp_pad.groupedsparseproj(gate_d, 0.85, precision=1e-6, linrat=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gsp_gate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sps_tools.padded_sparsity(xp_mat, ni_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "------------------\n",
    "## Flow Through Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "print(images.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model.features(images)\n",
    "out1 = model.features[0](images)\n",
    "print(f\"images: {images.shape} || layer1: {model.features[0].weight.shape } || out: {out1.shape}\")\n",
    "\n",
    "out2 = model.features[3](out1)\n",
    "print(f\"inputs: {out1.shape} || layer2: {model.features[3].weight.shape} || out: {out2.shape}\")\n",
    "\n",
    "out3 = model.features[7](out2)\n",
    "print(f\"inputs: {out2.shape} || layer3: {model.features[7].weight.shape} || out: {out3.shape}\")\n",
    "\n",
    "out4 = model.features[10](out3)\n",
    "print(f\"inputs: {out3.shape} || layer4: {model.features[10].weight.shape} || out: {out4.shape}\")\n",
    "\n",
    "out5 = model.features[14](out4)\n",
    "print(f\"inputs: {out4.shape} || layer5: {model.features[14].weight.shape} || out: {out5.shape}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.features[14].weight.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# images, target = next(iter(trainloader))\n",
    "\n",
    "# images = images.cuda('cuda:0', non_blocking=True)\n",
    "# target = target.cuda('cuda:0', non_blocking=True)\n",
    "# print(images.shape)\n",
    "\n",
    "# model(images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.ones(2,2,4,2)\n",
    "print(a)\n",
    "b = torch.ones(2,2,2,1) * 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(a @ b)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------\n",
    "## Setup Training and related functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print( f\"[{batch_idx}/{len(trainloader)}], Loss: {(train_loss/(batch_idx+1))} | Acc: {100.*correct/total} \" \\\n",
    "                   f\"grad norm-7: {torch.norm(model.features[7].gsp_gate.grad):.3f} | w_norm: {torch.norm(model.features[7].gsp_gate):.3f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def test(model, criterion, testloader, epoch, args):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    model.gsp_training_mode = False\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "\n",
    "test(model, criterion, testloader, 1, args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Conv2D forward\n",
      "Modified NEW Linear forward\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/users/rohib/anaconda3/envs/imagenet/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 10.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "train(2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch: 2\n",
      "[0/391], Loss: 2.3510491847991943 | Acc: 7.8125 grad norm-7: 2.944 | w_norm: 1.363\n",
      "[100/391], Loss: 2.3620583515356084 | Acc: 11.997215346534654 grad norm-7: 0.001 | w_norm: 3.145\n",
      "[200/391], Loss: 2.207957200743073 | Acc: 15.127487562189055 grad norm-7: 0.000 | w_norm: 2.991\n",
      "[300/391], Loss: 2.1229694234176333 | Acc: 16.805959302325583 grad norm-7: 0.001 | w_norm: 2.845\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_topk_gates(model, prune_sps=0.8):\n",
    "    pruned_gates = dict()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'gsp_gate' in name:\n",
    "            gate_vec = param.detach()\n",
    "            k = math.floor(gate_vec.shape[0] * (1-prune_sps))\n",
    "            val, ind = torch.topk(gate_vec, k=k)\n",
    "\n",
    "            pruned_gates[name] = torch.zeros_like(gate_vec)\n",
    "            pruned_gates[name][ind] = val\n",
    "\n",
    "            pruned_gates[name] -= pruned_gates[name].min()\n",
    "            pruned_gates[name] /= pruned_gates[name].max()\n",
    "    # [x.shape for x in gates.values()]\n",
    "    return pruned_gates"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_topk_act(model, prune_sps=0.8):\n",
    "    pruned_gates = dict()\n",
    "    pruned_gates_l = list()\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            gate_vec = layer.reshaped_act.detach().flatten()\n",
    "            k = math.floor(gate_vec.shape[0] * (1-prune_sps))\n",
    "            val, ind = torch.topk(gate_vec, k=k)\n",
    "\n",
    "            pruned_gates[name] = torch.zeros_like(gate_vec)\n",
    "            pruned_gates[name][ind] = val\n",
    "\n",
    "            pruned_gates[name] -= pruned_gates[name].min()\n",
    "            pruned_gates[name] /= pruned_gates[name].max()\n",
    "            pruned_gates_l.append(pruned_gates[name])\n",
    "    # [x.shape for x in gates.values()]\n",
    "    return pruned_gates, pruned_gates_l"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pruned_gates, pruned_gates_l = get_topk_act(model)\n",
    "pruned_gates = get_topk_gates(model)\n",
    "# [x.shape for x in pruned_gates.values()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_abs_sps(model):\n",
    "    nonzero = total = 0\n",
    "    # print(f\"TYPE: {type(model)}\")\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            # print(name)\n",
    "            tensor = layer.weight.detach().clone()\n",
    "            # nz_count.append(torch.count_nonzero(tensor))\n",
    "            nz_count = torch.count_nonzero(tensor).item()\n",
    "            total_params = tensor.numel()\n",
    "            nonzero += nz_count\n",
    "            total += total_params\n",
    "    \n",
    "    # print(f\"TOTAL: {total}\")\n",
    "    abs_sps = 100 * (total-nonzero) / total\n",
    "\n",
    "    return abs_sps, total, (total-nonzero)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# layer_d = dict()\n",
    "def prune_filters(model):\n",
    "    prod_l = list()\n",
    "    act_mat_d = dict()\n",
    "    prune_sps = 0.80\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            # layer_d[name] = layer\n",
    "            prod = torch.abs(layer.gsp_w @ layer.gsp_gate)\n",
    "            # Normalize\n",
    "            prod -= prod.min()\n",
    "            prod /= prod.max()\n",
    "            # print(f\" gsp_w: {layer.gsp_w.shape} | gate: {layer.gsp_gate.shape} | prod: {prod.shape}\")\n",
    "            prod_l.append(prod)\n",
    "            \n",
    "            # Get TopK and create vector with topk values and zeros rest\n",
    "            act_mat = torch.zeros_like(prod)\n",
    "            k = math.floor(prod.shape[0] * (1 - prune_sps))\n",
    "            vals, ind = torch.topk(prod, k=k)\n",
    "            act_mat[ind] = vals\n",
    "\n",
    "            if isinstance(layer, nn.Conv2d): \n",
    "                reshaped_act = act_mat.reshape(act_mat.shape[0],1,1,1)\n",
    "                layer.weight.data = layer.weight.data * reshaped_act\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                reshaped_act = act_mat.reshape(act_mat.shape[0],1)\n",
    "                layer.weight.data = layer.weight.data * reshaped_act\n",
    "            print(f\"LayerShp: {layer.weight.shape} | prod: {prod.shape} | act_mat: {reshaped_act.shape}\")\n",
    "            # print(f\"Layer Data Shape: {}\")\n",
    "            act_mat_d[name] = act_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_parameters():\n",
    "    print(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "setup_pruning_exp(model, prune_sps = 0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, layer in model.named_parameters():\n",
    "    print(name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prune_filters(model)\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "masks_d, masks_l = sps_tools.get_conv_linear_mask(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "apply_prune_mask(model, masks_l)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----------\n",
    "-----------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pass Minibatch to test GSP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.gsp_training_mode = True\n",
    "model.start_gsp_epoch = -1\n",
    "\n",
    "print(f\"gsp start epoch: {model.start_gsp_epoch}\")\n",
    "print(f\"epoch: {model.curr_epoch} | iter: {model.curr_iter} | gsp_int: {model.gsp_int}\")\n",
    "\n",
    "images, target = next(iter(trainloader))\n",
    "\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = model(images)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "model.curr_iter += 1\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# print(model.features[0].weight.grad)\n",
    "# print(torch.norm(model.features[7].gsp_gate.grad))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "get_abs_sps(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(torch.norm(model.features[7].gsp_gate.grad))\n",
    "print(torch.norm(model.features[7].gsp_gate))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sps_tools.get_layerwise_sps(net)\n",
    "# sps_tools.get_abs_sps(net)a\n",
    "\n",
    "images, target = next(iter(trainloader))\n",
    "images = images.cuda('cuda:0', non_blocking=True)\n",
    "target = target.cuda('cuda:0', non_blocking=True)\n",
    "\n",
    "# writer.add_graph(model, images)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)"
  },
  "interpreter": {
   "hash": "45e16559b97ae70bf8d810f94860f8482f9a4cb519f6949425ba42eb446cb034"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}