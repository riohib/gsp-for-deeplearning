{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "import networks.load as load\n",
    "\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils_gsp.logger import Logger\n",
    "# from utils_gsp import sps_tools\n",
    "from gsp_model import GSP_Model\n",
    "import utils_gsp.gsp_general as gsp_gen\n",
    "import tools.ipynb_funcs as utilfuncs\n",
    "import tools.visualization as viz\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from main import train, validate, accuracy, save_checkpoint, setup_experiment, gsp_sparse_training, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    arch = 'resnet20'\n",
    "    workers = 4\n",
    "    epochs=160\n",
    "    start_epoch=0\n",
    "    batch_size = 128\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay=1e-4\n",
    "    print_freq = 50\n",
    "    resume = False\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    half = False\n",
    "    exp_name = 'gsp_test'\n",
    "\n",
    "    gpu=None\n",
    "    logdir = '/logdir'\n",
    "    gsp_training = True \n",
    "    gsp_sps = 0.8\n",
    "    proj_filters = False\n",
    "    gsp_int = 150\n",
    "    gsp_start_ep = -1\n",
    "    finetune = False\n",
    "    finetune_sps = 0.9\n",
    "\n",
    "\n",
    "global args, best_acc1\n",
    "args = Args\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.resume = './results/gspS0.9/gsp/model_best.pth.tar' # LOAD GSP MODEL\n",
    "\n",
    "# args.resume = './results/gspS0.80/fine_0.9/model_best.pth.tar'\n",
    "# args.finetune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " input logdir: ./results/gsp_test/logdir \n",
      "\n",
      "\n",
      " RETURNED FILE LOGGER! \n",
      "\n",
      "Files already downloaded and verified\n",
      "The sparsity of the model is: 0.26\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# Setup the experiment\n",
    "flogger = setup_experiment(args)\n",
    "args.logger.log_cmd_arguments(args)\n",
    "\n",
    "# model = torch.nn.DataParallel(resnet.__dict__[args.arch]())\n",
    "# model = VGG('D')\n",
    "model = load.model(args.arch)\n",
    "model.cuda()\n",
    "\n",
    "model_gsp = GSP_Model(model)\n",
    "\n",
    "if args.finetune:\n",
    "    flogger.info(15*\"*\" + \" Model will be finetuned!! \" + 15*\"*\")\n",
    "    model_gsp.prune_and_mask_model(sps=args.finetune_sps)\n",
    "    \n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        model_gsp.model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.evaluate, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, 4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), download=True),\n",
    "    batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "\n",
    "# ----------------------- Make a GSP Model -----------------------\n",
    "print(f\"The sparsity of the model is: {model_gsp.get_model_sps():.2f}\")\n",
    "args.writer = SummaryWriter(log_dir=f'results/{args.exp_name}/runs/{datetime.now().strftime(\"%m-%d_%H:%M\")}')\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "# ============================ Setup GSP model ============================\n",
    "if args.gsp_training:\n",
    "    gsp_sparse_training(model_gsp, train_loader, args)\n",
    "    flogger.info(15*\"*\" + \" Model will be trained with GSP Sparsity!! \" + 15*\"*\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(train_loader, model_gsp, criterion, optimizer, 0, args, gsp_mode=True)\n",
    "# validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sparsity: 86.14 %\n"
     ]
    }
   ],
   "source": [
    "model_gsp.get_model_sps()\n",
    "model_gsp.print_model_sps()\n",
    "model_gsp.proj_filters=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_gsp.force_apply_gsp(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_gsp.prune_and_mask_model(sps=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global GSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_all_layers(self, sps):\n",
    "    layer_d = dict()\n",
    "    shape_d = dict()\n",
    "    ctr = 0\n",
    "    for i, (name, layer) in enumerate(self.model.named_modules()):\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            shape_d[name] = layer.weight.shape\n",
    "            layer_d[ctr] = layer.weight.data.detach().clone().flatten()\n",
    "            ctr+=1\n",
    "\n",
    "    xp_mat, ni_list = gsp_gen.GSP(layer_d, sps=sps)\n",
    "    out_layers = gsp_gen.unpad_output_mat(xp_mat, ni_list)\n",
    "\n",
    "    # rebuild_network\n",
    "    ctr = 0\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.weight.data = out_layers[ctr].reshape(shape_d[name])\n",
    "            ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_all_layers(model_gsp, sps=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (name, layer) in enumerate(model.named_modules()):\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        print(layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sparsity(matrix, ni_list):\n",
    "    \"\"\"\n",
    "    This Hoyer Sparsity Calculation is for matrices with the end of the columns that are padded. Hence,\n",
    "    it needs the information of how much of each columns are elements and how much of them are padded.\n",
    "    ni_list: Contains the number of values in each column (rest are padded with zero).\n",
    "    \"\"\"\n",
    "\n",
    "    ni = matrix.shape[0]\n",
    "    device = matrix.device\n",
    "    ni_tensor = torch.tensor(ni_list).to(device)\n",
    "\n",
    "    # Get Indices of all zero vector columns.\n",
    "    zero_col_ind = (abs(matrix.sum(0) - 0) < 2.22e-16).nonzero().view(-1)  \n",
    "    spx_c = (torch.sqrt(ni_tensor) - torch.norm(matrix,1, dim=0) / torch.norm(matrix,2, dim=0)) / (torch.sqrt(ni_tensor) - 1)\n",
    "    if len(zero_col_ind) != 0:\n",
    "        spx_c[zero_col_ind] = 1  # Sparsity = 1 if column already zero vector.\n",
    "    \n",
    "    if matrix.dim() > 1:   \n",
    "        sps_avg = spx_c.mean()\n",
    "    elif matrix.dim() == 1:  # If not a matrix but a column vector!\n",
    "        sps_avg =  spx_c    \n",
    "    return sps_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, weight_l, shape_l, weight_d, layers_d = utilfuncs.get_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_d[names[0]].weight.data.detach().device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz.plot_weight_dist(model, title='Resnet20 Distribution', arch='resnet20', \n",
    "#                     filename='./results/gspS0.80/fine_0.9/w_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gsp_prune(model_gsp, sps=0.8):\n",
    "    model_gsp.force_apply_gsp(sps)\n",
    "    print(f\"SPS after gsp application: {model_gsp.get_model_sps():.2f}\")\n",
    "    \n",
    "    model_gsp.prune_and_mask_model(sps)\n",
    "    print(f\"SPS after pruning: {model_gsp.get_model_sps():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gsp_prune(model_gsp, sps=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomg Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.ones((3,3,2,2))\n",
    "# a[0,1,:,:] = 2\n",
    "# a[0,2,:,:] = 3\n",
    "\n",
    "# a[1,0,:,:] = 4\n",
    "# a[1,1,:,:] = 5\n",
    "# a[1,2,:,:] = 6\n",
    "\n",
    "# a[2,0,:,:] = 7\n",
    "# a[2,1,:,:] = 8\n",
    "# a[2,2,:,:] = 9"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a80be99c85f7168e962cfd15ef8eaee54987e9a808a4cfe4ee99a80cb38466"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
