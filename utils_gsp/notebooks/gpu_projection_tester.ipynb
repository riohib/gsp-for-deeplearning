{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pickle\n",
    "import scipy.io\n",
    "import logging\n",
    "import pdb\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def sparsity(matrix):\n",
    "    r = matrix.shape[1]  # no of vectors\n",
    "\n",
    "    spx = 0\n",
    "    spxList = []\n",
    "    for i in range(r):\n",
    "        if matrix[:, i].sum() == 0:\n",
    "            spx = 1\n",
    "            spxList.append(spx)\n",
    "            print('here')\n",
    "        else:\n",
    "            ni = matrix.shape[0]\n",
    "            spx = (np.sqrt(ni) - torch.norm(matrix[:, i], 1) / torch.norm(matrix[:, i], 2)) / (np.sqrt(ni) - 1)\n",
    "            spxList.append(spx)\n",
    "        spx = sum(spxList) / r\n",
    "\n",
    "    return spx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def checkCritical(matrix, critval_list, precision=1e-6):\n",
    "    max_elems = torch.max(matrix, 0)[0]\n",
    "\n",
    "    ind_crit_bool = (abs(matrix - max_elems) < precision)\n",
    "    crit_points = matrix * ind_crit_bool\n",
    "\n",
    "    num_crit_points = torch.sum(ind_crit_bool, dim=0)\n",
    "\n",
    "    # Boolean of vector cols with non-trivial critical values\n",
    "    crit_cols = torch.where(num_crit_points.float() > 1, torch.ones(matrix.shape[1], device=device), \\\n",
    "                            torch.zeros(matrix.shape[1], device=device))\n",
    "\n",
    "    # getting non-trivial critical values\n",
    "    critval_list = max_elems[crit_cols.bool()]\n",
    "\n",
    "    return critval_list, max_elems"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "max_elems = torch.max(matrix, 0)[0]\n",
    "\n",
    "ind_crit_bool = (abs(matrix - max_elems) < precision)\n",
    "crit_points = matrix * ind_crit_bool\n",
    "\n",
    "num_crit_points = torch.sum(ind_crit_bool, dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "arg1 = torch.ones(matrix.shape[1], device='cuda:0')\n",
    "arg2 = torch.zeros(matrix.shape[1], device='cuda:0')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "str(arg1.device)\n",
    "\n",
    "device = torch.device(arg1.device)\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "torch.where(num_crit_points.float() > 1, arg1, arg2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "print(arg1.device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "a = 5\n",
    "torch.tensor(a, device='cuda')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(5, device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def gmu(matrix, xp_mat, mu=0):\n",
    "    vgmu = 0\n",
    "    gradg = 0\n",
    "    matrix = torch.abs(matrix)\n",
    "    xp_mat = torch.zeros([matrix.shape[0], matrix.shape[1]]).to(device)\n",
    "    glist = []\n",
    "\n",
    "    gsp_iter = 0\n",
    "\n",
    "    # ------------------------------- Previous For Loop --------------------------------------\n",
    "    ni = matrix.shape[0]\n",
    "    betai = 1 / (torch.sqrt(torch.tensor(ni, dtype=torch.float32, device=device)) - 1)\n",
    "\n",
    "    xp_mat = matrix - (mu * betai)\n",
    "    indtp = xp_mat > 0\n",
    "\n",
    "    xp_mat.relu_()\n",
    "\n",
    "    # outputs\n",
    "    mnorm = torch.norm(xp_mat, dim=0)\n",
    "    mnorm_inf = mnorm.clone()\n",
    "    mnorm_inf[mnorm_inf == 0] = float(\"Inf\")\n",
    "\n",
    "    col_norm_mask = (mnorm > 0)\n",
    "\n",
    "    # mat_mask =  (col_norm_mask.float().view(1,784) * torch.ones(300,1))\n",
    "    mat_mask = (col_norm_mask.float().view(1, matrix.shape[1]) * torch.ones(matrix.shape[0], 1,device=device))\n",
    "\n",
    "    nip = torch.sum(xp_mat > 0, dim=0)  # columnwise number of values > 0\n",
    "\n",
    "    # needs the if condition mnorm> 0 (it's included)\n",
    "    # Terms in the Gradient Calculation\n",
    "    term2 = torch.pow(torch.sum(xp_mat, dim=0), 2)\n",
    "    mnorm_inv = torch.pow(mnorm_inf, -1)\n",
    "    mnorm_inv3 = torch.pow(mnorm_inf, -3)\n",
    "\n",
    "    # The column vectors with norm mnorm == 0 zero, should not contribute to the gradient sum.\n",
    "    # In the published algorithm, we only calculate gradients for condition: mnorm> 0\n",
    "    # To vectorize, we include in the matrix columns where mnorm == 0, but we manually replace\n",
    "    # the inf after divide by zero with 0, so that the grad of that column becomes 0 and\n",
    "    # doesn't contribute to the sum.\n",
    "    # mnorm_inv[torch.isinf(mnorm_inv)] = 0\n",
    "    # mnorm_inv3[torch.isinf(mnorm_inv3)] = 0\n",
    "\n",
    "    # Calculate Gradient\n",
    "    gradg_mat = torch.pow(betai, 2) * (-nip * mnorm_inv + term2 * mnorm_inv3)\n",
    "    gradg = torch.sum(gradg_mat)\n",
    "\n",
    "    # vgmu calculation\n",
    "    ## When indtp is not empty (the columns whose norm are not zero)\n",
    "    # xp_mat /= mnorm\n",
    "    xp_mat[:, col_norm_mask] /= mnorm[col_norm_mask]\n",
    "\n",
    "    ## When indtp IS empty (the columns whose norm ARE zero)\n",
    "    max_elem_rows = torch.argmax(matrix, dim=0)[~col_norm_mask]  # The Row Indices where maximum of that column occurs\n",
    "    xp_mat[max_elem_rows, ~col_norm_mask] = 1\n",
    "\n",
    "    # vgmu computation\n",
    "    vgmu_mat = betai * torch.sum(xp_mat, dim=0)\n",
    "    vgmu = torch.sum(vgmu_mat)\n",
    "\n",
    "    return vgmu, xp_mat, gradg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def groupedsparseproj(matrix, sps, precision=1e-6, linrat=0.9):\n",
    "    # sps = 0.9 ;  precision=1e-6; linrat=0.9\n",
    "\n",
    "    epsilon = 10e-15\n",
    "    k = 0\n",
    "    muup0 = 0\n",
    "    r = matrix.shape[1]  # No of Columns\n",
    "\n",
    "    critmu = torch.tensor([])\n",
    "    critval_list = []\n",
    "\n",
    "    vgmu = torch.zeros(1, device=device)\n",
    "    # maxxi_list = []\n",
    "\n",
    "    # These operations were inside the loop, but doesn't need to be.\n",
    "    matrix_sign = torch.sign(matrix)\n",
    "    pos_matrix = matrix_sign * matrix\n",
    "    xp_mat = torch.zeros([matrix.shape[0], matrix.shape[1]]).to(device)\n",
    "    ni = matrix.shape[0]\n",
    "\n",
    "    # -------------------------------------------------------------------------------\n",
    "    # Check Critical Points\n",
    "    k = r * np.sqrt(ni) / (np.sqrt(ni) - 1)\n",
    "    # check critical values of mu where g(mu) is discontinuous, that is,\n",
    "    # where the two (or more) largest entries of x{i} are equal to one another.\n",
    "    critical_val, max_xi = checkCritical(pos_matrix, critval_list)\n",
    "    muup0 = max(max_xi * (np.sqrt(ni) - 1))\n",
    "    critmu = torch.tensor(critval_list) * (np.sqrt(ni) - 1)\n",
    "\n",
    "    k = k - r * sps\n",
    "    vgmu, xp_mat, gradg = gmu(pos_matrix, xp_mat, 0)\n",
    "\n",
    "    if vgmu < k:\n",
    "        xp_mat = matrix\n",
    "        gxpmu = vgmu\n",
    "        numiter = 0\n",
    "        return xp_mat\n",
    "    else:\n",
    "        numiter = 0\n",
    "        mulow = 0\n",
    "        glow = vgmu\n",
    "        muup = muup0\n",
    "        # Initialization on mu using 0, it seems to work best because the\n",
    "        # slope at zero is rather steep while it is gets falt for large mu\n",
    "        newmu = 0\n",
    "        gnew = glow\n",
    "        gpnew = gradg  # g'(0)\n",
    "        delta = muup - mulow\n",
    "        switch = True\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        while abs(gnew - k) > precision * r and numiter < 100:\n",
    "            oldmu = newmu\n",
    "            # % Secant method:\n",
    "            # % newmu = mulow + (k-glow)*(muup-mulow)/(gup-glow);\n",
    "\n",
    "            # % Bisection:\n",
    "            # % newmu = (muup+mulow)/2;\n",
    "            # % Newton:\n",
    "            newmu = oldmu + (k - gnew) / (gpnew + epsilon)\n",
    "\n",
    "            if (newmu >= muup) or (newmu <= mulow):  # If Newton goes out of the interval, use bisection\n",
    "                newmu = (mulow + muup) / 2\n",
    "\n",
    "            # print( 'Value of numiter: ' + str(numiter))\n",
    "            gnew, xnew, gpnew = gmu(matrix, xp_mat, newmu)\n",
    "\n",
    "            if gnew < k:\n",
    "                gup = gnew\n",
    "                xup = xnew\n",
    "                muup = newmu\n",
    "            else:\n",
    "                glow = gnew\n",
    "                mulow = xnew\n",
    "                mulow = newmu\n",
    "\n",
    "            # Guarantees linear convergence\n",
    "            if (muup - mulow) > linrat * delta and abs(oldmu - newmu) < (1 - linrat) * delta:\n",
    "                newmu = (mulow + muup) / 2\n",
    "                gnew, xnew, gpnew = gmu(matrix, xp_mat, newmu)\n",
    "\n",
    "                if gnew < k:\n",
    "                    gup = gnew\n",
    "                    xup = xnew\n",
    "                    muup = newmu\n",
    "                else:\n",
    "                    glow = gnew\n",
    "                    mulow = xnew\n",
    "                    mulow = newmu\n",
    "                numiter += 1\n",
    "            numiter += 1\n",
    "\n",
    "            if critmu.shape[0] != 0 and abs(mulow - muup) < abs(newmu) * precision and \\\n",
    "                    min(abs(newmu - critmu)) < precision * newmu:\n",
    "                print('The objective function is discontinuous around mu^*.')\n",
    "                xp = xnew\n",
    "                gxpmu = gnew\n",
    "        try:\n",
    "            xp_mat = xnew\n",
    "            # print(' xp_mat = xnew')\n",
    "        except:\n",
    "            scipy.io.savemat('matrix.mat', mdict={'arr': matrix})\n",
    "\n",
    "        gxpmu = gnew\n",
    "\n",
    "    # pdb.set_trace()\n",
    "\n",
    "    # alpha = torch.zeros([1, matrix.shape[1]], device=device)\n",
    "    # for i in range(r):\n",
    "    #     alpha[0, i] = torch.matmul(xp_mat[:, i], pos_matrix[:, i])\n",
    "    #     xp_mat[:, i] = alpha[:, i] * (matrix_sign[:, i] * xp_mat[:, i])\n",
    "    \n",
    "    alpha_mat = torch.matmul(xp_mat.T, pos_matrix)\n",
    "    alpha = torch.diagonal(alpha_mat)\n",
    "    xp_mat = alpha * (matrix_sign * xp_mat)\n",
    "\n",
    "    return xp_mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def load_matrix_debug():\n",
    "    with open(\"./matrices/matrix_3.pkl\", \"rb\") as fpA:  # Pickling\n",
    "        matrix = pickle.load(fpA)\n",
    "        # matrix = matrix.detach()\n",
    "        matrix = torch.from_numpy(matrix)\n",
    "    return matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "matrix = load_matrix_debug()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "matrix = matrix.to(device)\n",
    "sps = 0.9\n",
    "precision = 1e-6\n",
    "linrat = 0.9"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "X = groupedsparseproj(matrix, sps, precision=1e-6, linrat=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "sparsity(matrix)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.1551, device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "matrix = matrix.to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "sps = 0.9 ;  precision=1e-6; linrat=0.9\n",
    "\n",
    "epsilon = 10e-15\n",
    "k = 0\n",
    "muup0 = 0\n",
    "r = matrix.shape[1]  # No of Columns\n",
    "\n",
    "critmu = torch.tensor([])\n",
    "critval_list = []\n",
    "\n",
    "vgmu = torch.zeros(1, device=device)\n",
    "# maxxi_list = []\n",
    "\n",
    "# These operations were inside the loop, but doesn't need to be.\n",
    "matrix_sign = torch.sign(matrix)\n",
    "pos_matrix = matrix_sign * matrix\n",
    "xp_mat = torch.zeros([matrix.shape[0], matrix.shape[1]]).to(device)\n",
    "ni = matrix.shape[0]\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Check Critical Points\n",
    "k = r * np.sqrt(ni) / (np.sqrt(ni) - 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check critical values of mu where g(mu) is discontinuous, that is,\n",
    "# where the two (or more) largest entries of x{i} are equal to one another.\n",
    "critical_val, max_xi = checkCritical(pos_matrix, critval_list)\n",
    "muup0 = max(max_xi * (np.sqrt(ni) - 1))\n",
    "critmu = torch.tensor(critval_list) * (np.sqrt(ni) - 1)\n",
    "\n",
    "k = k - r * sps\n",
    "vgmu, xp_mat, gradg = gmu(pos_matrix, xp_mat, 0)\n",
    "\n",
    "if vgmu < k:\n",
    "    xp_mat = matrix\n",
    "    gxpmu = vgmu\n",
    "    numiter = 0\n",
    "    xp_mat\n",
    "else:\n",
    "    numiter = 0\n",
    "    mulow = 0\n",
    "    glow = vgmu\n",
    "    muup = muup0\n",
    "    # Initialization on mu using 0, it seems to work best because the\n",
    "    # slope at zero is rather steep while it is gets falt for large mu\n",
    "    newmu = 0\n",
    "    gnew = glow\n",
    "    gpnew = gradg  # g'(0)\n",
    "    delta = muup - mulow\n",
    "    switch = True\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    while abs(gnew - k) > precision * r and numiter < 100:\n",
    "        oldmu = newmu\n",
    "        # % Secant method:\n",
    "        # % newmu = mulow + (k-glow)*(muup-mulow)/(gup-glow);\n",
    "\n",
    "        # % Bisection:\n",
    "        # % newmu = (muup+mulow)/2;\n",
    "        # % Newton:\n",
    "        newmu = oldmu + (k - gnew) / (gpnew + epsilon)\n",
    "\n",
    "        if (newmu >= muup) or (newmu <= mulow):  # If Newton goes out of the interval, use bisection\n",
    "            newmu = (mulow + muup) / 2\n",
    "\n",
    "        # print( 'Value of numiter: ' + str(numiter))\n",
    "        gnew, xnew, gpnew = gmu(matrix, xp_mat, newmu)\n",
    "\n",
    "        if gnew < k:\n",
    "            gup = gnew\n",
    "            xup = xnew\n",
    "            muup = newmu\n",
    "        else:\n",
    "            glow = gnew\n",
    "            mulow = xnew\n",
    "            mulow = newmu\n",
    "\n",
    "        # Guarantees linear convergence\n",
    "        if (muup - mulow) > linrat * delta and abs(oldmu - newmu) < (1 - linrat) * delta:\n",
    "            newmu = (mulow + muup) / 2\n",
    "            gnew, xnew, gpnew = gmu(matrix, xp_mat, newmu)\n",
    "\n",
    "            if gnew < k:\n",
    "                gup = gnew\n",
    "                xup = xnew\n",
    "                muup = newmu\n",
    "            else:\n",
    "                glow = gnew\n",
    "                mulow = xnew\n",
    "                mulow = newmu\n",
    "            numiter += 1\n",
    "        numiter += 1\n",
    "\n",
    "        if critmu.shape[0] != 0 and abs(mulow - muup) < abs(newmu) * precision and \\\n",
    "                min(abs(newmu - critmu)) < precision * newmu:\n",
    "            print('The objective function is discontinuous around mu^*.')\n",
    "            xp = xnew\n",
    "            gxpmu = gnew\n",
    "    try:\n",
    "        xp_mat = xnew\n",
    "        # print(' xp_mat = xnew')\n",
    "    except:\n",
    "        scipy.io.savemat('matrix.mat', mdict={'arr': matrix})\n",
    "\n",
    "    gxpmu = gnew"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# alpha_mat = torch.matmul(xp_mat.T, pos_matrix)\n",
    "# alpha = torch.diagonal(alpha_mat)\n",
    "# xp_mat = alpha * (matrix_sign * xp_mat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "torch.norm(xp_mat, 2, dim=0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "matrix.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([50, 8000])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "torch.norm(xp_mat, 2, dim=0).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8000])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('nv-imagenet': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "d05cc80b9d10f7e2f9383da42a9a71bdc0f65d5f668fef46c05db91793c7970c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}