{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "import networks.load as load\n",
    "\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils_gsp.logger import Logger\n",
    "from utils_gsp import sps_tools\n",
    "from gsp_model import GSP_Model\n",
    "import tools.ipynb_funcs as utilfuncs\n",
    "import tools.visualization as viz\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from main import train, validate, accuracy, save_checkpoint, setup_experiment, gsp_sparse_training, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    arch = 'resnet20'\n",
    "    workers = 4\n",
    "    epochs=160\n",
    "    start_epoch=0\n",
    "    batch_size = 128\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay=1e-4\n",
    "    print_freq = 50\n",
    "    resume = False\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    half = False\n",
    "    exp_name = 'gsp_test'\n",
    "\n",
    "    gpu=None\n",
    "    logdir = '/logdir'\n",
    "    gsp_training = True \n",
    "    gsp_sps = 0.8\n",
    "    gsp_int = 150\n",
    "    gsp_start_ep = -1\n",
    "    finetune = False\n",
    "    finetune_sps = 0.9\n",
    "\n",
    "\n",
    "global args, best_acc1\n",
    "args = Args\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.resume = './results/gspS0.9/gsp/model_best.pth.tar' # LOAD GSP MODEL\n",
    "\n",
    "# args.resume = './results/gspS0.80/fine_0.9/model_best.pth.tar'\n",
    "# args.finetune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " input logdir: ./results/gsp_test/logdir \n",
      "\n",
      "\n",
      " RETURNED FILE LOGGER! \n",
      "\n",
      "Files already downloaded and verified\n",
      "The sparsity of the model is: 0.26\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# Setup the experiment\n",
    "flogger = setup_experiment(args)\n",
    "args.logger.log_cmd_arguments(args)\n",
    "\n",
    "# model = torch.nn.DataParallel(resnet.__dict__[args.arch]())\n",
    "# model = VGG('D')\n",
    "model = load.model(args.arch)\n",
    "model.cuda()\n",
    "\n",
    "model_gsp = GSP_Model(model)\n",
    "\n",
    "if args.finetune:\n",
    "    flogger.info(15*\"*\" + \" Model will be finetuned!! \" + 15*\"*\")\n",
    "    model_gsp.prune_and_mask_model(sps=args.finetune_sps)\n",
    "    \n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        model_gsp.model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.evaluate, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, 4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), download=True),\n",
    "    batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "\n",
    "# ----------------------- Make a GSP Model -----------------------\n",
    "print(f\"The sparsity of the model is: {model_gsp.get_model_sps():.2f}\")\n",
    "args.writer = SummaryWriter(log_dir=f'results/{args.exp_name}/runs/{datetime.now().strftime(\"%m-%d_%H:%M\")}')\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "# ============================ Setup GSP model ============================\n",
    "if args.gsp_training:\n",
    "    gsp_sparse_training(model_gsp, train_loader, args)\n",
    "    flogger.info(15*\"*\" + \" Model will be trained with GSP Sparsity!! \" + 15*\"*\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(train_loader, model_gsp, criterion, optimizer, 0, args, gsp_mode=False)\n",
    "# validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2550774501153039"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsp.get_model_sps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        w_shape[name] = layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = weight_d[names[1]]\n",
    "print(weight_d[names[1]].shape)\n",
    "layer.reshape(layer.shape[0], -1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.force_apply_gsp(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.prune_and_mask_model(sps=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, weight_l, shape_l, weight_d, layers_d = utilfuncs.get_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz.plot_weight_dist(model, title='Resnet20 Distribution', arch='resnet20', \n",
    "#                     filename='./results/gspS0.80/fine_0.9/w_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gsp_prune(model_gsp, sps=0.8):\n",
    "    model_gsp.force_apply_gsp(sps)\n",
    "    print(f\"SPS after gsp application: {model_gsp.get_model_sps():.2f}\")\n",
    "    \n",
    "    model_gsp.prune_and_mask_model(sps)\n",
    "    print(f\"SPS after pruning: {model_gsp.get_model_sps():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gsp_prune(model_gsp, sps=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a80be99c85f7168e962cfd15ef8eaee54987e9a808a4cfe4ee99a80cb38466"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
