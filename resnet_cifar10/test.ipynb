{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56']\n",
      "['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56']\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import resnet\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils_gsp.logger import Logger\n",
    "from utils_gsp import sps_tools\n",
    "from gsp_model import GSP_Model\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from main import train, validate, accuracy, save_checkpoint, setup_experiment, gsp_sparse_training, AverageMeter\n",
    "\n",
    "model_names = sorted(name for name in resnet.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "                     and name.startswith(\"resnet\")\n",
    "                     and callable(resnet.__dict__[name]))\n",
    "\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    arch = 'resnet20'\n",
    "    workers = 4\n",
    "    epochs=160\n",
    "    start_epoch=0\n",
    "    batch_size = 128\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay=1e-4\n",
    "    print_freq = 50\n",
    "    resume = False\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    half = False\n",
    "    exp_name = 'gsp_test'\n",
    "\n",
    "    gpu=None\n",
    "    logdir = '/logdir'\n",
    "    gsp_training = True \n",
    "    gsp_sps = 0.8\n",
    "    gsp_int = 150\n",
    "    gsp_start_ep = -1\n",
    "    finetuning = False\n",
    "    finetune_sps = 0.9\n",
    "\n",
    "\n",
    "global args, best_acc1\n",
    "args = Args\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume = './results/gspS80/model_best.pth.tar' # LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56']\n",
      "\n",
      " input logdir: ./results/gsp_test/logdir \n",
      "\n",
      "\n",
      " RETURNED FILE LOGGER! \n",
      "\n",
      "=> loading checkpoint './results/gspS80/model_best.pth.tar'\n",
      "=> loaded checkpoint 'False' (epoch 185)\n",
      "Files already downloaded and verified\n",
      "The sparsity of the model is: 3.82\n",
      "Current Epoch: 185\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# Setup the experiment\n",
    "flogger = setup_experiment(args)\n",
    "args.logger.log_cmd_arguments(args)\n",
    "\n",
    "model = torch.nn.DataParallel(resnet.__dict__[args.arch]())\n",
    "model.cuda()\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.evaluate, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, 4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), download=True),\n",
    "    batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "\n",
    "# ----------------------- Make a GSP Model -----------------------\n",
    "model_gsp = GSP_Model(model)\n",
    "\n",
    "print(f\"The sparsity of the model is: {model_gsp.get_model_sps():.2f}\")\n",
    "args.writer = SummaryWriter(log_dir=f'results/{args.exp_name}/runs/{datetime.now().strftime(\"%m-%d_%H:%M\")}')\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "# ============================ Setup GSP model ============================\n",
    "if args.gsp_training:\n",
    "    gsp_sparse_training(model_gsp, train_loader, args)\n",
    "    flogger.info(15*\"*\" + \" Model will be trained with GSP Sparsity!! \" + 15*\"*\" )\n",
    "\n",
    "# ============== PRUNE the model and Register Mask ==============\n",
    "if args.finetuning:\n",
    "    flogger.info(15*\"*\" + \" Model will be finetuned!! \" + 15*\"*\")\n",
    "    sps_tools.prune_with_sps(model_gsp.model.module, sparsity = args.finetune_sps)\n",
    "    masks_d, masks_l = sps_tools.get_conv_linear_mask(model_gsp.model.module)\n",
    "    model_gsp.register_pre_hook_mask(masks_d) # This for forward pre hook mask registration\n",
    "    # model_gsp.register_hook_mask(model.module, masks_l) # Does not work with DDP\n",
    "\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "#                 milestones=[80, 120], last_epoch=args.start_epoch - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying GSP!! GSP_Mode: True\n",
      "Applying GSP!! GSP_Mode: True\n",
      "Applying GSP!! GSP_Mode: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(train_loader, model_gsp, criterion, optimizer, 0, args, gsp_mode=False)\n",
    "# validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.20384419523546"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsp.get_model_sps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning with threshold : 0.05073028802871704 for layer module.linear.bias\n"
     ]
    }
   ],
   "source": [
    "# model_gsp.force_apply_gsp(0.80)\n",
    "model_gsp.prune_and_mask_model(sps=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_tools.prune_with_sps(model, 0.9)\n",
    "masks_d ,_ = sps_tools.get_conv_linear_mask(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model_gsp.model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "        module.weight.data = module.weight.data * model_gsp.masks[module]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a80be99c85f7168e962cfd15ef8eaee54987e9a808a4cfe4ee99a80cb38466"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
