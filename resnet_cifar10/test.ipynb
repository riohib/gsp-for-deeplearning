{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56']\n",
      "['resnet110', 'resnet1202', 'resnet20', 'resnet32', 'resnet44', 'resnet56']\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import resnet\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "from networks.vgg16 import VGG\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils_gsp.logger import Logger\n",
    "from utils_gsp import sps_tools\n",
    "from gsp_model import GSP_Model\n",
    "import tools.ipynb_funcs as utilfuncs\n",
    "import tools.visualization as viz\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from main import train, validate, accuracy, save_checkpoint, setup_experiment, gsp_sparse_training, AverageMeter\n",
    "\n",
    "model_names = sorted(name for name in resnet.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "                     and name.startswith(\"resnet\")\n",
    "                     and callable(resnet.__dict__[name]))\n",
    "\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    arch = 'resnet20'\n",
    "    workers = 4\n",
    "    epochs=160\n",
    "    start_epoch=0\n",
    "    batch_size = 128\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay=1e-4\n",
    "    print_freq = 50\n",
    "    resume = False\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    half = False\n",
    "    exp_name = 'gsp_test'\n",
    "\n",
    "    gpu=None\n",
    "    logdir = '/logdir'\n",
    "    gsp_training = True \n",
    "    gsp_sps = 0.8\n",
    "    gsp_int = 150\n",
    "    gsp_start_ep = -1\n",
    "    finetune = False\n",
    "    finetune_sps = 0.9\n",
    "\n",
    "\n",
    "global args, best_acc1\n",
    "args = Args\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.resume = './results/gspS0.9/gsp/model_best.pth.tar' # LOAD GSP MODEL\n",
    "\n",
    "# args.resume = './results/gspS0.80/fine_0.9/model_best.pth.tar'\n",
    "# args.finetune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " input logdir: ./results/gsp_test/logdir \n",
      "\n",
      "\n",
      " RETURNED FILE LOGGER! \n",
      "\n",
      "Files already downloaded and verified\n",
      "The sparsity of the model is: 0.03\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# Setup the experiment\n",
    "flogger = setup_experiment(args)\n",
    "args.logger.log_cmd_arguments(args)\n",
    "\n",
    "# model = torch.nn.DataParallel(resnet.__dict__[args.arch]())\n",
    "# model = VGG('D')\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "model_gsp = GSP_Model(model)\n",
    "\n",
    "if args.finetune:\n",
    "    flogger.info(15*\"*\" + \" Model will be finetuned!! \" + 15*\"*\")\n",
    "    model_gsp.prune_and_mask_model(sps=args.finetune_sps)\n",
    "    \n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        model_gsp.model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.evaluate, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, 4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), download=True),\n",
    "    batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "\n",
    "# ----------------------- Make a GSP Model -----------------------\n",
    "print(f\"The sparsity of the model is: {model_gsp.get_model_sps():.2f}\")\n",
    "args.writer = SummaryWriter(log_dir=f'results/{args.exp_name}/runs/{datetime.now().strftime(\"%m-%d_%H:%M\")}')\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "# ============================ Setup GSP model ============================\n",
    "if args.gsp_training:\n",
    "    gsp_sparse_training(model_gsp, train_loader, args)\n",
    "    flogger.info(15*\"*\" + \" Model will be trained with GSP Sparsity!! \" + 15*\"*\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rohib/anaconda3/envs/imagenet/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8059/1855635405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_gsp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsp_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# validate(val_loader, model, criterion, args)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users2/rohib/github-repos/gsp-for-deeplearning/resnet_cifar10/main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model_gsp, criterion, optimizer, epoch, args, gsp_mode)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gsp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/imagenet/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/users2/rohib/github-repos/gsp-for-deeplearning/resnet_cifar10/networks/vgg16.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train(train_loader, model_gsp, criterion, optimizer, 0, args, gsp_mode=False)\n",
    "# validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.get_model_sps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_sps(self):\n",
    "    nonzero = total = 0\n",
    "    for name, param in self.model.named_parameters():\n",
    "        if 'mask' not in name:\n",
    "            tensor = param.detach().clone()\n",
    "            # nz_count.append(torch.count_nonzero(tensor))\n",
    "            nz_count = torch.count_nonzero(tensor).item()\n",
    "            total_params = tensor.numel()\n",
    "            nonzero += nz_count\n",
    "            total += total_params\n",
    "    \n",
    "    tensor = None\n",
    "    # print(f\"TOTAL: {total}\")\n",
    "    abs_sps = 100 * (total-nonzero) / total\n",
    "    return abs_sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_sps(model_gsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.force_apply_gsp(0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.prune_and_mask_model(sps=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, weight_l, shape_l, weight_d, layers_d = utilfuncs.get_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz.plot_weight_dist(model, title='Resnet20 Distribution', arch='resnet20', \n",
    "#                     filename='./results/gspS0.80/fine_0.9/w_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gsp_prune(model_gsp, sps=0.8):\n",
    "    model_gsp.force_apply_gsp(sps)\n",
    "    print(f\"SPS after gsp application: {model_gsp.get_model_sps():.2f}\")\n",
    "    \n",
    "    model_gsp.prune_and_mask_model(sps)\n",
    "    print(f\"SPS after pruning: {model_gsp.get_model_sps():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gsp_prune(model_gsp, sps=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a80be99c85f7168e962cfd15ef8eaee54987e9a808a4cfe4ee99a80cb38466"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('imagenet': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
