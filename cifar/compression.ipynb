{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import networks.torch_vgg as vgg\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import validate\n",
    "from datasets import dataprep\n",
    "from gsp_model import GSP_Model\n",
    "from main import AverageMeter, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    arch = 'vgg19_bn'\n",
    "    dataset='cifar10'\n",
    "    workers = 4\n",
    "    epochs=160\n",
    "    start_epoch=0\n",
    "    batch_size = 128\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay=1e-4\n",
    "    print_freq = 50\n",
    "    resume = False\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    half = False\n",
    "    exp_name = 'gsp_test'\n",
    "    \n",
    "    gpu=None\n",
    "    logdir = '/logdir'\n",
    "    gsp_training = True \n",
    "    gsp_sps = 0.8\n",
    "    scheduled_sps_run = True\n",
    "    proj_filters = False\n",
    "    proj_model = False\n",
    "    gsp_int = 150\n",
    "    gsp_start_ep = -1\n",
    "    finetune = False\n",
    "    finetune_sps = 0.9\n",
    "    \n",
    "    filelogger = None\n",
    "\n",
    "global args, best_acc1\n",
    "args = Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume = \"/private/home/riohib/explore/gsp_cifar/cifar/model_best.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "if args.dataset == 'cifar10': num_classes = 10\n",
    "if args.dataset == 'cifar100': num_classes = 100\n",
    "\n",
    "if 'vgg' in args.arch: model = vgg.__dict__[\"vgg19_bn\"](num_classes=num_classes)\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "train_loader, val_loader = dataprep.get_data_loaders(dataset=args.dataset, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_gsp = GSP_Model(model)\n",
    "# model_gsp.logger = args.filelogger # Initiate Logger\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally resume from a checkpoint\n",
    "chkpt_path = args.resume\n",
    "def load_checkpoint(chkpt_path):\n",
    "    checkpoint = torch.load(chkpt_path)\n",
    "    args.start_epoch = checkpoint['epoch'] if not args.finetune else 0\n",
    "    best_acc1 = checkpoint['best_acc1'] if not args.finetune else 0\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "load_checkpoint(chkpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Acc@1: 93.090 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.09"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Acc@1: 93.090 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.09"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, fft_model, criterion, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_d = dict()\n",
    "names = list()\n",
    "for name, params in model.named_parameters():\n",
    "    names.append(name)\n",
    "    params_d[name] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_fft = torch.fft.fftn(params_d[names[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_d = dict()\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "        module_d[name] = module.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512.0\n"
     ]
    }
   ],
   "source": [
    "weight_tensor = module_d[name].flatten()\n",
    "numelem = weight_tensor.shape[0]\n",
    "topk_weights = numelem * 0.1\n",
    "print(topk_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_d[name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_tensor(in_tensor, sparsity=0.9):\n",
    "    t_shape = in_tensor.shape\n",
    "    tensor = in_tensor.flatten()\n",
    "    w_sps_num =  len(tensor) * sparsity\n",
    "    sorted_weights, _ = torch.sort(tensor.abs())\n",
    "    threshold = sorted_weights[:math.ceil(w_sps_num)+1][-1]\n",
    "    sps_tensor = torch.where(abs(tensor) < threshold, torch.tensor(0.0, device=tensor.device), tensor)\n",
    "    out_tensor = sps_tensor.reshape(t_shape)\n",
    "    return out_tensor\n",
    "\n",
    "def get_mask(in_tensor, sparsity=0.9):\n",
    "    out_tensor = threshold_tensor(in_tensor, sparsity=sparsity)\n",
    "    mask = out_tensor > 0.0   \n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if transform_func.__name__ == 'fft_fft':\n",
    "#     inverse_trans = torch.fft.ifft\n",
    "# elif transform_func.__name__ == 'fft_fftn':\n",
    "#     inverse_trans = torch.fft.ifftn\n",
    "#     print(\"using ifft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_fft_ifft(model):\n",
    "fft_module = dict()\n",
    "ifft_module = dict()\n",
    "sps_fft = dict()\n",
    "sps_abs_fft = dict()\n",
    "sps = 0.6\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "        fft_module[name] = torch.fft.fft(module.weight.data) # apply FFT\n",
    "        sps_abs_fft[name] = torch.abs(fft_module[name]) # get absolute FFT vales (make real)\n",
    "        sps_mask = get_mask(sps_abs_fft[name], sparsity=sps) # use the normalized real values for getting the topk mask\n",
    "        sps_fft_tensor = fft_module[name] * sps_mask # but mask the actual complex FFT values topk\n",
    "        ifft_module[name] = torch.fft.ifft(sps_fft_tensor).real # IFFT the sparse complex topk and save only the real values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_fft_model(ifft_modules):\n",
    "    for name, module in fft_model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            module.weight.data = ifft_module[name]\n",
    "    return fft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_fft_ifft(model):\n",
    "def transform_threshold(model, sps, transform_func):\n",
    "    fft_model = copy.deepcopy(model)\n",
    "    fft_module = dict()\n",
    "    ifft_module = dict()\n",
    "    sps_abs_fft = dict()\n",
    "\n",
    "    if transform_func.__name__ == 'fft_fft':\n",
    "        inverse_trans = torch.fft.ifft\n",
    "    elif transform_func.__name__ == 'fft_fftn':\n",
    "        inverse_trans = torch.fft.ifftn\n",
    "        print(\"using ifft\")\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            fft_module[name] = transform_func(module.weight.data) # apply FFT\n",
    "            sps_abs_fft[name] = torch.abs(fft_module[name]) # get absolute FFT vales (make real)\n",
    "            sps_mask = get_mask(sps_abs_fft[name], sparsity=sps) # use the normalized real values for getting the topk mask\n",
    "            sps_fft_tensor = fft_module[name] * sps_mask # but mask the actual complex FFT values topk\n",
    "            ifft_module[name] = inverse_trans(sps_fft_tensor).real # IFFT the sparse complex topk and save only the real values\n",
    "    return ifft_module, fft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Acc@1: 68.180 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.18"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifft_modules = transform_threshold(model, 0.5, torch.fft.fft)\n",
    "fft_model = populate_fft_model(ifft_modules)\n",
    "validate(val_loader, fft_model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.3125, 0.525, 0.7374999999999999, 0.95]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps_list = np.linspace(0.1, 0.95, 5)\n",
    "sps_list = list(sps_list)\n",
    "sps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "\n",
      " Validation Acc@1: 68.180 \n",
      "\n",
      "0.3125\n",
      "\n",
      " Validation Acc@1: 68.180 \n",
      "\n",
      "0.525\n",
      "\n",
      " Validation Acc@1: 68.180 \n",
      "\n",
      "0.7374999999999999\n",
      "\n",
      " Validation Acc@1: 68.180 \n",
      "\n",
      "0.95\n",
      "\n",
      " Validation Acc@1: 68.180 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_list = list()\n",
    "for sps in sps_list:\n",
    "    print(sps)\n",
    "    ifft_modules = transform_threshold(model, sps, torch.fft.fft)\n",
    "    fft_model = populate_fft_model(ifft_modules)\n",
    "    acc1 = validate(val_loader, fft_model, criterion, args)\n",
    "    acc_list.append(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(sps_list)\n",
    "for sps in sps_list:\n",
    "    print(sps)\n",
    "\n",
    "# acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Acc@1: 68.180 \n",
      "\n",
      "68.18\n"
     ]
    }
   ],
   "source": [
    "acc1 = validate(val_loader, fft_model, criterion, args)\n",
    "print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Acc@1: 93.090 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.09"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Step Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'vgg' in args.arch: model = vgg.__dict__[\"vgg19_bn\"](num_classes=10)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "train_loader, val_loader = dataprep.get_data_loaders(dataset=args.dataset, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_hook_for_profile',\n",
       " '_zero_grad_profile_name',\n",
       " 'add_param_group',\n",
       " 'defaults',\n",
       " 'load_state_dict',\n",
       " 'param_groups',\n",
       " 'state',\n",
       " 'state_dict',\n",
       " 'step',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import ModelAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ModelAnalysis(model, optimizer, criterion, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Acc@1: 30.000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to train mode\n"
     ]
    }
   ],
   "source": [
    "exp.train_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f414807afd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, label = exp.sample_data()\n",
    "image = data[0].cpu()\n",
    "plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepz =380 * 3\n",
    "for i in range(stepz):\n",
    "    loss = exp.sample_forward()\n",
    "    exp.backward(loss)\n",
    "    exp.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss: 2.3201189041137695\n",
      "[1] loss: 2.339859962463379\n",
      "[2] loss: 2.283064365386963\n",
      "[3] loss: 2.9042866230010986\n",
      "[4] loss: 2.7028861045837402\n",
      "[5] loss: 2.7130579948425293\n",
      "[6] loss: 3.2010178565979004\n",
      "[7] loss: 3.5326085090637207\n",
      "[8] loss: 3.358269691467285\n",
      "[9] loss: 3.0857889652252197\n",
      "[10] loss: 4.496649265289307\n",
      "[11] loss: 4.309123516082764\n",
      "[12] loss: 4.221973419189453\n",
      "[13] loss: 4.295749664306641\n",
      "[14] loss: 4.054405689239502\n",
      "[15] loss: 5.4131598472595215\n",
      "[16] loss: 3.7319021224975586\n",
      "[17] loss: 4.064109802246094\n",
      "[18] loss: 4.120781421661377\n",
      "[19] loss: 4.344333648681641\n",
      "[20] loss: 4.747957706451416\n",
      "[21] loss: 3.5490329265594482\n",
      "[22] loss: 4.2142653465271\n",
      "[23] loss: 3.621762275695801\n",
      "[24] loss: 3.128854513168335\n",
      "[25] loss: 3.1459438800811768\n",
      "[26] loss: 3.3066670894622803\n",
      "[27] loss: 4.193065166473389\n",
      "[28] loss: 3.7613747119903564\n",
      "[29] loss: 5.176436901092529\n",
      "[30] loss: 4.407149791717529\n",
      "[31] loss: 4.196115493774414\n",
      "[32] loss: 5.588255405426025\n",
      "[33] loss: 3.328944683074951\n",
      "[34] loss: 6.093028545379639\n",
      "[35] loss: 5.788975715637207\n",
      "[36] loss: 6.521832466125488\n",
      "[37] loss: 5.774928569793701\n",
      "[38] loss: 3.39526104927063\n",
      "[39] loss: 3.709449529647827\n",
      "[40] loss: 4.318195819854736\n",
      "[41] loss: 4.737865447998047\n",
      "[42] loss: 3.7310690879821777\n",
      "[43] loss: 3.3676061630249023\n",
      "[44] loss: 4.022919178009033\n",
      "[45] loss: 3.2176105976104736\n",
      "[46] loss: 4.075412750244141\n",
      "[47] loss: 3.951375722885132\n",
      "[48] loss: 4.277429103851318\n",
      "[49] loss: 4.180490016937256\n",
      "[50] loss: 3.2355151176452637\n",
      "[51] loss: 3.7334890365600586\n",
      "[52] loss: 4.017931938171387\n",
      "[53] loss: 3.248687505722046\n",
      "[54] loss: 3.1710846424102783\n",
      "[55] loss: 4.905922889709473\n",
      "[56] loss: 2.7643871307373047\n",
      "[57] loss: 3.7738499641418457\n",
      "[58] loss: 5.629252910614014\n",
      "[59] loss: 2.526174545288086\n",
      "[60] loss: 5.106622695922852\n",
      "[61] loss: 4.599148750305176\n",
      "[62] loss: 3.7521555423736572\n",
      "[63] loss: 3.0366647243499756\n",
      "[64] loss: 3.0426228046417236\n",
      "[65] loss: 3.5932233333587646\n",
      "[66] loss: 4.041021823883057\n",
      "[67] loss: 5.108729839324951\n",
      "[68] loss: 4.541271209716797\n",
      "[69] loss: 3.5209243297576904\n",
      "[70] loss: 3.5598225593566895\n",
      "[71] loss: 2.612220287322998\n",
      "[72] loss: 4.540229797363281\n",
      "[73] loss: 4.610529899597168\n",
      "[74] loss: 4.048712730407715\n",
      "[75] loss: 5.143861770629883\n",
      "[76] loss: 4.386159896850586\n",
      "[77] loss: 3.2237346172332764\n",
      "[78] loss: 3.899716854095459\n",
      "[79] loss: 2.421154737472534\n",
      "[80] loss: 3.1788597106933594\n",
      "[81] loss: 3.778752565383911\n",
      "[82] loss: 2.7235419750213623\n",
      "[83] loss: 3.7454068660736084\n",
      "[84] loss: 4.306267261505127\n",
      "[85] loss: 3.929884433746338\n",
      "[86] loss: 2.9225919246673584\n",
      "[87] loss: 3.456265449523926\n",
      "[88] loss: 3.0112884044647217\n",
      "[89] loss: 3.0732905864715576\n",
      "[90] loss: 3.7362494468688965\n",
      "[91] loss: 2.7293529510498047\n",
      "[92] loss: 3.1859018802642822\n",
      "[93] loss: 2.3507437705993652\n",
      "[94] loss: 2.4714813232421875\n",
      "[95] loss: 2.35565447807312\n",
      "[96] loss: 2.3814916610717773\n",
      "[97] loss: 2.4417574405670166\n",
      "[98] loss: 3.8985297679901123\n",
      "[99] loss: 2.4274075031280518\n",
      "[100] loss: 3.865142345428467\n",
      "[101] loss: 2.5484821796417236\n",
      "[102] loss: 2.293980836868286\n",
      "[103] loss: 2.2194132804870605\n",
      "[104] loss: 2.623461961746216\n",
      "[105] loss: 2.396326780319214\n",
      "[106] loss: 2.5523626804351807\n",
      "[107] loss: 3.110150098800659\n",
      "[108] loss: 4.453389644622803\n",
      "[109] loss: 4.181606292724609\n",
      "[110] loss: 2.3326382637023926\n",
      "[111] loss: 2.625343084335327\n",
      "[112] loss: 3.1413261890411377\n",
      "[113] loss: 3.410607099533081\n",
      "[114] loss: 3.111528158187866\n",
      "[115] loss: 3.864647626876831\n",
      "[116] loss: 3.5312185287475586\n",
      "[117] loss: 3.4271247386932373\n",
      "[118] loss: 3.4533298015594482\n",
      "[119] loss: 3.9745771884918213\n",
      "[120] loss: 4.012448310852051\n",
      "[121] loss: 4.41212797164917\n",
      "[122] loss: 4.304225444793701\n",
      "[123] loss: 2.890019416809082\n",
      "[124] loss: 3.692373275756836\n",
      "[125] loss: 3.0822861194610596\n",
      "[126] loss: 3.2422518730163574\n",
      "[127] loss: 3.268937587738037\n",
      "[128] loss: 3.2915091514587402\n",
      "[129] loss: 2.8878684043884277\n",
      "[130] loss: 2.8840630054473877\n",
      "[131] loss: 3.0888822078704834\n",
      "[132] loss: 3.2472288608551025\n",
      "[133] loss: 3.635436534881592\n",
      "[134] loss: 2.8692612648010254\n",
      "[135] loss: 3.6615591049194336\n",
      "[136] loss: 2.9712088108062744\n",
      "[137] loss: 2.944179058074951\n",
      "[138] loss: 2.5162432193756104\n",
      "[139] loss: 2.8153274059295654\n",
      "[140] loss: 2.613347053527832\n",
      "[141] loss: 2.8353044986724854\n",
      "[142] loss: 2.4877254962921143\n",
      "[143] loss: 2.4252617359161377\n",
      "[144] loss: 3.160627603530884\n",
      "[145] loss: 3.043299436569214\n",
      "[146] loss: 3.0292811393737793\n",
      "[147] loss: 2.4467806816101074\n",
      "[148] loss: 2.4717886447906494\n",
      "[149] loss: 2.801325798034668\n",
      "[150] loss: 2.797957420349121\n",
      "[151] loss: 2.6836869716644287\n",
      "[152] loss: 2.499140501022339\n",
      "[153] loss: 3.3177573680877686\n",
      "[154] loss: 2.839480400085449\n",
      "[155] loss: 2.8951518535614014\n",
      "[156] loss: 2.879564046859741\n",
      "[157] loss: 2.6502933502197266\n",
      "[158] loss: 2.8855388164520264\n",
      "[159] loss: 3.021402597427368\n",
      "[160] loss: 2.6414737701416016\n",
      "[161] loss: 3.0671768188476562\n",
      "[162] loss: 2.9811344146728516\n",
      "[163] loss: 2.5886123180389404\n",
      "[164] loss: 2.556499481201172\n",
      "[165] loss: 3.2445437908172607\n",
      "[166] loss: 3.338134288787842\n",
      "[167] loss: 2.83510422706604\n",
      "[168] loss: 2.8556652069091797\n",
      "[169] loss: 3.1887903213500977\n",
      "[170] loss: 2.927943229675293\n",
      "[171] loss: 2.6146297454833984\n",
      "[172] loss: 2.5287344455718994\n",
      "[173] loss: 2.758356809616089\n",
      "[174] loss: 2.6215896606445312\n",
      "[175] loss: 2.5239689350128174\n",
      "[176] loss: 2.737539052963257\n",
      "[177] loss: 2.6237635612487793\n",
      "[178] loss: 2.9448413848876953\n",
      "[179] loss: 2.4395906925201416\n",
      "[180] loss: 2.4782984256744385\n",
      "[181] loss: 2.4081876277923584\n",
      "[182] loss: 2.532681941986084\n",
      "[183] loss: 2.6132752895355225\n",
      "[184] loss: 2.465423107147217\n",
      "[185] loss: 2.570669651031494\n",
      "[186] loss: 2.4271442890167236\n",
      "[187] loss: 2.500483751296997\n",
      "[188] loss: 2.409031867980957\n",
      "[189] loss: 2.3342103958129883\n",
      "[190] loss: 2.382499933242798\n",
      "[191] loss: 2.574655771255493\n",
      "[192] loss: 2.374232053756714\n",
      "[193] loss: 2.2527709007263184\n",
      "[194] loss: 2.2304294109344482\n",
      "[195] loss: 2.483751058578491\n",
      "[196] loss: 2.344724178314209\n",
      "[197] loss: 2.290142059326172\n",
      "[198] loss: 2.733433485031128\n",
      "[199] loss: 2.551699638366699\n",
      "[200] loss: 2.3154549598693848\n",
      "[201] loss: 2.694643020629883\n",
      "[202] loss: 2.2899296283721924\n",
      "[203] loss: 2.3814470767974854\n",
      "[204] loss: 2.3680267333984375\n",
      "[205] loss: 2.4610934257507324\n",
      "[206] loss: 2.7320261001586914\n",
      "[207] loss: 2.4350547790527344\n",
      "[208] loss: 2.6193134784698486\n",
      "[209] loss: 2.522709846496582\n",
      "[210] loss: 2.633114814758301\n",
      "[211] loss: 2.676884174346924\n",
      "[212] loss: 2.4273335933685303\n",
      "[213] loss: 2.307842493057251\n",
      "[214] loss: 2.53096342086792\n",
      "[215] loss: 2.2926392555236816\n",
      "[216] loss: 2.455427885055542\n",
      "[217] loss: 2.2199745178222656\n",
      "[218] loss: 2.3000988960266113\n",
      "[219] loss: 2.3924336433410645\n",
      "[220] loss: 2.972564935684204\n",
      "[221] loss: 2.357597589492798\n",
      "[222] loss: 2.2881979942321777\n",
      "[223] loss: 2.240492820739746\n",
      "[224] loss: 2.2969932556152344\n",
      "[225] loss: 2.3344950675964355\n",
      "[226] loss: 2.32851243019104\n",
      "[227] loss: 2.4890713691711426\n",
      "[228] loss: 2.200617551803589\n",
      "[229] loss: 2.763122081756592\n",
      "[230] loss: 2.3716964721679688\n",
      "[231] loss: 2.5780441761016846\n",
      "[232] loss: 2.3311607837677\n",
      "[233] loss: 2.379854679107666\n",
      "[234] loss: 2.491145372390747\n",
      "[235] loss: 2.323364496231079\n",
      "[236] loss: 2.314791440963745\n",
      "[237] loss: 2.4591965675354004\n",
      "[238] loss: 2.518132209777832\n",
      "[239] loss: 2.29529070854187\n",
      "[240] loss: 2.4916272163391113\n",
      "[241] loss: 2.377408266067505\n",
      "[242] loss: 2.3587839603424072\n",
      "[243] loss: 2.405365467071533\n",
      "[244] loss: 2.357337236404419\n",
      "[245] loss: 2.1546621322631836\n",
      "[246] loss: 2.263927936553955\n",
      "[247] loss: 2.3329379558563232\n",
      "[248] loss: 2.2006494998931885\n",
      "[249] loss: 2.272859811782837\n",
      "[250] loss: 2.481285333633423\n",
      "[251] loss: 2.5440542697906494\n",
      "[252] loss: 2.2187693119049072\n",
      "[253] loss: 2.3740150928497314\n",
      "[254] loss: 2.4727914333343506\n",
      "[255] loss: 2.214057445526123\n",
      "[256] loss: 2.1339290142059326\n",
      "[257] loss: 2.495520830154419\n",
      "[258] loss: 2.418797016143799\n",
      "[259] loss: 2.4613125324249268\n",
      "[260] loss: 2.2336924076080322\n",
      "[261] loss: 2.292144536972046\n",
      "[262] loss: 2.30641770362854\n",
      "[263] loss: 2.4626572132110596\n",
      "[264] loss: 2.457038164138794\n",
      "[265] loss: 2.339729070663452\n",
      "[266] loss: 2.3507354259490967\n",
      "[267] loss: 2.1149721145629883\n",
      "[268] loss: 2.325270891189575\n",
      "[269] loss: 2.3086023330688477\n",
      "[270] loss: 2.3416244983673096\n",
      "[271] loss: 2.395204544067383\n",
      "[272] loss: 2.3836851119995117\n",
      "[273] loss: 2.3999810218811035\n",
      "[274] loss: 2.3811306953430176\n",
      "[275] loss: 2.3985984325408936\n",
      "[276] loss: 2.416001796722412\n",
      "[277] loss: 2.404595375061035\n",
      "[278] loss: 2.2823240756988525\n",
      "[279] loss: 2.210498571395874\n",
      "[280] loss: 2.361112594604492\n",
      "[281] loss: 2.2767555713653564\n",
      "[282] loss: 2.3255786895751953\n",
      "[283] loss: 2.3302431106567383\n",
      "[284] loss: 2.4802427291870117\n",
      "[285] loss: 2.3464162349700928\n",
      "[286] loss: 2.209968328475952\n",
      "[287] loss: 2.2254555225372314\n",
      "[288] loss: 2.4129393100738525\n",
      "[289] loss: 2.2714266777038574\n",
      "[290] loss: 2.405250310897827\n",
      "[291] loss: 2.293454170227051\n",
      "[292] loss: 2.2081410884857178\n",
      "[293] loss: 2.193089723587036\n",
      "[294] loss: 2.2334470748901367\n",
      "[295] loss: 2.3196606636047363\n",
      "[296] loss: 2.3490488529205322\n",
      "[297] loss: 2.2289884090423584\n",
      "[298] loss: 2.195855140686035\n",
      "[299] loss: 2.2363574504852295\n",
      "[300] loss: 2.2289092540740967\n",
      "[301] loss: 2.2686142921447754\n",
      "[302] loss: 2.2370243072509766\n",
      "[303] loss: 2.2602438926696777\n",
      "[304] loss: 2.3302741050720215\n",
      "[305] loss: 2.2380318641662598\n",
      "[306] loss: 2.184609889984131\n",
      "[307] loss: 2.215581178665161\n",
      "[308] loss: 2.2056984901428223\n",
      "[309] loss: 2.2154455184936523\n",
      "[310] loss: 2.194004535675049\n",
      "[311] loss: 2.2202770709991455\n",
      "[312] loss: 2.2031188011169434\n",
      "[313] loss: 2.3241770267486572\n",
      "[314] loss: 2.187737226486206\n",
      "[315] loss: 2.2763333320617676\n",
      "[316] loss: 2.21168851852417\n",
      "[317] loss: 2.260371446609497\n",
      "[318] loss: 2.190476894378662\n",
      "[319] loss: 2.185750961303711\n",
      "[320] loss: 2.1907451152801514\n",
      "[321] loss: 2.1883721351623535\n",
      "[322] loss: 2.401017665863037\n",
      "[323] loss: 2.272195816040039\n",
      "[324] loss: 2.2107057571411133\n",
      "[325] loss: 2.272608518600464\n",
      "[326] loss: 2.179673671722412\n",
      "[327] loss: 2.1304845809936523\n",
      "[328] loss: 2.173692226409912\n",
      "[329] loss: 2.1391563415527344\n",
      "[330] loss: 2.193446397781372\n",
      "[331] loss: 2.1835460662841797\n",
      "[332] loss: 2.1454079151153564\n",
      "[333] loss: 2.1313095092773438\n",
      "[334] loss: 2.16459059715271\n",
      "[335] loss: 2.216634511947632\n",
      "[336] loss: 2.1557278633117676\n",
      "[337] loss: 2.1777851581573486\n",
      "[338] loss: 2.173469066619873\n",
      "[339] loss: 2.067843198776245\n",
      "[340] loss: 2.20729398727417\n",
      "[341] loss: 2.162710189819336\n",
      "[342] loss: 2.1901276111602783\n",
      "[343] loss: 2.16456937789917\n",
      "[344] loss: 2.204089641571045\n",
      "[345] loss: 2.219968795776367\n",
      "[346] loss: 2.1146750450134277\n",
      "[347] loss: 2.078007459640503\n",
      "[348] loss: 2.1502389907836914\n",
      "[349] loss: 2.2063887119293213\n",
      "[350] loss: 2.1567394733428955\n",
      "[351] loss: 2.177224636077881\n",
      "[352] loss: 2.1653759479522705\n",
      "[353] loss: 2.224759340286255\n",
      "[354] loss: 2.190364122390747\n",
      "[355] loss: 2.1138579845428467\n",
      "[356] loss: 2.206559181213379\n",
      "[357] loss: 2.1280980110168457\n",
      "[358] loss: 2.112194776535034\n",
      "[359] loss: 2.108640432357788\n",
      "[360] loss: 2.2407898902893066\n",
      "[361] loss: 2.0708768367767334\n",
      "[362] loss: 2.1626346111297607\n",
      "[363] loss: 2.1093626022338867\n",
      "[364] loss: 2.133723735809326\n",
      "[365] loss: 2.1712489128112793\n",
      "[366] loss: 2.158691883087158\n",
      "[367] loss: 2.098497152328491\n",
      "[368] loss: 2.165252923965454\n",
      "[369] loss: 2.1597776412963867\n",
      "[370] loss: 2.0273308753967285\n",
      "[371] loss: 2.195504665374756\n",
      "[372] loss: 2.073333740234375\n",
      "[373] loss: 2.123579740524292\n",
      "[374] loss: 2.1764450073242188\n",
      "[375] loss: 2.183213710784912\n",
      "[376] loss: 2.1102681159973145\n",
      "[377] loss: 2.0280771255493164\n",
      "[378] loss: 2.0291357040405273\n",
      "[379] loss: 2.162757635116577\n",
      "[380] loss: 2.1078238487243652\n",
      "[381] loss: 2.097370147705078\n",
      "[382] loss: 2.1580135822296143\n",
      "[383] loss: 2.062730073928833\n",
      "[384] loss: 2.0815021991729736\n",
      "[385] loss: 2.0395498275756836\n",
      "[386] loss: 2.044701099395752\n",
      "[387] loss: 2.157613754272461\n",
      "[388] loss: 2.117361068725586\n",
      "[389] loss: 2.1105730533599854\n",
      "[390] loss: 2.0719287395477295\n",
      "[391] loss: 2.0636160373687744\n",
      "[392] loss: 1.986570954322815\n",
      "[393] loss: 2.089341402053833\n",
      "[394] loss: 2.0709567070007324\n",
      "[395] loss: 2.341212272644043\n",
      "[396] loss: 2.050791025161743\n",
      "[397] loss: 2.0608973503112793\n",
      "[398] loss: 2.0958704948425293\n",
      "[399] loss: 2.086059808731079\n",
      "[400] loss: 2.0078635215759277\n",
      "[401] loss: 2.104562997817993\n",
      "[402] loss: 2.302849054336548\n",
      "[403] loss: 2.0038042068481445\n",
      "[404] loss: 2.071214199066162\n",
      "[405] loss: 2.0995233058929443\n",
      "[406] loss: 2.063927412033081\n",
      "[407] loss: 2.0750937461853027\n",
      "[408] loss: 2.071910858154297\n",
      "[409] loss: 1.9680101871490479\n",
      "[410] loss: 2.113807201385498\n",
      "[411] loss: 2.0347800254821777\n",
      "[412] loss: 2.092381477355957\n",
      "[413] loss: 2.124314546585083\n",
      "[414] loss: 2.079322099685669\n",
      "[415] loss: 2.0495219230651855\n",
      "[416] loss: 2.132941961288452\n",
      "[417] loss: 2.141345262527466\n",
      "[418] loss: 2.099879264831543\n",
      "[419] loss: 2.0613322257995605\n",
      "[420] loss: 2.0453712940216064\n",
      "[421] loss: 2.063601016998291\n",
      "[422] loss: 2.0141382217407227\n",
      "[423] loss: 1.9966540336608887\n",
      "[424] loss: 2.0766074657440186\n",
      "[425] loss: 2.068275213241577\n",
      "[426] loss: 2.127075433731079\n",
      "[427] loss: 2.0931966304779053\n",
      "[428] loss: 2.0937769412994385\n",
      "[429] loss: 2.0542140007019043\n",
      "[430] loss: 2.038444995880127\n",
      "[431] loss: 2.0381312370300293\n",
      "[432] loss: 2.07528018951416\n",
      "[433] loss: 2.11028790473938\n",
      "[434] loss: 2.0665600299835205\n",
      "[435] loss: 2.01357364654541\n",
      "[436] loss: 2.1010377407073975\n",
      "[437] loss: 2.0439112186431885\n",
      "[438] loss: 2.1325843334198\n",
      "[439] loss: 2.0125153064727783\n",
      "[440] loss: 2.124084949493408\n",
      "[441] loss: 2.0030810832977295\n",
      "[442] loss: 2.1928484439849854\n",
      "[443] loss: 2.0847785472869873\n",
      "[444] loss: 2.0079896450042725\n",
      "[445] loss: 2.013310432434082\n",
      "[446] loss: 2.013413906097412\n",
      "[447] loss: 2.016986608505249\n",
      "[448] loss: 2.044267416000366\n",
      "[449] loss: 2.0407485961914062\n",
      "[450] loss: 2.118773937225342\n",
      "[451] loss: 2.1068003177642822\n",
      "[452] loss: 2.0578904151916504\n",
      "[453] loss: 2.0309269428253174\n",
      "[454] loss: 2.034376382827759\n",
      "[455] loss: 2.045090913772583\n",
      "[456] loss: 1.988224983215332\n",
      "[457] loss: 2.1843864917755127\n",
      "[458] loss: 1.973785161972046\n",
      "[459] loss: 2.10036301612854\n",
      "[460] loss: 2.10048508644104\n",
      "[461] loss: 2.033006191253662\n",
      "[462] loss: 2.122302293777466\n",
      "[463] loss: 2.0355920791625977\n",
      "[464] loss: 2.1172852516174316\n",
      "[465] loss: 2.0281004905700684\n",
      "[466] loss: 1.9986211061477661\n",
      "[467] loss: 1.989465594291687\n",
      "[468] loss: 1.9954650402069092\n",
      "[469] loss: 2.0992913246154785\n",
      "[470] loss: 1.9898865222930908\n",
      "[471] loss: 2.14988374710083\n",
      "[472] loss: 2.0816237926483154\n",
      "[473] loss: 2.0816664695739746\n",
      "[474] loss: 2.0503058433532715\n",
      "[475] loss: 2.001180648803711\n",
      "[476] loss: 1.9421007633209229\n",
      "[477] loss: 2.0821382999420166\n",
      "[478] loss: 1.9320690631866455\n",
      "[479] loss: 2.092449426651001\n",
      "[480] loss: 2.0362794399261475\n",
      "[481] loss: 1.980735421180725\n",
      "[482] loss: 2.000070095062256\n",
      "[483] loss: 2.0301787853240967\n",
      "[484] loss: 2.0288257598876953\n",
      "[485] loss: 2.1172735691070557\n",
      "[486] loss: 2.04675555229187\n",
      "[487] loss: 1.9401179552078247\n",
      "[488] loss: 2.069845676422119\n",
      "[489] loss: 1.9793118238449097\n",
      "[490] loss: 2.081393003463745\n",
      "[491] loss: 1.9526567459106445\n",
      "[492] loss: 1.968800663948059\n",
      "[493] loss: 2.0526204109191895\n",
      "[494] loss: 2.0458788871765137\n",
      "[495] loss: 2.0214269161224365\n",
      "[496] loss: 1.9395347833633423\n",
      "[497] loss: 1.975017786026001\n",
      "[498] loss: 2.06280255317688\n",
      "[499] loss: 2.0985896587371826\n",
      "[500] loss: 2.0629327297210693\n",
      "[501] loss: 2.0095622539520264\n",
      "[502] loss: 2.170232057571411\n",
      "[503] loss: 2.043365001678467\n",
      "[504] loss: 2.1409502029418945\n",
      "[505] loss: 2.0747129917144775\n",
      "[506] loss: 1.9997799396514893\n",
      "[507] loss: 2.0273597240448\n",
      "[508] loss: 2.0034024715423584\n",
      "[509] loss: 1.9931654930114746\n",
      "[510] loss: 2.022684097290039\n",
      "[511] loss: 2.042617082595825\n",
      "[512] loss: 2.0992324352264404\n",
      "[513] loss: 2.1255271434783936\n",
      "[514] loss: 2.0273561477661133\n",
      "[515] loss: 2.0847625732421875\n",
      "[516] loss: 1.9394574165344238\n",
      "[517] loss: 2.0501153469085693\n",
      "[518] loss: 2.0828301906585693\n",
      "[519] loss: 2.0051846504211426\n",
      "[520] loss: 2.000713586807251\n",
      "[521] loss: 1.9216082096099854\n",
      "[522] loss: 2.1014697551727295\n",
      "[523] loss: 1.9974950551986694\n",
      "[524] loss: 1.9953566789627075\n",
      "[525] loss: 1.9739831686019897\n",
      "[526] loss: 1.9687631130218506\n",
      "[527] loss: 2.1329402923583984\n",
      "[528] loss: 2.045102834701538\n",
      "[529] loss: 2.072166919708252\n",
      "[530] loss: 1.9357450008392334\n",
      "[531] loss: 2.0477564334869385\n",
      "[532] loss: 1.951913833618164\n",
      "[533] loss: 2.00883412361145\n",
      "[534] loss: 1.9640138149261475\n",
      "[535] loss: 2.1283552646636963\n",
      "[536] loss: 2.017332077026367\n",
      "[537] loss: 1.9540823698043823\n",
      "[538] loss: 2.1417343616485596\n",
      "[539] loss: 2.0572779178619385\n",
      "[540] loss: 2.0713353157043457\n",
      "[541] loss: 2.0529732704162598\n",
      "[542] loss: 2.0897300243377686\n",
      "[543] loss: 2.0586771965026855\n",
      "[544] loss: 1.9581317901611328\n",
      "[545] loss: 1.9465909004211426\n",
      "[546] loss: 1.9333181381225586\n",
      "[547] loss: 1.9640898704528809\n",
      "[548] loss: 2.0134716033935547\n",
      "[549] loss: 2.027693271636963\n",
      "[550] loss: 2.1162590980529785\n",
      "[551] loss: 1.9789159297943115\n",
      "[552] loss: 2.000844955444336\n",
      "[553] loss: 2.0333871841430664\n",
      "[554] loss: 1.9596116542816162\n",
      "[555] loss: 2.002845287322998\n",
      "[556] loss: 1.9392406940460205\n",
      "[557] loss: 2.0042214393615723\n",
      "[558] loss: 1.9970462322235107\n",
      "[559] loss: 1.9825974702835083\n",
      "[560] loss: 2.0357813835144043\n",
      "[561] loss: 1.9832018613815308\n",
      "[562] loss: 1.8674585819244385\n",
      "[563] loss: 1.9049969911575317\n",
      "[564] loss: 1.9025599956512451\n",
      "[565] loss: 2.1276893615722656\n",
      "[566] loss: 1.8981125354766846\n",
      "[567] loss: 1.994133472442627\n",
      "[568] loss: 2.00524640083313\n",
      "[569] loss: 1.9299670457839966\n",
      "[570] loss: 1.9554507732391357\n",
      "[571] loss: 2.083507537841797\n",
      "[572] loss: 1.9730435609817505\n",
      "[573] loss: 1.908094048500061\n",
      "[574] loss: 2.055269956588745\n",
      "[575] loss: 2.0050814151763916\n",
      "[576] loss: 2.0448172092437744\n",
      "[577] loss: 2.01997971534729\n",
      "[578] loss: 1.9631083011627197\n",
      "[579] loss: 1.9363075494766235\n",
      "[580] loss: 1.919586420059204\n",
      "[581] loss: 1.944372534751892\n",
      "[582] loss: 2.097085952758789\n",
      "[583] loss: 1.9549330472946167\n",
      "[584] loss: 1.9705913066864014\n",
      "[585] loss: 2.0001327991485596\n",
      "[586] loss: 1.9257299900054932\n",
      "[587] loss: 2.001044750213623\n",
      "[588] loss: 1.9799646139144897\n",
      "[589] loss: 2.0688416957855225\n",
      "[590] loss: 2.011306047439575\n",
      "[591] loss: 1.8147104978561401\n",
      "[592] loss: 1.9640218019485474\n",
      "[593] loss: 2.1248795986175537\n",
      "[594] loss: 1.9597558975219727\n",
      "[595] loss: 2.0712947845458984\n",
      "[596] loss: 2.073038101196289\n",
      "[597] loss: 1.981516718864441\n",
      "[598] loss: 1.933029294013977\n",
      "[599] loss: 1.978926420211792\n",
      "[600] loss: 1.9195493459701538\n",
      "[601] loss: 1.968776822090149\n",
      "[602] loss: 2.013035297393799\n",
      "[603] loss: 1.9728460311889648\n",
      "[604] loss: 1.9433448314666748\n",
      "[605] loss: 1.9485920667648315\n",
      "[606] loss: 1.9263352155685425\n",
      "[607] loss: 1.9105894565582275\n",
      "[608] loss: 1.861029028892517\n",
      "[609] loss: 1.8605396747589111\n",
      "[610] loss: 1.9824150800704956\n",
      "[611] loss: 2.0790226459503174\n",
      "[612] loss: 1.9654736518859863\n",
      "[613] loss: 1.9655957221984863\n",
      "[614] loss: 2.006817579269409\n",
      "[615] loss: 1.9599086046218872\n",
      "[616] loss: 1.927910327911377\n",
      "[617] loss: 2.0023419857025146\n",
      "[618] loss: 1.8945412635803223\n",
      "[619] loss: 1.9536585807800293\n",
      "[620] loss: 2.0130629539489746\n",
      "[621] loss: 1.9027373790740967\n",
      "[622] loss: 2.048584222793579\n",
      "[623] loss: 2.1029343605041504\n",
      "[624] loss: 1.8958477973937988\n",
      "[625] loss: 1.86451256275177\n",
      "[626] loss: 1.9618070125579834\n",
      "[627] loss: 2.0206212997436523\n",
      "[628] loss: 2.0157699584960938\n",
      "[629] loss: 2.019859790802002\n",
      "[630] loss: 2.0611965656280518\n",
      "[631] loss: 2.037942886352539\n",
      "[632] loss: 1.9219694137573242\n",
      "[633] loss: 2.012936592102051\n",
      "[634] loss: 1.9935975074768066\n",
      "[635] loss: 1.9991909265518188\n",
      "[636] loss: 1.9089443683624268\n",
      "[637] loss: 2.0514392852783203\n",
      "[638] loss: 2.0280492305755615\n",
      "[639] loss: 2.0005412101745605\n",
      "[640] loss: 2.018832206726074\n",
      "[641] loss: 1.9165966510772705\n",
      "[642] loss: 1.9688204526901245\n",
      "[643] loss: 1.9552921056747437\n",
      "[644] loss: 2.0215182304382324\n",
      "[645] loss: 1.9941542148590088\n",
      "[646] loss: 1.9969942569732666\n",
      "[647] loss: 2.006981611251831\n",
      "[648] loss: 1.9724558591842651\n",
      "[649] loss: 1.9833091497421265\n",
      "[650] loss: 1.8999789953231812\n",
      "[651] loss: 2.050933599472046\n",
      "[652] loss: 1.8744221925735474\n",
      "[653] loss: 1.990308403968811\n",
      "[654] loss: 1.8947635889053345\n",
      "[655] loss: 1.9269115924835205\n",
      "[656] loss: 1.956989049911499\n",
      "[657] loss: 2.0496864318847656\n",
      "[658] loss: 1.8172942399978638\n",
      "[659] loss: 1.9653059244155884\n",
      "[660] loss: 1.8853354454040527\n",
      "[661] loss: 2.0449585914611816\n",
      "[662] loss: 1.8435086011886597\n",
      "[663] loss: 1.8644574880599976\n",
      "[664] loss: 2.0262179374694824\n",
      "[665] loss: 1.9955793619155884\n",
      "[666] loss: 1.8702573776245117\n",
      "[667] loss: 1.8549814224243164\n",
      "[668] loss: 1.964548110961914\n",
      "[669] loss: 1.9898147583007812\n",
      "[670] loss: 1.960357666015625\n",
      "[671] loss: 1.9217658042907715\n",
      "[672] loss: 1.934747576713562\n",
      "[673] loss: 1.9159255027770996\n",
      "[674] loss: 2.0134835243225098\n",
      "[675] loss: 1.8926565647125244\n",
      "[676] loss: 1.8830957412719727\n",
      "[677] loss: 1.9349393844604492\n",
      "[678] loss: 1.9334237575531006\n",
      "[679] loss: 1.906542181968689\n",
      "[680] loss: 1.9208487272262573\n",
      "[681] loss: 1.9912817478179932\n",
      "[682] loss: 1.8816583156585693\n",
      "[683] loss: 1.9179222583770752\n",
      "[684] loss: 1.9235162734985352\n",
      "[685] loss: 1.884499192237854\n",
      "[686] loss: 1.9870634078979492\n",
      "[687] loss: 1.9166501760482788\n",
      "[688] loss: 2.0213358402252197\n",
      "[689] loss: 2.0152699947357178\n",
      "[690] loss: 1.9980781078338623\n",
      "[691] loss: 1.97946298122406\n",
      "[692] loss: 1.8903093338012695\n",
      "[693] loss: 2.00994873046875\n",
      "[694] loss: 1.9193488359451294\n",
      "[695] loss: 1.8397531509399414\n",
      "[696] loss: 1.914291262626648\n",
      "[697] loss: 1.8649158477783203\n",
      "[698] loss: 1.856802225112915\n",
      "[699] loss: 1.8627727031707764\n",
      "[700] loss: 1.9101505279541016\n",
      "[701] loss: 1.9062542915344238\n",
      "[702] loss: 1.8799607753753662\n",
      "[703] loss: 1.8819998502731323\n",
      "[704] loss: 2.0085010528564453\n",
      "[705] loss: 1.8620136976242065\n",
      "[706] loss: 1.9014840126037598\n",
      "[707] loss: 1.8998488187789917\n",
      "[708] loss: 1.9307252168655396\n",
      "[709] loss: 1.9158499240875244\n",
      "[710] loss: 2.0264556407928467\n",
      "[711] loss: 2.048377513885498\n",
      "[712] loss: 1.8473094701766968\n",
      "[713] loss: 1.887344241142273\n",
      "[714] loss: 1.9243663549423218\n",
      "[715] loss: 1.919913649559021\n",
      "[716] loss: 1.9292669296264648\n",
      "[717] loss: 1.8898160457611084\n",
      "[718] loss: 1.8011634349822998\n",
      "[719] loss: 1.899765133857727\n",
      "[720] loss: 1.853055477142334\n",
      "[721] loss: 1.905570387840271\n",
      "[722] loss: 1.8273545503616333\n",
      "[723] loss: 1.91481351852417\n",
      "[724] loss: 1.797401785850525\n",
      "[725] loss: 1.9492164850234985\n",
      "[726] loss: 2.042851448059082\n",
      "[727] loss: 1.9521863460540771\n",
      "[728] loss: 2.0333590507507324\n",
      "[729] loss: 1.9553418159484863\n",
      "[730] loss: 1.9770082235336304\n",
      "[731] loss: 1.9529602527618408\n",
      "[732] loss: 1.9328324794769287\n",
      "[733] loss: 1.9413795471191406\n",
      "[734] loss: 1.8585532903671265\n",
      "[735] loss: 2.0878541469573975\n",
      "[736] loss: 1.877171277999878\n",
      "[737] loss: 2.0106377601623535\n",
      "[738] loss: 1.9652888774871826\n",
      "[739] loss: 1.876338005065918\n",
      "[740] loss: 1.8861796855926514\n",
      "[741] loss: 1.9085160493850708\n",
      "[742] loss: 1.9560954570770264\n",
      "[743] loss: 1.8103519678115845\n",
      "[744] loss: 1.9081907272338867\n",
      "[745] loss: 1.9847962856292725\n",
      "[746] loss: 1.8845651149749756\n",
      "[747] loss: 1.8952109813690186\n",
      "[748] loss: 1.8947972059249878\n",
      "[749] loss: 1.9502124786376953\n",
      "[750] loss: 1.9120490550994873\n",
      "[751] loss: 2.003995418548584\n",
      "[752] loss: 1.9382574558258057\n",
      "[753] loss: 1.8374989032745361\n",
      "[754] loss: 1.8639020919799805\n",
      "[755] loss: 1.9206585884094238\n",
      "[756] loss: 1.8852068185806274\n",
      "[757] loss: 1.981789469718933\n",
      "[758] loss: 1.9166055917739868\n",
      "[759] loss: 1.8999037742614746\n"
     ]
    }
   ],
   "source": [
    "for i in range(760):\n",
    "    loss = exp.iterate_once()\n",
    "    print(f\"[{i}] loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: batch_id:[0] | Acc@1: 26.56 | Loss: 1.938923954963684\n",
      "Training: batch_id:[20] | Acc@1: 21.54 | Loss: 2.0795178413391113\n",
      "Training: batch_id:[40] | Acc@1: 21.49 | Loss: 2.0643038749694824\n",
      "Training: batch_id:[60] | Acc@1: 21.54 | Loss: 1.9637987613677979\n",
      "Training: batch_id:[80] | Acc@1: 21.65 | Loss: 2.0018930435180664\n",
      "Training: batch_id:[100] | Acc@1: 22.06 | Loss: 1.9809231758117676\n",
      "Training: batch_id:[120] | Acc@1: 22.31 | Loss: 2.1040079593658447\n",
      "Training: batch_id:[140] | Acc@1: 22.41 | Loss: 2.0015015602111816\n",
      "Training: batch_id:[160] | Acc@1: 22.67 | Loss: 1.907214641571045\n",
      "Training: batch_id:[180] | Acc@1: 22.78 | Loss: 1.997668981552124\n",
      "Training: batch_id:[200] | Acc@1: 22.97 | Loss: 1.9010010957717896\n",
      "Training: batch_id:[220] | Acc@1: 23.14 | Loss: 1.9728494882583618\n",
      "Training: batch_id:[240] | Acc@1: 23.18 | Loss: 1.971200942993164\n",
      "Training: batch_id:[260] | Acc@1: 23.34 | Loss: 2.035740852355957\n",
      "Training: batch_id:[280] | Acc@1: 23.55 | Loss: 1.8482301235198975\n",
      "Training: batch_id:[300] | Acc@1: 23.75 | Loss: 1.9212665557861328\n",
      "Training: batch_id:[320] | Acc@1: 23.99 | Loss: 1.8172014951705933\n",
      "Training: batch_id:[340] | Acc@1: 24.21 | Loss: 1.9293136596679688\n",
      "Training: batch_id:[360] | Acc@1: 24.32 | Loss: 1.8365366458892822\n",
      "Training: batch_id:[380] | Acc@1: 24.49 | Loss: 1.8929657936096191\n",
      "Training: batch_id:[0] | Acc@1: 25.78 | Loss: 1.9597694873809814\n",
      "Training: batch_id:[20] | Acc@1: 26.97 | Loss: 1.9311740398406982\n",
      "Training: batch_id:[40] | Acc@1: 27.86 | Loss: 1.8487577438354492\n",
      "Training: batch_id:[60] | Acc@1: 27.98 | Loss: 1.9673891067504883\n",
      "Training: batch_id:[80] | Acc@1: 28.43 | Loss: 1.863991618156433\n",
      "Training: batch_id:[100] | Acc@1: 28.43 | Loss: 1.8775714635849\n",
      "Training: batch_id:[120] | Acc@1: 28.74 | Loss: 1.7601256370544434\n",
      "Training: batch_id:[140] | Acc@1: 28.96 | Loss: 1.7116217613220215\n",
      "Training: batch_id:[160] | Acc@1: 29.12 | Loss: 1.83260977268219\n",
      "Training: batch_id:[180] | Acc@1: 29.17 | Loss: 1.6986438035964966\n",
      "Training: batch_id:[200] | Acc@1: 29.23 | Loss: 1.8484547138214111\n",
      "Training: batch_id:[220] | Acc@1: 29.27 | Loss: 1.87138032913208\n",
      "Training: batch_id:[240] | Acc@1: 29.29 | Loss: 1.7694590091705322\n",
      "Training: batch_id:[260] | Acc@1: 29.40 | Loss: 1.7970341444015503\n",
      "Training: batch_id:[280] | Acc@1: 29.49 | Loss: 1.7682271003723145\n",
      "Training: batch_id:[300] | Acc@1: 29.59 | Loss: 1.8265331983566284\n",
      "Training: batch_id:[320] | Acc@1: 29.58 | Loss: 1.8953790664672852\n",
      "Training: batch_id:[340] | Acc@1: 29.89 | Loss: 1.7292400598526\n",
      "Training: batch_id:[360] | Acc@1: 30.06 | Loss: 1.5360889434814453\n",
      "Training: batch_id:[380] | Acc@1: 30.15 | Loss: 1.802080750465393\n",
      "Training: batch_id:[0] | Acc@1: 31.25 | Loss: 1.8344939947128296\n",
      "Training: batch_id:[20] | Acc@1: 34.15 | Loss: 1.6256686449050903\n",
      "Training: batch_id:[40] | Acc@1: 33.67 | Loss: 1.7254825830459595\n",
      "Training: batch_id:[60] | Acc@1: 33.38 | Loss: 1.8153610229492188\n",
      "Training: batch_id:[80] | Acc@1: 33.72 | Loss: 1.7478253841400146\n",
      "Training: batch_id:[100] | Acc@1: 33.66 | Loss: 1.8014204502105713\n",
      "Training: batch_id:[120] | Acc@1: 34.12 | Loss: 1.5787928104400635\n",
      "Training: batch_id:[140] | Acc@1: 34.39 | Loss: 1.866873025894165\n",
      "Training: batch_id:[160] | Acc@1: 34.37 | Loss: 1.7215843200683594\n",
      "Training: batch_id:[180] | Acc@1: 34.43 | Loss: 1.692723274230957\n",
      "Training: batch_id:[200] | Acc@1: 34.58 | Loss: 1.696839690208435\n",
      "Training: batch_id:[220] | Acc@1: 34.74 | Loss: 1.6684095859527588\n",
      "Training: batch_id:[240] | Acc@1: 34.86 | Loss: 1.626312494277954\n",
      "Training: batch_id:[260] | Acc@1: 34.95 | Loss: 1.6566987037658691\n",
      "Training: batch_id:[280] | Acc@1: 35.10 | Loss: 1.6149404048919678\n",
      "Training: batch_id:[300] | Acc@1: 35.17 | Loss: 1.591256856918335\n",
      "Training: batch_id:[320] | Acc@1: 35.26 | Loss: 1.782387614250183\n",
      "Training: batch_id:[340] | Acc@1: 35.34 | Loss: 1.5602936744689941\n",
      "Training: batch_id:[360] | Acc@1: 35.42 | Loss: 1.6668754816055298\n",
      "Training: batch_id:[380] | Acc@1: 35.64 | Loss: 1.614813208580017\n",
      "Training: batch_id:[0] | Acc@1: 40.62 | Loss: 1.5834136009216309\n",
      "Training: batch_id:[20] | Acc@1: 39.32 | Loss: 1.4598352909088135\n",
      "Training: batch_id:[40] | Acc@1: 40.15 | Loss: 1.4524229764938354\n",
      "Training: batch_id:[60] | Acc@1: 40.27 | Loss: 1.6216398477554321\n",
      "Training: batch_id:[80] | Acc@1: 40.07 | Loss: 1.539604902267456\n",
      "Training: batch_id:[100] | Acc@1: 40.09 | Loss: 1.4419608116149902\n",
      "Training: batch_id:[120] | Acc@1: 40.23 | Loss: 1.7316457033157349\n",
      "Training: batch_id:[140] | Acc@1: 40.62 | Loss: 1.5776318311691284\n",
      "Training: batch_id:[160] | Acc@1: 40.58 | Loss: 1.5782999992370605\n",
      "Training: batch_id:[180] | Acc@1: 40.70 | Loss: 1.5987526178359985\n",
      "Training: batch_id:[200] | Acc@1: 40.73 | Loss: 1.5496599674224854\n",
      "Training: batch_id:[220] | Acc@1: 40.87 | Loss: 1.3805397748947144\n",
      "Training: batch_id:[240] | Acc@1: 40.90 | Loss: 1.5963565111160278\n",
      "Training: batch_id:[260] | Acc@1: 41.00 | Loss: 1.5582247972488403\n",
      "Training: batch_id:[280] | Acc@1: 41.24 | Loss: 1.4466173648834229\n",
      "Training: batch_id:[300] | Acc@1: 41.30 | Loss: 1.6061464548110962\n",
      "Training: batch_id:[320] | Acc@1: 41.27 | Loss: 1.4051775932312012\n",
      "Training: batch_id:[340] | Acc@1: 41.47 | Loss: 1.6926195621490479\n",
      "Training: batch_id:[360] | Acc@1: 41.59 | Loss: 1.52372145652771\n",
      "Training: batch_id:[380] | Acc@1: 41.80 | Loss: 1.4311387538909912\n",
      "Training: batch_id:[0] | Acc@1: 42.97 | Loss: 1.4762747287750244\n",
      "Training: batch_id:[20] | Acc@1: 46.43 | Loss: 1.4545973539352417\n",
      "Training: batch_id:[40] | Acc@1: 46.46 | Loss: 1.533677339553833\n",
      "Training: batch_id:[60] | Acc@1: 45.26 | Loss: 1.457270860671997\n",
      "Training: batch_id:[80] | Acc@1: 45.31 | Loss: 1.3537158966064453\n",
      "Training: batch_id:[100] | Acc@1: 45.58 | Loss: 1.383939504623413\n",
      "Training: batch_id:[120] | Acc@1: 45.69 | Loss: 1.324155330657959\n",
      "Training: batch_id:[140] | Acc@1: 45.81 | Loss: 1.5708379745483398\n",
      "Training: batch_id:[160] | Acc@1: 46.06 | Loss: 1.572167992591858\n",
      "Training: batch_id:[180] | Acc@1: 46.10 | Loss: 1.1410049200057983\n",
      "Training: batch_id:[200] | Acc@1: 46.33 | Loss: 1.2954891920089722\n",
      "Training: batch_id:[220] | Acc@1: 46.48 | Loss: 1.3144654035568237\n",
      "Training: batch_id:[240] | Acc@1: 46.71 | Loss: 1.3140219449996948\n",
      "Training: batch_id:[260] | Acc@1: 46.82 | Loss: 1.36360764503479\n",
      "Training: batch_id:[280] | Acc@1: 46.91 | Loss: 1.2812073230743408\n",
      "Training: batch_id:[300] | Acc@1: 47.11 | Loss: 1.4819759130477905\n",
      "Training: batch_id:[320] | Acc@1: 47.22 | Loss: 1.3833177089691162\n",
      "Training: batch_id:[340] | Acc@1: 47.26 | Loss: 1.4462260007858276\n",
      "Training: batch_id:[360] | Acc@1: 47.31 | Loss: 1.3626205921173096\n",
      "Training: batch_id:[380] | Acc@1: 47.47 | Loss: 1.4036682844161987\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    exp.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5723, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = exp.sample_forward()\n",
    "print(loss)\n",
    "exp.backward(loss)\n",
    "exp.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "backward() missing 1 required positional argument: 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/private/home/riohib/testing/gsp-for-deeplearning/cifar/compression.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdevfair/private/home/riohib/testing/gsp-for-deeplearning/cifar/compression.ipynb#ch0000088vscode-remote?line=0'>1</a>\u001b[0m exp\u001b[39m.\u001b[39;49mbackward()\n",
      "\u001b[0;31mTypeError\u001b[0m: backward() missing 1 required positional argument: 'loss'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n",
      "Setting to train mode\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    exp.iterate_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_d = dict()\n",
    "for name, params in exp.model.named_parameters():\n",
    "    params_d[name] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module.features.0.weight': Parameter containing:\n",
       " tensor([[[[ 0.1759, -0.0015,  0.0382],\n",
       "           [-0.0113,  0.0736, -0.0569],\n",
       "           [ 0.0417,  0.0545, -0.0611]],\n",
       " \n",
       "          [[-0.0418, -0.0942, -0.0136],\n",
       "           [ 0.1758, -0.0062,  0.0290],\n",
       "           [ 0.0151,  0.0022,  0.0441]],\n",
       " \n",
       "          [[ 0.0153, -0.0438,  0.0523],\n",
       "           [ 0.0268, -0.0200,  0.0332],\n",
       "           [ 0.0451,  0.0590, -0.0263]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0064, -0.0202,  0.0373],\n",
       "           [-0.0789, -0.1407,  0.0120],\n",
       "           [ 0.0401,  0.0815,  0.0572]],\n",
       " \n",
       "          [[ 0.1374,  0.0087, -0.0596],\n",
       "           [ 0.0080, -0.0809, -0.2124],\n",
       "           [-0.0584,  0.0580, -0.0757]],\n",
       " \n",
       "          [[-0.1096, -0.0294,  0.0258],\n",
       "           [ 0.0101, -0.0099,  0.0276],\n",
       "           [-0.0332,  0.0481,  0.0646]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0080,  0.0292,  0.0222],\n",
       "           [-0.0299, -0.0185, -0.1320],\n",
       "           [ 0.0155,  0.0494,  0.0325]],\n",
       " \n",
       "          [[ 0.0109, -0.0619, -0.0642],\n",
       "           [-0.0409,  0.0621, -0.0045],\n",
       "           [-0.0947, -0.1041,  0.0384]],\n",
       " \n",
       "          [[ 0.0335, -0.0768,  0.0386],\n",
       "           [ 0.0967,  0.0171,  0.0685],\n",
       "           [ 0.0132,  0.0230, -0.2062]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0650,  0.0648, -0.0260],\n",
       "           [ 0.0181,  0.0157, -0.0315],\n",
       "           [ 0.0329, -0.0976,  0.0090]],\n",
       " \n",
       "          [[ 0.0189, -0.0577,  0.0107],\n",
       "           [ 0.0844, -0.0013, -0.0938],\n",
       "           [ 0.0289, -0.0191, -0.1254]],\n",
       " \n",
       "          [[-0.0231, -0.1592, -0.0916],\n",
       "           [-0.0029, -0.0321, -0.0916],\n",
       "           [ 0.0016, -0.0131, -0.0741]]],\n",
       " \n",
       " \n",
       "         [[[-0.0073, -0.0013,  0.0151],\n",
       "           [-0.0799, -0.0585,  0.0399],\n",
       "           [ 0.0092,  0.0041, -0.0644]],\n",
       " \n",
       "          [[ 0.0039, -0.0721,  0.1148],\n",
       "           [-0.0354, -0.0414,  0.0249],\n",
       "           [ 0.1059, -0.1065, -0.0300]],\n",
       " \n",
       "          [[ 0.0869,  0.0812,  0.0508],\n",
       "           [ 0.0827,  0.0671,  0.0363],\n",
       "           [ 0.0470,  0.0291,  0.0171]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0162,  0.0402, -0.0676],\n",
       "           [-0.0358,  0.0725,  0.0058],\n",
       "           [ 0.0404,  0.0370,  0.0014]],\n",
       " \n",
       "          [[ 0.0581,  0.0079, -0.0048],\n",
       "           [ 0.1102, -0.0429, -0.0754],\n",
       "           [-0.0394, -0.0467, -0.0141]],\n",
       " \n",
       "          [[-0.0584,  0.0245,  0.0085],\n",
       "           [ 0.0449, -0.0031,  0.0388],\n",
       "           [ 0.0092,  0.1011,  0.0005]]]], device='cuda:0', requires_grad=True),\n",
       " 'module.features.0.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.1.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.1.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.3.weight': Parameter containing:\n",
       " tensor([[[[-1.1147e-02, -3.4487e-02,  1.8303e-02],\n",
       "           [-1.2585e-02,  6.1629e-03, -3.1956e-02],\n",
       "           [-1.8334e-02, -6.6400e-02, -5.0645e-02]],\n",
       " \n",
       "          [[ 9.5871e-03,  1.0012e-01, -1.0203e-01],\n",
       "           [ 9.4668e-02,  8.3009e-03,  5.1956e-02],\n",
       "           [-7.7628e-03,  3.7404e-02, -1.6667e-04]],\n",
       " \n",
       "          [[-5.8285e-02, -7.1831e-02,  1.0547e-01],\n",
       "           [-3.3899e-02, -3.7071e-02, -5.8059e-02],\n",
       "           [ 2.9988e-02,  7.0843e-02,  9.6397e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.1524e-03,  5.5569e-02,  3.0474e-02],\n",
       "           [ 4.6778e-03,  1.0173e-01,  5.9731e-02],\n",
       "           [ 7.3309e-02, -2.3524e-02, -1.2888e-02]],\n",
       " \n",
       "          [[-3.3760e-03,  9.7462e-03, -3.4002e-02],\n",
       "           [ 1.6224e-01, -4.9879e-03, -3.1614e-02],\n",
       "           [-1.8776e-02, -2.3721e-02, -2.4966e-02]],\n",
       " \n",
       "          [[ 2.1374e-02, -1.1397e-01, -2.8300e-02],\n",
       "           [ 5.1493e-02, -2.2115e-02,  9.6011e-02],\n",
       "           [-4.8335e-02, -4.2277e-02, -3.1855e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.1467e-03,  8.7837e-02, -7.1356e-02],\n",
       "           [ 5.5467e-02, -1.9559e-02, -3.8715e-02],\n",
       "           [ 7.1182e-02,  2.2913e-02, -4.3346e-02]],\n",
       " \n",
       "          [[ 8.3318e-02, -2.1679e-02,  8.8369e-02],\n",
       "           [-1.2271e-02,  8.0854e-02,  1.9844e-03],\n",
       "           [ 1.1282e-02,  1.4530e-03, -9.1365e-03]],\n",
       " \n",
       "          [[-4.2285e-02, -7.6481e-02, -4.1539e-02],\n",
       "           [-3.7854e-02,  1.7511e-02,  3.9968e-06],\n",
       "           [ 1.9769e-02, -6.4267e-02,  8.8520e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.3705e-02,  6.0416e-02,  3.9100e-03],\n",
       "           [ 3.2474e-02,  1.1949e-02, -3.1231e-02],\n",
       "           [-1.9182e-02,  7.0026e-02, -2.4935e-02]],\n",
       " \n",
       "          [[-8.7169e-02, -8.3203e-02, -1.2487e-02],\n",
       "           [-6.9263e-03, -3.0717e-02, -3.8193e-02],\n",
       "           [-9.2669e-03,  3.2503e-03,  5.8636e-02]],\n",
       " \n",
       "          [[-3.9480e-02, -4.5573e-02, -2.1602e-02],\n",
       "           [-1.3503e-02, -8.7644e-02,  1.1929e-02],\n",
       "           [-7.1275e-03, -1.3999e-02, -4.8489e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.0090e-02,  4.1190e-02,  8.1487e-02],\n",
       "           [-7.4152e-02,  1.5198e-02,  8.9604e-02],\n",
       "           [-8.0653e-04, -2.9613e-02, -8.3616e-02]],\n",
       " \n",
       "          [[ 7.2350e-03,  1.3713e-02, -6.4524e-02],\n",
       "           [ 1.3819e-01,  4.6003e-02, -4.1807e-03],\n",
       "           [ 5.8910e-03,  9.3702e-02,  1.3397e-02]],\n",
       " \n",
       "          [[ 7.8410e-02, -3.6654e-02, -5.8568e-03],\n",
       "           [-8.3915e-03,  3.0162e-02,  4.8774e-02],\n",
       "           [-7.8436e-02, -4.2476e-02, -1.6928e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.2724e-02, -3.9232e-02, -9.1869e-02],\n",
       "           [-2.5508e-02, -5.8942e-02, -6.8673e-02],\n",
       "           [-1.1364e-02,  3.5990e-02, -7.5121e-02]],\n",
       " \n",
       "          [[-2.1575e-02,  3.0185e-02,  2.1010e-03],\n",
       "           [ 3.0305e-02,  3.3409e-02, -7.1541e-02],\n",
       "           [ 6.6747e-02, -2.9012e-02, -9.4983e-02]],\n",
       " \n",
       "          [[ 5.3911e-02,  9.5608e-04, -8.8422e-02],\n",
       "           [-7.9087e-02, -7.5943e-02,  6.9186e-02],\n",
       "           [-5.0055e-03,  5.6283e-02,  1.4501e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-8.4980e-03, -4.6040e-02,  1.5437e-02],\n",
       "           [-7.9156e-03,  1.7252e-01,  7.9664e-02],\n",
       "           [ 8.7525e-03,  5.6909e-02,  5.3099e-02]],\n",
       " \n",
       "          [[-4.0301e-02, -6.1446e-02,  2.4762e-02],\n",
       "           [ 2.9513e-02, -3.8634e-02, -1.1590e-02],\n",
       "           [ 3.4619e-02,  5.7432e-02, -5.9482e-02]],\n",
       " \n",
       "          [[-5.7460e-02, -1.0708e-02, -5.3429e-02],\n",
       "           [ 9.6814e-02, -2.1719e-03, -2.5854e-02],\n",
       "           [ 4.4289e-02,  1.0318e-02, -2.0183e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0160e-02,  1.9728e-01, -3.2957e-03],\n",
       "           [ 1.2156e-02,  2.5250e-02, -1.0907e-02],\n",
       "           [-5.7476e-04,  2.4692e-02, -3.3651e-02]],\n",
       " \n",
       "          [[ 6.0582e-06,  1.0053e-01,  9.4475e-03],\n",
       "           [ 4.4884e-02, -1.0895e-01, -5.8345e-02],\n",
       "           [-1.9039e-02,  2.3113e-02,  7.9460e-02]],\n",
       " \n",
       "          [[-4.1937e-02,  4.8669e-02, -2.2092e-02],\n",
       "           [-1.0606e-03,  1.5233e-02,  5.8195e-02],\n",
       "           [-6.8871e-03,  1.6664e-02, -7.1215e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.7542e-03,  3.6824e-03, -5.6360e-02],\n",
       "           [ 2.0258e-02,  7.3006e-02,  2.9413e-02],\n",
       "           [-7.5606e-02,  9.7284e-03,  3.6400e-02]],\n",
       " \n",
       "          [[ 2.0568e-02, -5.1651e-02,  1.1360e-02],\n",
       "           [-2.7028e-02,  6.5798e-02, -2.0227e-02],\n",
       "           [ 1.0932e-03,  2.1346e-02,  1.1051e-01]],\n",
       " \n",
       "          [[-8.6784e-02, -4.1420e-02, -7.3278e-02],\n",
       "           [-2.7173e-03,  5.3747e-02,  4.1393e-02],\n",
       "           [ 1.3457e-01, -1.2092e-02, -3.3104e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.1481e-02,  1.5489e-02,  2.6220e-02],\n",
       "           [-4.4460e-03,  4.1153e-02,  2.6108e-02],\n",
       "           [ 6.1551e-02, -1.2305e-01, -5.8019e-02]],\n",
       " \n",
       "          [[-4.0592e-02,  2.3959e-02,  1.4380e-01],\n",
       "           [-7.7871e-02, -4.2079e-02,  8.7617e-03],\n",
       "           [-3.8961e-02,  4.8944e-02,  4.5322e-03]],\n",
       " \n",
       "          [[ 2.2049e-02,  5.7339e-02,  3.5296e-02],\n",
       "           [ 4.5675e-02,  7.0899e-02, -1.0161e-01],\n",
       "           [ 5.6386e-02, -3.8891e-02, -6.9329e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.8494e-02, -1.1971e-02,  3.2497e-02],\n",
       "           [ 9.3493e-03, -1.3734e-01,  5.6575e-02],\n",
       "           [ 2.1646e-02,  1.2095e-01,  4.7232e-02]],\n",
       " \n",
       "          [[-1.9416e-02,  1.8750e-03,  3.3058e-02],\n",
       "           [ 1.4550e-02, -5.9130e-02, -1.6094e-02],\n",
       "           [-6.4203e-02, -9.6741e-02,  1.3442e-02]],\n",
       " \n",
       "          [[ 4.6668e-02, -7.9607e-03, -2.5212e-02],\n",
       "           [-9.1543e-02, -6.8119e-02,  9.6019e-02],\n",
       "           [-1.1159e-02, -2.5369e-02,  1.3847e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.1947e-02,  6.5590e-02, -3.2404e-02],\n",
       "           [ 1.0954e-01, -6.0773e-03,  2.4652e-02],\n",
       "           [ 2.3618e-02, -1.5547e-01,  3.8246e-03]],\n",
       " \n",
       "          [[-1.3015e-01,  1.8815e-02,  3.9548e-02],\n",
       "           [-9.3742e-02, -4.4667e-02, -5.2096e-02],\n",
       "           [-2.9393e-02,  3.2029e-02,  3.1761e-02]],\n",
       " \n",
       "          [[-1.1233e-03, -1.4929e-02,  9.8439e-02],\n",
       "           [-5.7749e-02,  4.4051e-02, -1.7933e-02],\n",
       "           [ 6.5680e-03,  1.2747e-01,  5.2608e-02]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.3.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.4.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.4.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.7.weight': Parameter containing:\n",
       " tensor([[[[-0.0542, -0.0975, -0.0258],\n",
       "           [-0.0260, -0.0122, -0.0046],\n",
       "           [ 0.0595,  0.0113, -0.0265]],\n",
       " \n",
       "          [[-0.0255, -0.0407, -0.0487],\n",
       "           [ 0.0529,  0.0339,  0.0396],\n",
       "           [-0.0413, -0.0062,  0.0711]],\n",
       " \n",
       "          [[ 0.0514, -0.0545, -0.0516],\n",
       "           [ 0.0537,  0.0391, -0.0145],\n",
       "           [ 0.1040,  0.0116, -0.0325]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0408,  0.0110,  0.0080],\n",
       "           [-0.0341,  0.0240, -0.0157],\n",
       "           [ 0.0136, -0.0732,  0.0878]],\n",
       " \n",
       "          [[-0.0070, -0.0611, -0.0480],\n",
       "           [ 0.0534, -0.0608, -0.0568],\n",
       "           [ 0.0368, -0.0477,  0.0493]],\n",
       " \n",
       "          [[ 0.0057,  0.0214, -0.0260],\n",
       "           [ 0.0773,  0.0723,  0.0490],\n",
       "           [-0.0232, -0.0603,  0.0066]]],\n",
       " \n",
       " \n",
       "         [[[-0.0240, -0.0214,  0.0098],\n",
       "           [-0.0030, -0.0213,  0.0070],\n",
       "           [ 0.0055, -0.0403, -0.0007]],\n",
       " \n",
       "          [[ 0.0017,  0.0069, -0.0118],\n",
       "           [-0.0159, -0.0354, -0.0136],\n",
       "           [ 0.0662, -0.0028,  0.0558]],\n",
       " \n",
       "          [[-0.0490,  0.0429, -0.0049],\n",
       "           [-0.0120, -0.0062,  0.0221],\n",
       "           [ 0.0497, -0.0159, -0.0885]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0756, -0.0289, -0.0201],\n",
       "           [-0.0349, -0.0189,  0.0024],\n",
       "           [ 0.0262, -0.0245, -0.0669]],\n",
       " \n",
       "          [[ 0.0503, -0.0112, -0.0440],\n",
       "           [ 0.0455, -0.0492, -0.0201],\n",
       "           [ 0.0399,  0.0064, -0.0168]],\n",
       " \n",
       "          [[-0.0530, -0.0473,  0.0386],\n",
       "           [ 0.0586,  0.0025, -0.0614],\n",
       "           [-0.0203, -0.0098, -0.0238]]],\n",
       " \n",
       " \n",
       "         [[[-0.0305,  0.0246, -0.0132],\n",
       "           [-0.0301, -0.0140,  0.0513],\n",
       "           [ 0.0465, -0.0315,  0.0598]],\n",
       " \n",
       "          [[-0.0217, -0.0335, -0.0587],\n",
       "           [-0.0083, -0.0214,  0.0151],\n",
       "           [-0.0355,  0.0559, -0.0548]],\n",
       " \n",
       "          [[-0.0486, -0.0445, -0.0672],\n",
       "           [-0.0523, -0.0479,  0.0529],\n",
       "           [ 0.0176, -0.0358,  0.0369]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0458, -0.0209,  0.0591],\n",
       "           [ 0.0533,  0.0615, -0.0202],\n",
       "           [-0.0419, -0.0302, -0.0260]],\n",
       " \n",
       "          [[-0.0548,  0.0273,  0.0456],\n",
       "           [-0.0146, -0.0006,  0.0707],\n",
       "           [-0.0248, -0.0130,  0.0030]],\n",
       " \n",
       "          [[ 0.0386,  0.0070,  0.0303],\n",
       "           [ 0.0113, -0.0175, -0.0085],\n",
       "           [ 0.0713,  0.0351, -0.0232]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0428, -0.0452,  0.1314],\n",
       "           [-0.0376, -0.0065,  0.0185],\n",
       "           [-0.0466, -0.0418,  0.0041]],\n",
       " \n",
       "          [[ 0.1012, -0.0458,  0.0358],\n",
       "           [-0.0895, -0.0271, -0.0043],\n",
       "           [ 0.0189, -0.0573, -0.0467]],\n",
       " \n",
       "          [[ 0.0126, -0.0140,  0.0009],\n",
       "           [ 0.0319,  0.0113, -0.0218],\n",
       "           [-0.0637,  0.0648,  0.0363]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0219, -0.0576, -0.0365],\n",
       "           [ 0.0849,  0.0156, -0.0212],\n",
       "           [-0.0112,  0.0221,  0.0340]],\n",
       " \n",
       "          [[-0.0200,  0.0038, -0.0007],\n",
       "           [-0.0159,  0.0037, -0.0275],\n",
       "           [ 0.0082, -0.0204,  0.0570]],\n",
       " \n",
       "          [[ 0.0062,  0.0393, -0.0141],\n",
       "           [-0.0128, -0.0187,  0.0244],\n",
       "           [ 0.0021,  0.0350,  0.0192]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0244,  0.0338,  0.0375],\n",
       "           [ 0.0126,  0.0058, -0.0156],\n",
       "           [-0.0198,  0.0320, -0.0325]],\n",
       " \n",
       "          [[ 0.0252, -0.0464,  0.0417],\n",
       "           [ 0.0116, -0.0320, -0.0436],\n",
       "           [ 0.0549,  0.0094, -0.0090]],\n",
       " \n",
       "          [[ 0.0835, -0.0208, -0.0041],\n",
       "           [-0.0305, -0.0509,  0.0420],\n",
       "           [-0.0180,  0.0259, -0.0556]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0415, -0.0318, -0.0364],\n",
       "           [ 0.0164,  0.0191,  0.0614],\n",
       "           [-0.0401, -0.1027, -0.0311]],\n",
       " \n",
       "          [[ 0.0070,  0.0334, -0.1093],\n",
       "           [-0.0700,  0.0914,  0.0070],\n",
       "           [-0.0614, -0.0286,  0.0042]],\n",
       " \n",
       "          [[-0.0356, -0.0360, -0.0115],\n",
       "           [ 0.0414,  0.0357,  0.0090],\n",
       "           [ 0.0919,  0.0374, -0.0504]]],\n",
       " \n",
       " \n",
       "         [[[-0.1060,  0.0067, -0.0106],\n",
       "           [ 0.0037,  0.0408,  0.0035],\n",
       "           [-0.0381,  0.0719, -0.0146]],\n",
       " \n",
       "          [[ 0.0756, -0.0104, -0.0041],\n",
       "           [-0.0493, -0.0301,  0.0323],\n",
       "           [ 0.0445,  0.0019,  0.0668]],\n",
       " \n",
       "          [[-0.0272, -0.0048,  0.0460],\n",
       "           [-0.0703, -0.0038,  0.0110],\n",
       "           [ 0.0222,  0.0495,  0.0074]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0040,  0.0026, -0.0280],\n",
       "           [ 0.0682,  0.0825, -0.0758],\n",
       "           [-0.0762,  0.0111,  0.0318]],\n",
       " \n",
       "          [[-0.0624, -0.0334, -0.0082],\n",
       "           [ 0.0730,  0.0128, -0.0526],\n",
       "           [ 0.0055, -0.0251,  0.0039]],\n",
       " \n",
       "          [[-0.0022, -0.0783, -0.0437],\n",
       "           [ 0.0223,  0.0412, -0.0197],\n",
       "           [ 0.0349,  0.0402, -0.0326]]]], device='cuda:0', requires_grad=True),\n",
       " 'module.features.7.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.8.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.8.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.10.weight': Parameter containing:\n",
       " tensor([[[[-3.6681e-02, -2.6720e-02, -1.0865e-02],\n",
       "           [-4.6137e-02,  4.5384e-02,  7.3668e-03],\n",
       "           [-6.3453e-02, -6.0517e-02,  8.7054e-02]],\n",
       " \n",
       "          [[-6.4444e-02,  4.6766e-02, -1.8975e-02],\n",
       "           [ 3.1628e-03, -5.3928e-03,  9.1275e-03],\n",
       "           [ 2.9852e-02, -5.4732e-03, -3.3942e-02]],\n",
       " \n",
       "          [[-2.0990e-02,  9.5976e-02, -7.7054e-03],\n",
       "           [ 2.2512e-02, -2.6395e-03,  3.5510e-03],\n",
       "           [-1.5808e-03,  1.4165e-02,  1.0818e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.0483e-02,  2.2792e-02, -2.3349e-02],\n",
       "           [ 8.0382e-04,  4.1553e-02, -3.5244e-02],\n",
       "           [-2.7583e-02, -4.5346e-02,  5.4534e-02]],\n",
       " \n",
       "          [[ 4.2799e-02,  2.4406e-02,  1.0240e-02],\n",
       "           [-4.3688e-03, -5.2339e-02, -2.3885e-02],\n",
       "           [ 1.1884e-02,  3.4463e-02, -1.4623e-02]],\n",
       " \n",
       "          [[ 5.4785e-02,  1.4380e-02,  6.6940e-02],\n",
       "           [ 5.5373e-02, -1.5892e-02,  7.7096e-02],\n",
       "           [ 1.0524e-01,  2.6945e-03,  1.0404e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.2073e-02,  4.2111e-02,  3.2201e-02],\n",
       "           [ 8.7994e-02, -2.3564e-02,  2.8286e-03],\n",
       "           [-3.0595e-02, -1.5443e-03,  7.0294e-02]],\n",
       " \n",
       "          [[-2.7230e-02,  3.9063e-02,  1.1236e-03],\n",
       "           [ 2.4314e-02, -8.6023e-03,  5.6818e-02],\n",
       "           [ 1.7542e-02, -4.5235e-02,  7.5332e-02]],\n",
       " \n",
       "          [[ 6.1893e-03, -3.0860e-02, -4.1818e-03],\n",
       "           [ 7.9068e-02,  1.9719e-02,  2.5607e-02],\n",
       "           [ 9.7975e-03,  4.0538e-02,  1.1017e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.1305e-02, -3.6467e-02, -3.8971e-02],\n",
       "           [ 6.4002e-02, -1.5448e-02, -4.7153e-02],\n",
       "           [ 9.7251e-02,  2.2640e-02, -2.2568e-02]],\n",
       " \n",
       "          [[-3.6908e-02, -1.7299e-02, -3.1174e-02],\n",
       "           [ 9.7078e-03,  6.2362e-02,  3.0550e-02],\n",
       "           [ 7.5386e-03, -6.3334e-02,  6.7967e-02]],\n",
       " \n",
       "          [[ 4.5270e-02, -4.8306e-02,  2.8570e-03],\n",
       "           [-3.3265e-02, -1.6709e-02, -8.4363e-03],\n",
       "           [-6.4120e-02,  6.7066e-02, -1.1767e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.7828e-02,  5.5591e-02, -2.2432e-02],\n",
       "           [-5.6633e-02,  1.1061e-02,  3.0391e-02],\n",
       "           [-2.7508e-02, -7.0808e-03,  9.5530e-02]],\n",
       " \n",
       "          [[-2.9188e-02, -4.2933e-02, -2.7315e-02],\n",
       "           [-1.7489e-02, -6.5849e-02, -4.9000e-02],\n",
       "           [ 1.3504e-02,  2.1680e-02,  5.0982e-02]],\n",
       " \n",
       "          [[ 3.4412e-02,  2.0522e-02, -4.1040e-02],\n",
       "           [ 1.4908e-02, -7.5839e-02,  5.7166e-02],\n",
       "           [ 1.0585e-02, -2.5624e-02,  1.5480e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.6913e-02, -2.7619e-02, -3.3673e-02],\n",
       "           [-4.3319e-02,  2.4899e-02,  2.1496e-02],\n",
       "           [-1.0051e-02, -2.6117e-02, -6.4997e-02]],\n",
       " \n",
       "          [[-5.0846e-02, -9.0294e-02, -1.7135e-02],\n",
       "           [-6.0506e-02, -2.8236e-02,  3.0463e-02],\n",
       "           [ 1.9175e-02,  4.1916e-02,  4.3531e-02]],\n",
       " \n",
       "          [[-5.2036e-03, -8.8863e-02,  2.2703e-02],\n",
       "           [-1.2063e-02,  2.7922e-02, -5.7427e-02],\n",
       "           [ 3.8865e-02,  1.2764e-01, -7.2027e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.5979e-02,  5.3786e-03, -4.4428e-02],\n",
       "           [ 7.3800e-02, -3.2384e-02, -3.3919e-02],\n",
       "           [-2.8600e-02,  2.7101e-02, -7.8579e-03]],\n",
       " \n",
       "          [[ 3.5536e-02, -5.7610e-02, -3.1712e-02],\n",
       "           [ 5.9960e-02,  1.2096e-02,  1.3968e-01],\n",
       "           [-1.0443e-02, -4.5365e-02,  2.5755e-02]],\n",
       " \n",
       "          [[ 4.5724e-03, -5.1411e-02, -1.3470e-02],\n",
       "           [-8.7975e-03, -8.7075e-03,  1.6296e-02],\n",
       "           [-3.9218e-02, -3.5119e-03, -1.9779e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7297e-02,  9.5928e-04, -4.0478e-02],\n",
       "           [-4.5765e-02, -1.2066e-01,  6.3492e-03],\n",
       "           [ 3.9074e-02,  4.0535e-02,  9.7371e-03]],\n",
       " \n",
       "          [[-2.4759e-02, -1.7283e-02, -1.7340e-03],\n",
       "           [ 4.9668e-03, -2.3950e-02, -9.9975e-04],\n",
       "           [-2.7845e-02, -3.4091e-02,  1.8126e-02]],\n",
       " \n",
       "          [[ 8.9208e-03,  7.3214e-02, -8.2842e-03],\n",
       "           [ 2.1830e-03,  8.3915e-03,  4.9084e-02],\n",
       "           [ 1.3167e-01, -3.4216e-02, -9.9247e-03]]],\n",
       " \n",
       " \n",
       "         [[[-6.6234e-02,  6.0681e-02,  4.7280e-02],\n",
       "           [-6.1390e-02, -3.7262e-02, -2.9157e-02],\n",
       "           [-9.8762e-03, -3.4267e-03, -4.0403e-02]],\n",
       " \n",
       "          [[-6.7267e-03,  2.5510e-02, -2.8445e-02],\n",
       "           [ 5.4096e-03, -4.7402e-02,  6.5883e-04],\n",
       "           [ 5.4365e-02,  5.1513e-02, -8.4371e-02]],\n",
       " \n",
       "          [[-2.9723e-02,  9.7509e-05, -3.9430e-02],\n",
       "           [ 7.4887e-04,  1.4736e-03,  1.2353e-02],\n",
       "           [-1.1681e-03,  2.4675e-02,  3.7101e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.0199e-02,  7.2736e-03, -6.2595e-02],\n",
       "           [ 7.7733e-02,  3.2016e-02,  3.8122e-02],\n",
       "           [ 3.5202e-03, -7.7367e-02, -1.9307e-03]],\n",
       " \n",
       "          [[-6.8441e-02, -4.4501e-02, -1.8311e-02],\n",
       "           [-3.4094e-02,  2.0542e-02,  5.8407e-02],\n",
       "           [ 1.0371e-03, -6.9457e-02, -2.0527e-02]],\n",
       " \n",
       "          [[-1.7347e-02, -5.1475e-03,  2.4102e-02],\n",
       "           [-2.1037e-02,  5.9076e-02, -2.7257e-02],\n",
       "           [ 9.2878e-03, -6.9616e-02,  5.1107e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0343e-02,  7.9237e-03,  4.1854e-02],\n",
       "           [ 1.6646e-02,  5.0028e-02,  1.4793e-02],\n",
       "           [ 5.2790e-02, -7.1954e-02,  4.5858e-02]],\n",
       " \n",
       "          [[-3.8150e-02, -2.6589e-03,  7.1062e-02],\n",
       "           [-7.6080e-02, -3.6078e-02,  5.0877e-02],\n",
       "           [ 7.2600e-02, -7.1421e-02,  1.9756e-02]],\n",
       " \n",
       "          [[-2.2297e-02, -4.5888e-02,  9.0579e-03],\n",
       "           [ 6.9388e-02,  1.7565e-02,  1.8356e-02],\n",
       "           [-3.9766e-02, -1.2890e-02,  5.5289e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.5416e-02, -1.8819e-02, -5.2598e-02],\n",
       "           [-3.2756e-02,  5.0727e-02,  4.3249e-02],\n",
       "           [-9.2519e-02, -8.1931e-02,  1.2912e-02]],\n",
       " \n",
       "          [[-5.7125e-03,  4.6320e-02,  3.6571e-02],\n",
       "           [-3.1247e-03,  1.2188e-02, -2.5456e-02],\n",
       "           [-3.6890e-02,  3.9299e-02,  4.4469e-03]],\n",
       " \n",
       "          [[-3.1891e-02,  2.1038e-02,  4.6621e-03],\n",
       "           [-8.1204e-02, -1.9406e-02,  2.8062e-02],\n",
       "           [ 9.1236e-02,  4.6698e-02, -1.8839e-02]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.10.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.11.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.11.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.14.weight': Parameter containing:\n",
       " tensor([[[[ 5.2901e-04, -2.2365e-04, -2.5121e-02],\n",
       "           [-1.6179e-02, -3.2238e-02, -4.4958e-02],\n",
       "           [ 2.0445e-03,  3.3078e-03,  1.6441e-02]],\n",
       " \n",
       "          [[-2.0057e-03,  1.2613e-03, -4.1375e-03],\n",
       "           [ 3.8673e-02,  9.7776e-03,  3.5965e-02],\n",
       "           [ 4.1014e-02, -3.8346e-02, -2.7136e-02]],\n",
       " \n",
       "          [[-4.5637e-02,  5.9879e-03, -6.2416e-03],\n",
       "           [-2.2679e-02, -3.0561e-02, -1.0111e-02],\n",
       "           [-3.9117e-03,  4.2946e-02,  8.8542e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1086e-02, -8.8717e-04,  1.5559e-02],\n",
       "           [-1.6684e-03, -8.7372e-03, -7.2686e-03],\n",
       "           [ 1.4019e-02, -3.0860e-02, -1.7230e-02]],\n",
       " \n",
       "          [[-4.5092e-03, -2.9335e-02, -2.5936e-02],\n",
       "           [-2.5703e-02,  1.2958e-02, -1.3483e-02],\n",
       "           [ 5.9745e-02, -1.0973e-02, -5.4273e-02]],\n",
       " \n",
       "          [[-2.5446e-02,  2.1571e-03, -8.3691e-03],\n",
       "           [-3.8363e-02,  1.6097e-03,  6.6932e-02],\n",
       "           [ 4.0037e-02,  1.5261e-02, -1.7154e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.1300e-02, -3.1107e-03,  2.1143e-02],\n",
       "           [-4.2039e-02,  4.4119e-03, -2.8884e-02],\n",
       "           [ 2.6142e-02, -3.3853e-04,  1.9134e-04]],\n",
       " \n",
       "          [[ 2.2811e-02,  1.2975e-02, -7.0996e-03],\n",
       "           [ 3.1941e-02, -1.9776e-02, -2.3405e-02],\n",
       "           [ 5.6210e-02, -1.3815e-02,  2.5417e-03]],\n",
       " \n",
       "          [[-6.5095e-03, -4.6796e-03, -7.6273e-03],\n",
       "           [ 8.4980e-03,  2.4136e-02, -6.2200e-03],\n",
       "           [ 7.4874e-03, -2.8573e-02,  1.5731e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.9825e-02, -2.0190e-03, -2.8845e-02],\n",
       "           [ 5.4670e-03, -1.7781e-02,  4.2397e-03],\n",
       "           [ 2.4533e-03,  2.2984e-02, -2.1334e-02]],\n",
       " \n",
       "          [[ 3.0379e-03, -5.2472e-02,  8.9317e-03],\n",
       "           [-1.0068e-02,  8.1873e-03, -5.0893e-02],\n",
       "           [ 3.3147e-02, -2.0741e-02,  4.0021e-03]],\n",
       " \n",
       "          [[ 9.9768e-05, -9.4889e-03, -2.4090e-02],\n",
       "           [ 1.9805e-02,  4.1547e-02,  7.2299e-03],\n",
       "           [ 1.9208e-02,  3.7147e-02,  1.4517e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8180e-02, -2.2390e-02,  1.6090e-02],\n",
       "           [ 2.4744e-03,  2.7633e-03, -3.6544e-02],\n",
       "           [ 2.1865e-03,  7.6729e-02,  1.0820e-02]],\n",
       " \n",
       "          [[ 6.1997e-03,  3.2048e-02,  5.8267e-03],\n",
       "           [-2.5439e-02, -3.7534e-02,  1.0797e-02],\n",
       "           [-2.5486e-02,  4.7449e-02, -1.1758e-02]],\n",
       " \n",
       "          [[-2.5159e-02, -8.4572e-03,  2.0321e-02],\n",
       "           [ 3.0839e-02, -2.4235e-02, -8.8987e-03],\n",
       "           [-1.1665e-02, -6.7665e-02,  1.1004e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.4443e-03, -2.4934e-02,  2.4495e-02],\n",
       "           [ 4.3506e-02, -4.8935e-03,  3.5990e-02],\n",
       "           [ 5.9600e-02, -1.6641e-02,  4.1919e-02]],\n",
       " \n",
       "          [[-6.2235e-03,  3.9999e-02,  8.7272e-03],\n",
       "           [-2.1315e-03,  1.9875e-03,  3.2939e-02],\n",
       "           [ 7.3688e-02, -5.5007e-03,  7.4372e-03]],\n",
       " \n",
       "          [[-5.5418e-02,  4.7516e-02,  4.3674e-02],\n",
       "           [ 3.1517e-02, -5.7649e-04,  8.0194e-02],\n",
       "           [-6.2696e-03, -3.4246e-04, -3.1723e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.0098e-02,  1.9041e-02, -3.8470e-02],\n",
       "           [ 1.4685e-02, -3.6940e-02, -7.8050e-04],\n",
       "           [ 8.1723e-03,  1.2946e-02, -6.6784e-03]],\n",
       " \n",
       "          [[ 9.6087e-02, -8.8144e-03,  3.5606e-02],\n",
       "           [-1.9965e-02,  1.9368e-02,  6.8432e-02],\n",
       "           [-2.3930e-02, -1.1299e-02, -8.3824e-03]],\n",
       " \n",
       "          [[ 3.1924e-02, -6.1936e-02,  3.5954e-02],\n",
       "           [-3.1092e-03, -2.1433e-02,  2.9816e-02],\n",
       "           [-3.8685e-02, -8.3038e-03,  4.4881e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.1717e-02, -5.6373e-02,  4.5174e-03],\n",
       "           [-2.6176e-02, -6.3459e-02, -3.8086e-02],\n",
       "           [-3.6349e-02, -7.6306e-03,  6.3412e-02]],\n",
       " \n",
       "          [[-7.3218e-03, -2.3294e-02, -5.0397e-03],\n",
       "           [-2.4671e-03, -1.7582e-02, -2.5021e-02],\n",
       "           [-1.6837e-02,  4.6080e-03, -2.8399e-02]],\n",
       " \n",
       "          [[ 1.0655e-02, -2.5266e-02, -3.3131e-02],\n",
       "           [ 6.5851e-03,  2.7700e-02, -1.1540e-03],\n",
       "           [ 5.5281e-02, -8.1260e-03, -3.5209e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.9073e-02,  2.9552e-02, -1.6078e-02],\n",
       "           [-1.9274e-02,  6.0184e-03,  1.1240e-02],\n",
       "           [-9.3103e-03, -3.0936e-02, -5.7996e-02]],\n",
       " \n",
       "          [[-3.6392e-02, -4.4066e-02, -6.8319e-02],\n",
       "           [ 3.8916e-02,  9.3174e-03,  1.0998e-01],\n",
       "           [ 4.8614e-03, -3.3901e-02, -2.2258e-02]],\n",
       " \n",
       "          [[-5.6698e-04,  6.7076e-02, -5.4121e-03],\n",
       "           [ 3.1295e-02, -2.3638e-02, -2.5322e-02],\n",
       "           [-5.2894e-03, -3.4248e-02, -4.1204e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.5990e-02,  3.4847e-02,  3.9270e-03],\n",
       "           [-2.1497e-03, -3.6719e-02,  3.3325e-03],\n",
       "           [-2.1563e-02,  5.3017e-02, -1.5055e-02]],\n",
       " \n",
       "          [[ 2.7906e-02, -5.6624e-03, -1.1428e-02],\n",
       "           [-3.3847e-02,  2.4399e-02,  4.9919e-02],\n",
       "           [ 9.5632e-04, -6.4106e-03,  5.2465e-03]],\n",
       " \n",
       "          [[-1.9448e-02, -4.3711e-02,  6.8704e-02],\n",
       "           [-2.0592e-02, -2.1027e-02,  3.3357e-02],\n",
       "           [-5.8921e-05,  2.1756e-02, -4.6676e-03]]],\n",
       " \n",
       " \n",
       "         [[[-7.0419e-03,  1.7735e-03, -3.0619e-03],\n",
       "           [-1.7928e-02,  5.9492e-02, -4.0346e-05],\n",
       "           [-7.2776e-02, -2.6082e-02,  1.7610e-03]],\n",
       " \n",
       "          [[-1.9116e-02, -1.0224e-02,  4.4975e-02],\n",
       "           [-2.8592e-02, -4.9366e-02, -1.9620e-02],\n",
       "           [-5.9547e-03, -1.9850e-02, -3.1585e-02]],\n",
       " \n",
       "          [[-1.7770e-02,  1.7438e-02,  1.0407e-02],\n",
       "           [-2.4936e-02, -4.2290e-02, -4.0543e-02],\n",
       "           [-3.6174e-02, -4.9851e-02,  1.9180e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0513e-02,  2.5987e-02,  6.9966e-02],\n",
       "           [ 1.9784e-03,  1.1489e-02, -1.0152e-02],\n",
       "           [ 3.7509e-02,  4.7709e-03, -9.9477e-02]],\n",
       " \n",
       "          [[ 9.0237e-03, -2.1667e-02,  9.8390e-02],\n",
       "           [-5.3649e-02,  1.7231e-02, -5.7758e-02],\n",
       "           [-1.1219e-02,  3.7977e-02, -1.4596e-02]],\n",
       " \n",
       "          [[-2.8210e-02, -2.7966e-02, -3.4126e-02],\n",
       "           [ 1.8122e-03,  3.0853e-02,  1.6211e-02],\n",
       "           [-5.2039e-03,  4.2517e-02, -5.2196e-03]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.14.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.15.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.15.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.17.weight': Parameter containing:\n",
       " tensor([[[[-0.0266,  0.0564,  0.0177],\n",
       "           [ 0.0082, -0.0575,  0.0356],\n",
       "           [ 0.0268, -0.0386,  0.0283]],\n",
       " \n",
       "          [[-0.0256, -0.0243, -0.0315],\n",
       "           [ 0.0068,  0.0164, -0.0104],\n",
       "           [-0.0073, -0.0098, -0.0205]],\n",
       " \n",
       "          [[-0.0500, -0.0103,  0.0166],\n",
       "           [-0.0348,  0.0054, -0.0665],\n",
       "           [ 0.0249,  0.0110,  0.0452]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0117,  0.0098, -0.0243],\n",
       "           [ 0.0147, -0.0274, -0.0195],\n",
       "           [ 0.0016,  0.0101,  0.0442]],\n",
       " \n",
       "          [[ 0.0320, -0.1012, -0.0548],\n",
       "           [ 0.0274,  0.0159,  0.0100],\n",
       "           [-0.0619, -0.0236,  0.0255]],\n",
       " \n",
       "          [[ 0.0126,  0.0029,  0.0024],\n",
       "           [-0.0570, -0.0138, -0.0156],\n",
       "           [-0.0071,  0.0198, -0.0077]]],\n",
       " \n",
       " \n",
       "         [[[-0.0082,  0.0339, -0.0477],\n",
       "           [ 0.0194, -0.0356, -0.0059],\n",
       "           [-0.0267, -0.0406, -0.0201]],\n",
       " \n",
       "          [[-0.0067,  0.0340,  0.0005],\n",
       "           [ 0.0452, -0.0607,  0.0367],\n",
       "           [-0.0064, -0.0095,  0.0222]],\n",
       " \n",
       "          [[ 0.0606, -0.0438, -0.0308],\n",
       "           [-0.0216, -0.0142,  0.0143],\n",
       "           [-0.0053,  0.0550,  0.0493]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0062, -0.0106, -0.0017],\n",
       "           [-0.0379,  0.0224,  0.0145],\n",
       "           [ 0.0057, -0.0492, -0.0117]],\n",
       " \n",
       "          [[ 0.0096,  0.0035,  0.0060],\n",
       "           [ 0.0117, -0.0627,  0.0511],\n",
       "           [ 0.0318, -0.0406,  0.0105]],\n",
       " \n",
       "          [[-0.0045, -0.0610, -0.0021],\n",
       "           [-0.0129,  0.0376, -0.0163],\n",
       "           [ 0.0423, -0.0487,  0.0296]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0181, -0.0126, -0.0084],\n",
       "           [ 0.0155,  0.0194,  0.0306],\n",
       "           [-0.0488, -0.0030,  0.0117]],\n",
       " \n",
       "          [[-0.0522, -0.0056,  0.0343],\n",
       "           [-0.0142,  0.0224, -0.0047],\n",
       "           [ 0.0370, -0.0109, -0.0024]],\n",
       " \n",
       "          [[ 0.0168, -0.0061, -0.0597],\n",
       "           [-0.0386,  0.0383,  0.0265],\n",
       "           [-0.0288,  0.0161,  0.0153]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0317, -0.0069,  0.0012],\n",
       "           [ 0.0152,  0.0075,  0.0201],\n",
       "           [ 0.0376, -0.0298, -0.0432]],\n",
       " \n",
       "          [[ 0.0039, -0.0285,  0.0063],\n",
       "           [ 0.0412, -0.0110,  0.0181],\n",
       "           [-0.0147,  0.0483,  0.0215]],\n",
       " \n",
       "          [[-0.0333,  0.0070,  0.0021],\n",
       "           [-0.0219,  0.0660,  0.0046],\n",
       "           [ 0.0397,  0.0146,  0.0157]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0055, -0.0201,  0.0202],\n",
       "           [ 0.0243, -0.0093, -0.0288],\n",
       "           [-0.0020,  0.0101, -0.0113]],\n",
       " \n",
       "          [[-0.0190, -0.0009, -0.0311],\n",
       "           [ 0.0465,  0.0006,  0.0143],\n",
       "           [ 0.0408,  0.0035, -0.0482]],\n",
       " \n",
       "          [[-0.0377, -0.0685,  0.0310],\n",
       "           [ 0.0003, -0.0587, -0.0101],\n",
       "           [-0.0290,  0.0559,  0.0467]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0132, -0.0038, -0.0676],\n",
       "           [-0.0071,  0.0244,  0.0053],\n",
       "           [ 0.0087, -0.0133, -0.0134]],\n",
       " \n",
       "          [[-0.0164, -0.0022,  0.0022],\n",
       "           [-0.0033,  0.0100, -0.0029],\n",
       "           [-0.0054, -0.0042,  0.0016]],\n",
       " \n",
       "          [[-0.0112,  0.0254,  0.0291],\n",
       "           [-0.0488, -0.0189, -0.0201],\n",
       "           [ 0.0146, -0.0454, -0.0375]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0024,  0.0123,  0.0428],\n",
       "           [-0.0575, -0.0114,  0.0541],\n",
       "           [ 0.0035,  0.0327,  0.0451]],\n",
       " \n",
       "          [[-0.0290,  0.0126,  0.0370],\n",
       "           [ 0.0280, -0.0272,  0.0099],\n",
       "           [-0.0117,  0.0416, -0.0061]],\n",
       " \n",
       "          [[-0.0310,  0.0230, -0.0138],\n",
       "           [ 0.0072, -0.0390,  0.0059],\n",
       "           [ 0.0482, -0.0260, -0.0674]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0300,  0.0137, -0.0291],\n",
       "           [-0.0039,  0.0148, -0.0556],\n",
       "           [ 0.0550, -0.0088, -0.0126]],\n",
       " \n",
       "          [[ 0.0144, -0.0116,  0.0626],\n",
       "           [ 0.0192,  0.0186, -0.0140],\n",
       "           [ 0.0005, -0.0051,  0.0277]],\n",
       " \n",
       "          [[-0.0661,  0.0699,  0.0283],\n",
       "           [-0.0263, -0.0351, -0.0061],\n",
       "           [-0.0112, -0.0148,  0.0125]]],\n",
       " \n",
       " \n",
       "         [[[-0.0169, -0.0242, -0.0277],\n",
       "           [ 0.0017, -0.0391,  0.0124],\n",
       "           [-0.0328,  0.0219,  0.0162]],\n",
       " \n",
       "          [[-0.0282, -0.0045, -0.0487],\n",
       "           [ 0.0436, -0.0075, -0.0157],\n",
       "           [ 0.0437,  0.0062,  0.0201]],\n",
       " \n",
       "          [[ 0.0045, -0.0513, -0.0076],\n",
       "           [-0.0114, -0.0472, -0.0351],\n",
       "           [ 0.0242, -0.0305,  0.0095]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0297,  0.0061, -0.0060],\n",
       "           [-0.0307,  0.0343, -0.0290],\n",
       "           [ 0.0059,  0.0265,  0.0008]],\n",
       " \n",
       "          [[ 0.0472,  0.0164, -0.0205],\n",
       "           [-0.0119, -0.0625,  0.0545],\n",
       "           [ 0.0033,  0.0450,  0.0053]],\n",
       " \n",
       "          [[ 0.0028,  0.0344, -0.0799],\n",
       "           [-0.0128, -0.0185, -0.0206],\n",
       "           [-0.0138,  0.0277, -0.0172]]]], device='cuda:0', requires_grad=True),\n",
       " 'module.features.17.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.18.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.18.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.20.weight': Parameter containing:\n",
       " tensor([[[[-8.6547e-03, -4.4153e-03, -2.6259e-02],\n",
       "           [-3.3299e-02,  4.0237e-02,  4.1381e-02],\n",
       "           [-1.9051e-02, -3.7802e-02,  3.3750e-02]],\n",
       " \n",
       "          [[-1.3348e-02,  4.5481e-02,  8.6049e-03],\n",
       "           [ 9.6116e-03,  9.5838e-03, -1.6973e-02],\n",
       "           [ 3.2734e-02,  1.6901e-02,  1.0055e-03]],\n",
       " \n",
       "          [[ 2.2146e-02,  1.7542e-02, -3.6667e-02],\n",
       "           [-3.1330e-02,  8.9574e-03, -9.0652e-03],\n",
       "           [-4.3174e-02, -2.2536e-02, -8.2564e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 8.3011e-03,  9.3945e-03,  6.6283e-04],\n",
       "           [-1.0790e-02,  2.3193e-03,  1.2777e-02],\n",
       "           [-5.1591e-03, -5.6179e-02, -1.5812e-02]],\n",
       " \n",
       "          [[ 1.9618e-02, -8.7088e-04,  3.1893e-02],\n",
       "           [-3.2767e-02, -7.1887e-02,  2.4856e-02],\n",
       "           [-2.7452e-02,  1.9868e-03,  2.6980e-02]],\n",
       " \n",
       "          [[ 2.3348e-02,  1.3921e-02, -8.8258e-02],\n",
       "           [-1.0724e-02,  3.3637e-02,  1.7141e-02],\n",
       "           [-2.2865e-02, -1.7982e-03, -2.8615e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.7208e-02, -5.5711e-02, -2.1644e-02],\n",
       "           [ 1.9149e-02,  1.6505e-02, -5.5170e-03],\n",
       "           [ 4.5186e-03,  2.6498e-02, -1.3113e-02]],\n",
       " \n",
       "          [[ 3.4316e-02, -1.3429e-02,  1.7551e-02],\n",
       "           [-6.1044e-03,  3.8774e-02,  6.3928e-03],\n",
       "           [-5.7805e-02, -1.1333e-02, -7.1942e-02]],\n",
       " \n",
       "          [[-4.9337e-04,  5.4125e-02, -1.1394e-02],\n",
       "           [-6.2649e-03, -3.2658e-02,  3.2196e-02],\n",
       "           [-1.1363e-02,  9.9800e-03,  2.9766e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.3463e-02, -1.4976e-02,  1.3480e-02],\n",
       "           [-2.3542e-02, -3.1767e-02, -8.4866e-04],\n",
       "           [ 4.0609e-02,  3.1028e-02, -3.9332e-02]],\n",
       " \n",
       "          [[ 9.9747e-03, -1.4625e-02, -2.2203e-02],\n",
       "           [-3.7890e-02, -6.8499e-02, -1.0126e-02],\n",
       "           [ 6.2818e-02, -5.7616e-02,  1.3120e-02]],\n",
       " \n",
       "          [[ 2.2500e-02, -5.6198e-03,  3.6222e-03],\n",
       "           [-2.2388e-02,  4.0485e-02, -2.4024e-02],\n",
       "           [ 1.8658e-02,  2.9027e-02, -3.4075e-02]]],\n",
       " \n",
       " \n",
       "         [[[-9.9954e-03,  2.7951e-03,  6.0629e-02],\n",
       "           [-2.5628e-03,  1.4239e-04,  5.5682e-03],\n",
       "           [-4.5193e-02, -3.6562e-02,  3.2805e-02]],\n",
       " \n",
       "          [[-2.4546e-02,  5.4707e-03,  2.7727e-02],\n",
       "           [ 5.9305e-03,  3.1437e-02,  1.8683e-02],\n",
       "           [-5.2947e-02,  1.7571e-03, -3.3343e-02]],\n",
       " \n",
       "          [[-6.0020e-02,  1.1758e-02,  2.2944e-02],\n",
       "           [ 1.4512e-02,  1.3078e-02, -2.6305e-02],\n",
       "           [-8.1520e-03,  3.6276e-02, -3.5357e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.0406e-02,  1.1754e-02,  2.1771e-02],\n",
       "           [-2.8253e-02,  2.7027e-02,  1.3261e-02],\n",
       "           [ 8.5530e-03,  1.7797e-02,  2.0278e-02]],\n",
       " \n",
       "          [[-1.5688e-02,  5.2707e-02,  1.9600e-02],\n",
       "           [-6.4536e-04,  4.8861e-02, -1.5603e-02],\n",
       "           [ 3.5673e-02,  2.7632e-02,  3.5674e-03]],\n",
       " \n",
       "          [[-6.0955e-03, -7.9920e-02, -3.6847e-02],\n",
       "           [-5.0227e-02, -1.2439e-02,  4.1794e-03],\n",
       "           [ 4.2559e-02, -8.7209e-04,  5.7377e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 9.9371e-03,  3.5050e-03,  1.9420e-02],\n",
       "           [ 5.2345e-02, -1.0691e-03, -7.7996e-02],\n",
       "           [-1.6705e-02,  2.1131e-03, -2.3542e-03]],\n",
       " \n",
       "          [[-1.3868e-02,  2.3333e-02,  9.4206e-03],\n",
       "           [-3.5007e-03,  5.5355e-02,  2.9810e-02],\n",
       "           [ 1.1689e-02,  1.2021e-02,  1.0817e-02]],\n",
       " \n",
       "          [[ 8.7861e-03, -2.6944e-02,  4.1457e-03],\n",
       "           [-1.7227e-02,  1.4109e-02, -1.3465e-02],\n",
       "           [ 1.4008e-02, -6.6291e-03, -4.6744e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4225e-02, -1.1777e-02, -5.0339e-02],\n",
       "           [ 4.4387e-02, -7.1290e-03,  4.2473e-02],\n",
       "           [-1.2780e-02,  1.3033e-02, -2.6754e-02]],\n",
       " \n",
       "          [[ 1.7032e-02, -1.8143e-02, -1.0683e-02],\n",
       "           [-3.8472e-03,  4.0981e-02, -1.8106e-02],\n",
       "           [ 3.6232e-03, -3.6200e-02, -3.0269e-02]],\n",
       " \n",
       "          [[-4.3851e-02, -4.0764e-02, -3.2214e-02],\n",
       "           [-1.3882e-02,  8.7285e-03, -2.3893e-03],\n",
       "           [-5.1820e-02,  1.3126e-02, -1.5328e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3113e-02,  5.0096e-02,  2.2396e-02],\n",
       "           [ 3.4294e-02,  2.4924e-02, -7.0968e-02],\n",
       "           [ 8.7638e-03, -2.9141e-02, -7.7071e-03]],\n",
       " \n",
       "          [[-1.0211e-02, -2.8515e-02,  5.5843e-03],\n",
       "           [-3.2286e-02,  2.5027e-02, -8.3087e-03],\n",
       "           [-1.5619e-02, -4.9770e-02,  2.0192e-02]],\n",
       " \n",
       "          [[ 1.8458e-02,  1.1650e-02, -2.7758e-02],\n",
       "           [-4.9344e-03,  1.7872e-02, -1.0292e-02],\n",
       "           [ 1.0246e-02, -1.0699e-02,  2.7902e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.7259e-03,  2.9320e-02, -1.2473e-02],\n",
       "           [-4.8732e-02,  1.0264e-02, -2.5403e-02],\n",
       "           [-3.5694e-02, -1.3996e-02,  3.0951e-02]],\n",
       " \n",
       "          [[-2.6672e-02, -4.5416e-04, -1.7851e-02],\n",
       "           [ 3.0688e-02, -3.7143e-02,  2.3990e-02],\n",
       "           [-3.0144e-03,  1.8868e-02, -1.1895e-02]],\n",
       " \n",
       "          [[-1.2601e-02,  3.8123e-03, -1.3574e-02],\n",
       "           [-3.6788e-02, -3.1282e-02,  2.1174e-02],\n",
       "           [ 2.4446e-03,  1.3554e-02,  1.8687e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1972e-02,  1.8868e-02,  1.2669e-02],\n",
       "           [-1.7660e-02,  2.0582e-02,  1.2296e-02],\n",
       "           [ 3.3899e-03,  5.7140e-02,  3.3180e-02]],\n",
       " \n",
       "          [[-3.2473e-02,  4.5862e-02,  3.6185e-02],\n",
       "           [ 4.9877e-02, -4.2953e-02, -2.1606e-02],\n",
       "           [ 1.6381e-02, -1.8498e-02, -2.9699e-02]],\n",
       " \n",
       "          [[ 2.9279e-02, -5.0277e-02,  4.3196e-02],\n",
       "           [-2.4779e-02, -2.3713e-04,  1.7663e-02],\n",
       "           [ 2.4166e-02,  2.9006e-02, -2.6562e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.6307e-02,  3.9112e-02, -1.1274e-02],\n",
       "           [-2.0584e-02,  1.9973e-02, -2.0853e-02],\n",
       "           [ 3.7324e-06, -1.1601e-03,  2.5208e-02]],\n",
       " \n",
       "          [[ 6.0343e-04,  2.1650e-02,  1.6692e-02],\n",
       "           [-4.6699e-02, -2.7516e-02, -6.2413e-03],\n",
       "           [-7.2853e-03, -2.7718e-02,  2.7980e-02]],\n",
       " \n",
       "          [[ 3.0320e-02,  1.2329e-02,  4.6796e-02],\n",
       "           [ 4.2579e-02,  3.8622e-02,  1.5801e-02],\n",
       "           [ 1.5059e-02, -8.6677e-03, -2.4332e-02]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.20.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.21.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.21.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.23.weight': Parameter containing:\n",
       " tensor([[[[-7.9725e-03, -4.0891e-02, -1.7825e-03],\n",
       "           [-5.3571e-03,  1.3204e-02,  4.2157e-03],\n",
       "           [ 3.1293e-02, -1.7671e-02, -3.2408e-02]],\n",
       " \n",
       "          [[ 1.9665e-02,  3.3894e-03,  1.7543e-02],\n",
       "           [ 1.7116e-02,  2.2787e-02, -6.0415e-02],\n",
       "           [ 9.8612e-03,  1.7302e-02, -1.3488e-03]],\n",
       " \n",
       "          [[ 2.0441e-02,  5.3529e-03,  1.2188e-02],\n",
       "           [ 3.8018e-02, -3.6289e-02,  2.5239e-02],\n",
       "           [-2.8513e-02, -3.9779e-02, -3.8336e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3800e-02,  1.6202e-03,  5.4647e-02],\n",
       "           [-2.3429e-02,  1.3568e-02,  7.5051e-03],\n",
       "           [-1.5041e-03, -3.2456e-02,  7.5842e-02]],\n",
       " \n",
       "          [[-1.1362e-02, -1.7899e-02,  1.7697e-02],\n",
       "           [ 1.5014e-02,  9.6721e-03, -5.1605e-02],\n",
       "           [-1.7489e-04, -2.8641e-04,  7.4293e-03]],\n",
       " \n",
       "          [[ 1.8448e-02,  5.4512e-02,  6.7993e-03],\n",
       "           [ 3.0642e-02, -2.4441e-02, -5.8355e-04],\n",
       "           [-1.9729e-02,  7.4116e-02, -5.2972e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7748e-02,  3.4710e-03, -2.8808e-02],\n",
       "           [ 6.3529e-05, -5.7053e-03,  3.4254e-02],\n",
       "           [-2.5218e-03,  2.0959e-02, -7.3147e-02]],\n",
       " \n",
       "          [[-2.0745e-02, -2.3415e-02,  8.2209e-03],\n",
       "           [ 1.0158e-02, -2.4908e-02, -8.0564e-03],\n",
       "           [ 2.3494e-02, -1.6397e-03,  1.4147e-02]],\n",
       " \n",
       "          [[-3.2992e-02,  1.8889e-02, -8.0490e-05],\n",
       "           [ 9.6794e-03, -7.0268e-02,  7.3679e-03],\n",
       "           [ 2.7920e-02, -2.0655e-02, -7.2060e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.4837e-02, -8.8571e-03, -3.9654e-02],\n",
       "           [-3.9131e-02, -1.3911e-02, -2.7231e-02],\n",
       "           [-1.7656e-02,  5.7962e-02,  1.9561e-02]],\n",
       " \n",
       "          [[-1.6575e-02, -2.8846e-02, -1.3827e-02],\n",
       "           [-1.1997e-03, -5.9509e-03,  6.2262e-04],\n",
       "           [ 3.5577e-02,  5.0939e-03,  3.0732e-02]],\n",
       " \n",
       "          [[-2.2402e-02,  4.4075e-02,  2.5009e-02],\n",
       "           [-5.5332e-02, -4.0813e-02,  6.2246e-04],\n",
       "           [ 1.6305e-02,  2.0149e-02, -1.6538e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5592e-02, -1.0285e-02, -4.6657e-02],\n",
       "           [-1.4950e-02, -5.4343e-02, -6.8419e-02],\n",
       "           [-1.3903e-02,  5.6940e-02, -2.6229e-02]],\n",
       " \n",
       "          [[-3.0735e-03,  5.4023e-02, -2.8988e-02],\n",
       "           [-4.6634e-02,  6.6389e-02,  2.2650e-02],\n",
       "           [ 4.6978e-02, -5.3472e-02, -5.7833e-02]],\n",
       " \n",
       "          [[-1.9258e-02,  4.1464e-02, -2.0166e-02],\n",
       "           [-1.0272e-02, -1.6094e-02, -1.2452e-03],\n",
       "           [ 3.6173e-02,  2.7154e-02, -1.4107e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0765e-02, -4.6401e-02, -4.0145e-02],\n",
       "           [-4.0900e-02,  5.5440e-02, -7.2422e-02],\n",
       "           [-1.6617e-02,  7.8449e-03, -6.6399e-04]],\n",
       " \n",
       "          [[-4.1836e-03, -3.8924e-02,  1.9122e-02],\n",
       "           [ 2.6464e-02,  5.0916e-03,  9.1903e-03],\n",
       "           [-1.0231e-02,  4.3599e-03, -3.7309e-02]],\n",
       " \n",
       "          [[-1.5608e-03,  4.6276e-03, -1.5741e-02],\n",
       "           [-5.0840e-04, -6.1865e-03, -2.7494e-02],\n",
       "           [ 4.5951e-02, -4.4955e-02, -2.5377e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.2549e-02, -8.5814e-03, -5.2253e-02],\n",
       "           [-1.4411e-02, -2.1009e-02, -4.7970e-02],\n",
       "           [-1.1321e-02,  5.9224e-02, -4.3665e-02]],\n",
       " \n",
       "          [[ 1.8949e-02, -6.2374e-02,  3.7751e-02],\n",
       "           [-5.9999e-03,  2.0005e-02,  1.4672e-02],\n",
       "           [-5.9244e-03, -1.7913e-02, -6.1218e-02]],\n",
       " \n",
       "          [[ 3.5495e-02, -3.3029e-02,  1.0766e-02],\n",
       "           [-7.7771e-03, -5.3870e-03,  5.3721e-03],\n",
       "           [ 2.7316e-02,  5.5409e-02,  5.7530e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0455e-02, -1.4052e-02,  8.0332e-03],\n",
       "           [ 7.2089e-03, -4.3756e-02,  7.8841e-03],\n",
       "           [-8.5005e-03,  3.4391e-02, -4.4006e-02]],\n",
       " \n",
       "          [[-4.4717e-02, -1.1553e-02,  3.8695e-02],\n",
       "           [-5.2903e-02,  2.3819e-02, -2.3011e-02],\n",
       "           [ 4.6959e-02, -2.1472e-02,  1.5295e-02]],\n",
       " \n",
       "          [[ 7.0167e-02, -3.6483e-02, -2.3599e-02],\n",
       "           [-3.6306e-03, -3.3300e-02, -7.8440e-03],\n",
       "           [-3.1688e-02, -3.7308e-02,  9.9534e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 6.0726e-03,  6.5140e-03, -3.2283e-02],\n",
       "           [-1.7499e-02,  7.7484e-03,  3.6841e-02],\n",
       "           [ 2.4619e-02,  4.7601e-02, -2.2876e-02]],\n",
       " \n",
       "          [[-7.8562e-03, -2.2540e-02, -1.4182e-03],\n",
       "           [ 6.2892e-03, -2.5092e-02, -2.4963e-02],\n",
       "           [-3.2730e-04, -2.5102e-02, -5.1972e-02]],\n",
       " \n",
       "          [[-9.4270e-03,  3.7755e-02,  1.7848e-02],\n",
       "           [-3.8824e-02,  1.5104e-02, -1.4834e-02],\n",
       "           [ 3.2437e-02, -1.5168e-02,  1.5453e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7220e-02,  3.3104e-02, -2.1833e-02],\n",
       "           [ 3.0761e-04, -2.0523e-03, -2.1118e-02],\n",
       "           [-1.0810e-02,  1.0809e-03, -3.0194e-03]],\n",
       " \n",
       "          [[ 2.1686e-02, -6.7916e-02, -6.6470e-02],\n",
       "           [-8.3287e-02, -1.8192e-02,  3.2339e-02],\n",
       "           [-1.7076e-02, -5.2982e-02, -2.7855e-02]],\n",
       " \n",
       "          [[ 4.1858e-03, -7.8810e-02, -1.1273e-02],\n",
       "           [ 6.8037e-03,  9.5516e-03,  2.2636e-02],\n",
       "           [ 2.0874e-02,  3.3751e-03, -2.4189e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8330e-04, -6.7652e-02,  4.5182e-03],\n",
       "           [-1.1089e-02, -3.5145e-03,  5.2792e-03],\n",
       "           [ 5.5994e-03,  8.2242e-03, -2.1581e-02]],\n",
       " \n",
       "          [[ 1.6329e-02,  5.9716e-02,  1.0436e-02],\n",
       "           [-1.8127e-02, -1.8917e-02, -1.5775e-02],\n",
       "           [ 1.4614e-02, -1.1908e-02, -3.6620e-03]],\n",
       " \n",
       "          [[ 8.9946e-03,  4.1372e-02, -1.0205e-02],\n",
       "           [-2.8815e-02, -1.7020e-03, -5.8596e-02],\n",
       "           [ 3.6924e-02,  3.7360e-02,  1.2407e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.6249e-04,  5.0621e-02, -3.6777e-02],\n",
       "           [-2.9172e-02,  2.3176e-02,  2.6577e-03],\n",
       "           [-2.4023e-02, -1.4700e-03,  2.8196e-02]],\n",
       " \n",
       "          [[ 3.8785e-02,  1.9992e-02, -2.1385e-02],\n",
       "           [-5.8664e-03,  5.4368e-02,  4.5950e-02],\n",
       "           [ 3.5510e-02, -2.2276e-02,  4.4921e-02]],\n",
       " \n",
       "          [[-2.8399e-02, -8.5062e-03, -1.5484e-02],\n",
       "           [-5.2283e-02,  5.7184e-03, -3.0336e-02],\n",
       "           [ 7.7451e-03, -8.5083e-03, -3.1088e-03]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.23.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.24.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.24.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.features.27.weight': Parameter containing:\n",
       " tensor([[[[ 1.1467e-03,  3.7382e-03,  2.0795e-02],\n",
       "           [ 1.3674e-02, -2.9109e-02, -6.0586e-03],\n",
       "           [ 1.9543e-02,  1.6079e-02, -1.2101e-02]],\n",
       " \n",
       "          [[-1.0560e-02, -4.0895e-03,  1.4393e-02],\n",
       "           [ 7.4488e-03,  5.5243e-03,  4.5464e-03],\n",
       "           [-1.9088e-02,  3.3385e-02, -2.4174e-02]],\n",
       " \n",
       "          [[ 3.9081e-02, -6.2460e-03,  1.4587e-02],\n",
       "           [ 3.9784e-03, -1.5320e-02, -7.0684e-03],\n",
       "           [ 1.1395e-02,  3.6807e-02,  7.0410e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5436e-02, -5.4040e-03, -1.6124e-02],\n",
       "           [ 2.0731e-02,  5.2296e-03, -6.5319e-03],\n",
       "           [ 7.5396e-03,  1.5650e-02, -3.5777e-02]],\n",
       " \n",
       "          [[ 1.8008e-02,  2.9870e-03,  2.1795e-03],\n",
       "           [-2.1946e-02, -7.9737e-04,  4.6496e-03],\n",
       "           [-4.9394e-03,  1.6891e-02,  4.4332e-02]],\n",
       " \n",
       "          [[ 9.8821e-03, -7.0974e-03, -8.0067e-03],\n",
       "           [ 9.3255e-04,  3.4260e-02, -5.3709e-03],\n",
       "           [-3.0173e-02,  1.9503e-02, -2.5597e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.2344e-02,  3.1313e-03, -2.6403e-02],\n",
       "           [-1.2860e-02,  2.3133e-02,  3.7636e-03],\n",
       "           [-1.5104e-03, -2.7586e-02,  3.7089e-02]],\n",
       " \n",
       "          [[ 3.9520e-02, -2.0698e-02,  2.9883e-02],\n",
       "           [ 1.1666e-02,  9.3850e-03,  3.2173e-03],\n",
       "           [-2.6025e-02, -6.1698e-03,  6.9757e-03]],\n",
       " \n",
       "          [[ 1.0577e-03,  2.8216e-02,  9.3482e-03],\n",
       "           [-1.1968e-05, -1.3648e-02,  6.3664e-03],\n",
       "           [ 1.9549e-02,  6.1041e-03,  1.1674e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.6772e-03,  1.9230e-02, -1.5027e-02],\n",
       "           [ 1.0168e-02, -5.9433e-03, -1.1041e-02],\n",
       "           [ 4.0234e-02,  9.8183e-03, -3.6360e-02]],\n",
       " \n",
       "          [[-3.3038e-03,  6.0561e-03,  1.3452e-02],\n",
       "           [ 1.1061e-03,  2.8529e-02,  1.4296e-02],\n",
       "           [ 5.4963e-03, -5.5679e-03, -1.2108e-03]],\n",
       " \n",
       "          [[-2.2248e-02,  1.4271e-02, -1.0857e-02],\n",
       "           [-5.6918e-03,  1.3267e-02,  7.8909e-03],\n",
       "           [ 1.9637e-02, -6.5531e-02, -1.0457e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.6947e-02,  1.4669e-02,  7.3489e-03],\n",
       "           [ 2.2221e-02,  4.5817e-03,  7.9490e-03],\n",
       "           [ 4.2686e-02,  2.6390e-02,  2.3823e-02]],\n",
       " \n",
       "          [[-2.8589e-02, -4.8262e-03,  3.8905e-02],\n",
       "           [-2.1172e-02, -2.1570e-02,  1.8890e-03],\n",
       "           [ 9.9655e-03, -2.4321e-02,  2.8201e-03]],\n",
       " \n",
       "          [[ 3.6669e-03, -1.7063e-02,  1.4185e-02],\n",
       "           [ 3.1680e-04, -3.8099e-02,  3.1821e-02],\n",
       "           [-9.7734e-03, -6.9242e-03,  2.6720e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.9025e-02, -1.8720e-02, -3.3965e-02],\n",
       "           [-1.3901e-02,  2.1193e-02, -6.1967e-03],\n",
       "           [ 6.6432e-03, -1.6698e-02,  2.8216e-02]],\n",
       " \n",
       "          [[-2.0071e-02, -8.5852e-03, -1.8383e-02],\n",
       "           [ 3.2038e-02, -4.8401e-03, -7.2236e-03],\n",
       "           [-1.7239e-02,  3.0184e-02, -2.0752e-02]],\n",
       " \n",
       "          [[ 1.0253e-02, -1.8519e-02, -6.1274e-03],\n",
       "           [ 7.4672e-03, -1.9656e-02,  3.1315e-02],\n",
       "           [-8.3790e-03,  2.4562e-03, -1.3717e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.6971e-02, -1.0608e-02,  1.1176e-02],\n",
       "           [ 4.7167e-02, -3.2822e-02, -5.7570e-03],\n",
       "           [-1.2022e-02, -4.6758e-03, -4.5581e-02]],\n",
       " \n",
       "          [[ 2.5356e-02,  3.7164e-03, -2.0304e-03],\n",
       "           [-2.3189e-02,  3.1230e-03, -3.2568e-03],\n",
       "           [-1.1427e-02, -7.9799e-03, -2.2312e-02]],\n",
       " \n",
       "          [[ 4.1351e-02,  2.4371e-02, -2.4899e-02],\n",
       "           [-3.8279e-03,  1.9402e-03,  1.4847e-03],\n",
       "           [-2.6364e-02,  8.1157e-04,  1.7346e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.4931e-02, -1.5460e-02, -7.2800e-03],\n",
       "           [ 7.9921e-03, -3.0307e-03,  1.2248e-02],\n",
       "           [-2.4014e-03,  3.0850e-03,  2.4270e-03]],\n",
       " \n",
       "          [[-2.1369e-02,  1.6024e-02, -1.5569e-02],\n",
       "           [-1.3572e-02,  1.3926e-02,  1.0405e-02],\n",
       "           [-1.7578e-02, -2.9524e-04,  1.1539e-04]],\n",
       " \n",
       "          [[ 1.0735e-02, -3.1559e-03,  1.1849e-02],\n",
       "           [ 7.2650e-03, -2.5956e-03,  4.6006e-02],\n",
       "           [ 1.3185e-02, -2.9082e-02, -7.3887e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.1047e-02, -6.0936e-02, -1.0959e-02],\n",
       "           [-1.7909e-02,  2.3429e-02, -3.3699e-02],\n",
       "           [ 4.2840e-02, -3.9771e-02, -9.4174e-03]],\n",
       " \n",
       "          [[ 1.1041e-02,  1.0021e-02,  2.5465e-02],\n",
       "           [-2.2708e-02, -4.1096e-03,  3.8045e-02],\n",
       "           [ 2.5856e-02, -1.5512e-02,  3.9499e-02]],\n",
       " \n",
       "          [[ 2.4708e-02, -5.9179e-03,  3.0896e-02],\n",
       "           [ 1.2423e-02,  2.5089e-02, -8.3879e-03],\n",
       "           [ 3.2465e-02,  6.8632e-03,  4.4879e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0526e-03,  5.3865e-02,  4.3516e-02],\n",
       "           [-1.4418e-02,  1.4375e-02,  2.5180e-04],\n",
       "           [ 1.0759e-03, -1.7139e-02,  3.1542e-02]],\n",
       " \n",
       "          [[-1.4872e-03,  8.7622e-04, -1.8490e-02],\n",
       "           [-3.1011e-02, -2.6639e-02,  4.7523e-03],\n",
       "           [ 3.0742e-02, -2.3445e-03, -4.3415e-02]],\n",
       " \n",
       "          [[-1.7189e-02,  7.6686e-03,  1.2036e-02],\n",
       "           [-3.5839e-02,  9.2293e-03,  4.7088e-02],\n",
       "           [-1.1316e-02, -1.0190e-02,  4.5180e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.7600e-02,  2.1284e-02, -1.5857e-02],\n",
       "           [-1.6107e-02, -1.1622e-02, -2.7327e-03],\n",
       "           [ 2.0018e-02,  2.4468e-02,  2.0778e-02]],\n",
       " \n",
       "          [[ 1.6366e-02,  1.4738e-02,  4.4538e-02],\n",
       "           [ 4.7718e-03, -2.5835e-02, -1.0613e-02],\n",
       "           [ 6.8677e-03,  4.6416e-03,  4.4290e-02]],\n",
       " \n",
       "          [[-6.6739e-03,  2.1259e-02,  1.6534e-02],\n",
       "           [-1.1427e-02,  2.6529e-02,  2.9007e-03],\n",
       "           [ 4.5580e-02,  3.4429e-02, -4.2073e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1815e-02,  2.5289e-03,  2.0560e-02],\n",
       "           [ 1.4322e-02, -1.3097e-02, -3.0897e-02],\n",
       "           [-2.1466e-02, -1.8409e-02,  1.0630e-02]],\n",
       " \n",
       "          [[-1.4226e-02, -1.9128e-02,  3.6740e-02],\n",
       "           [-2.5454e-02, -1.6896e-02, -1.9050e-02],\n",
       "           [ 2.6919e-02, -3.0098e-03, -6.4991e-03]],\n",
       " \n",
       "          [[-6.8391e-03, -1.7250e-02, -1.0706e-02],\n",
       "           [ 1.5846e-02, -2.8740e-02, -4.3281e-02],\n",
       "           [-1.2484e-02,  1.6806e-02, -2.1195e-02]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.27.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.28.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.28.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.30.weight': Parameter containing:\n",
       " tensor([[[[-3.2560e-02,  3.5809e-03, -2.1459e-02],\n",
       "           [-3.0272e-02, -7.1154e-03,  2.7985e-02],\n",
       "           [-1.5980e-03,  3.3911e-02,  3.4893e-02]],\n",
       " \n",
       "          [[-1.8964e-02, -1.8970e-02, -3.5250e-02],\n",
       "           [-2.6815e-02, -1.9016e-02, -3.6783e-03],\n",
       "           [ 2.2716e-02, -6.1897e-03, -1.0240e-02]],\n",
       " \n",
       "          [[ 3.5350e-03,  1.2637e-02,  1.1281e-02],\n",
       "           [ 1.0871e-03, -3.2769e-02, -4.1701e-02],\n",
       "           [-2.3741e-02,  1.8600e-02,  2.2936e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.0606e-03, -9.9563e-03,  1.1211e-03],\n",
       "           [ 1.3518e-02, -1.0012e-02, -4.8292e-02],\n",
       "           [ 7.1718e-02, -3.0696e-02,  1.0571e-02]],\n",
       " \n",
       "          [[ 2.2712e-02, -2.2364e-02,  5.2162e-03],\n",
       "           [-4.9344e-03,  3.0297e-02, -1.0396e-04],\n",
       "           [ 4.2741e-04,  2.5756e-02, -2.0927e-02]],\n",
       " \n",
       "          [[-1.4029e-02, -3.1683e-02,  5.5056e-04],\n",
       "           [ 1.7919e-02, -7.3770e-03,  2.4110e-02],\n",
       "           [-3.7059e-02, -2.6138e-02,  1.4926e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.8770e-02,  2.4576e-02,  3.6050e-02],\n",
       "           [ 2.1480e-02, -2.1636e-02,  2.8877e-02],\n",
       "           [-7.6914e-03, -2.4885e-02, -4.4434e-03]],\n",
       " \n",
       "          [[ 8.5887e-03, -1.6895e-03, -1.3400e-02],\n",
       "           [ 1.2165e-02,  1.2728e-02,  1.8789e-02],\n",
       "           [-4.2346e-02, -2.8190e-03, -6.1254e-03]],\n",
       " \n",
       "          [[ 3.0443e-02, -2.6700e-02, -1.4482e-02],\n",
       "           [-1.0224e-02,  9.5899e-03, -4.1841e-02],\n",
       "           [ 3.0291e-02,  1.1569e-03, -7.3918e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.8795e-04,  1.7847e-02,  2.0695e-02],\n",
       "           [-8.3361e-03,  3.0140e-03, -2.8078e-03],\n",
       "           [-3.1992e-02, -1.5219e-02,  2.1376e-02]],\n",
       " \n",
       "          [[-1.1430e-02, -2.5692e-02,  1.0725e-02],\n",
       "           [-4.0943e-03,  4.4678e-02,  5.4263e-03],\n",
       "           [ 2.6619e-02,  1.2340e-03, -1.5569e-02]],\n",
       " \n",
       "          [[ 2.1234e-03, -2.7776e-02,  9.5844e-03],\n",
       "           [-4.1202e-02, -2.1424e-02,  3.4350e-03],\n",
       "           [ 7.3707e-03,  2.1333e-02, -1.2466e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.2290e-02, -2.9675e-02, -5.8293e-03],\n",
       "           [ 7.3738e-03,  4.1219e-02,  3.1219e-02],\n",
       "           [-3.1731e-03,  6.8221e-03,  1.6165e-02]],\n",
       " \n",
       "          [[ 2.2542e-02,  1.6834e-02, -1.3785e-03],\n",
       "           [ 3.0025e-02, -1.8531e-02, -4.3402e-03],\n",
       "           [-5.8232e-03, -2.1466e-02, -3.3737e-03]],\n",
       " \n",
       "          [[ 2.4131e-02, -7.7776e-03,  1.7514e-02],\n",
       "           [ 6.4702e-03,  2.2372e-02,  3.4583e-02],\n",
       "           [-3.1680e-02, -1.9219e-02,  2.1171e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.2795e-02, -9.6435e-03, -3.4930e-03],\n",
       "           [-2.7801e-03, -7.5918e-03, -1.3866e-02],\n",
       "           [ 2.6178e-02, -2.8617e-02,  1.5320e-02]],\n",
       " \n",
       "          [[-2.5889e-02,  3.4890e-03, -3.2639e-02],\n",
       "           [ 2.3767e-05, -1.5891e-02, -4.7970e-02],\n",
       "           [ 1.1799e-02, -3.5250e-04, -9.7481e-03]],\n",
       " \n",
       "          [[ 2.2238e-02, -1.0683e-02, -1.9447e-03],\n",
       "           [ 4.0172e-03,  1.6725e-02, -1.6694e-02],\n",
       "           [-2.9301e-02,  4.3070e-02, -8.4280e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.3803e-02, -5.7890e-03,  8.2663e-03],\n",
       "           [-3.4777e-03, -1.0379e-02, -3.7161e-02],\n",
       "           [-1.7952e-02,  2.0732e-03, -2.1278e-02]],\n",
       " \n",
       "          [[-1.1479e-02, -5.3307e-02, -5.7097e-03],\n",
       "           [ 1.0962e-02,  4.3030e-02, -1.8618e-02],\n",
       "           [-3.0430e-02, -1.3064e-02, -2.0188e-02]],\n",
       " \n",
       "          [[ 4.2041e-02,  7.9203e-03, -1.2850e-02],\n",
       "           [-1.6738e-02,  9.5925e-03, -6.3043e-03],\n",
       "           [-9.0826e-03, -6.8422e-04, -6.6246e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3775e-02, -3.7447e-03, -9.7933e-03],\n",
       "           [-2.1454e-02,  2.2318e-02,  2.8998e-02],\n",
       "           [-1.9986e-02, -1.2540e-02,  5.4077e-03]],\n",
       " \n",
       "          [[ 1.3784e-02,  4.7967e-04,  3.6894e-02],\n",
       "           [-2.2500e-02,  5.7253e-03, -6.8568e-03],\n",
       "           [-5.3178e-04, -9.3551e-03,  1.6281e-02]],\n",
       " \n",
       "          [[-5.6531e-02,  1.3616e-02, -9.1450e-03],\n",
       "           [ 2.1466e-02, -5.0649e-03, -1.2969e-02],\n",
       "           [-2.9003e-02, -5.0936e-02,  2.3534e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4474e-02, -3.4560e-02,  3.1644e-02],\n",
       "           [ 3.5803e-03, -1.1084e-02, -1.8346e-02],\n",
       "           [-4.2644e-02,  1.0205e-02, -2.1154e-02]],\n",
       " \n",
       "          [[-2.3808e-02, -7.9876e-03, -1.1751e-03],\n",
       "           [-6.7307e-02,  1.9469e-02, -1.2357e-02],\n",
       "           [ 5.2194e-03,  1.3300e-02, -5.2406e-03]],\n",
       " \n",
       "          [[-1.8267e-02,  1.3882e-02,  1.2601e-02],\n",
       "           [-2.7248e-02,  5.0274e-02, -3.6439e-03],\n",
       "           [ 2.8960e-04, -1.0494e-02, -9.7237e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.2747e-02,  2.0981e-02, -2.3858e-02],\n",
       "           [-4.9442e-02, -3.8948e-03,  1.3600e-02],\n",
       "           [-2.9295e-02,  9.2007e-03,  3.0373e-03]],\n",
       " \n",
       "          [[-6.9579e-03,  8.7743e-03, -3.3106e-02],\n",
       "           [-2.2953e-02, -3.2553e-02, -2.0746e-02],\n",
       "           [ 1.1593e-02,  3.1816e-02, -3.3620e-03]],\n",
       " \n",
       "          [[ 2.5469e-02,  5.1409e-03, -2.7159e-04],\n",
       "           [-3.7363e-02, -7.2634e-03, -9.1048e-03],\n",
       "           [ 1.6094e-02,  3.0067e-02,  3.3052e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3404e-02,  3.5821e-03,  1.6879e-02],\n",
       "           [ 2.1417e-02,  1.1322e-03,  3.6526e-02],\n",
       "           [-3.8131e-02, -1.1656e-02, -2.3479e-03]],\n",
       " \n",
       "          [[ 1.4630e-03, -5.7614e-02,  2.1873e-02],\n",
       "           [-4.4296e-02, -9.9840e-03,  1.6140e-02],\n",
       "           [-5.6225e-02, -1.1892e-02,  3.0080e-02]],\n",
       " \n",
       "          [[-2.2538e-02,  1.0508e-02, -1.2335e-02],\n",
       "           [ 3.9261e-02,  9.9855e-03, -3.9732e-03],\n",
       "           [ 5.1911e-02,  7.0928e-04,  2.0277e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0830e-02,  1.3179e-02, -1.1365e-02],\n",
       "           [ 1.3227e-02, -6.1150e-03,  1.4702e-02],\n",
       "           [-2.6282e-02,  1.2380e-02, -2.1944e-02]],\n",
       " \n",
       "          [[ 3.1544e-02,  1.9749e-02, -3.4683e-02],\n",
       "           [-8.6723e-03,  1.0845e-02,  2.7259e-02],\n",
       "           [-2.0152e-02, -1.0344e-02,  3.7518e-03]],\n",
       " \n",
       "          [[-1.9366e-02, -3.4106e-02,  1.1735e-02],\n",
       "           [ 2.8250e-02, -1.9224e-02,  9.4163e-03],\n",
       "           [-2.2035e-03,  1.1503e-02, -7.1741e-03]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.30.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.31.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.31.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.33.weight': Parameter containing:\n",
       " tensor([[[[ 2.1471e-02,  1.8604e-03,  8.3522e-03],\n",
       "           [-1.6332e-02, -1.5442e-02,  1.6288e-02],\n",
       "           [-2.6175e-02, -2.9638e-02,  3.4001e-02]],\n",
       " \n",
       "          [[-1.6541e-03,  4.7384e-04,  5.9486e-03],\n",
       "           [ 6.0166e-02,  2.6690e-02,  3.2948e-03],\n",
       "           [ 2.8244e-03,  1.1287e-03, -3.1718e-03]],\n",
       " \n",
       "          [[-4.2370e-02, -2.3021e-02, -2.4163e-03],\n",
       "           [ 1.9447e-02,  5.7640e-03, -3.2165e-02],\n",
       "           [-1.7903e-02,  8.9144e-03, -1.0473e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.3529e-02,  1.5719e-02, -8.3524e-03],\n",
       "           [ 3.5407e-02, -1.7548e-02,  4.4167e-03],\n",
       "           [-2.3987e-03,  5.9358e-03, -9.9094e-04]],\n",
       " \n",
       "          [[ 1.4546e-02, -8.2034e-03,  1.4053e-02],\n",
       "           [ 5.8074e-03, -4.5693e-03, -1.2890e-03],\n",
       "           [-8.9265e-03, -1.7198e-02,  1.5745e-02]],\n",
       " \n",
       "          [[-1.5787e-02, -2.6652e-02, -1.2034e-03],\n",
       "           [ 7.3850e-03,  1.4731e-02,  4.4927e-03],\n",
       "           [ 2.9701e-02,  2.7380e-02,  1.1821e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.4851e-04,  6.5681e-03, -3.6023e-03],\n",
       "           [ 3.1206e-02, -2.9693e-02,  2.3454e-03],\n",
       "           [-1.0684e-03, -6.3867e-03,  1.9128e-02]],\n",
       " \n",
       "          [[-3.4737e-03,  1.2468e-02, -1.7760e-02],\n",
       "           [-3.1598e-02, -1.2424e-02, -4.5208e-02],\n",
       "           [ 1.2926e-02, -2.8705e-02,  1.0385e-02]],\n",
       " \n",
       "          [[-9.3745e-03, -1.2794e-02, -1.9513e-03],\n",
       "           [-2.3755e-03,  1.7537e-02, -1.3486e-02],\n",
       "           [-1.4809e-02, -1.5920e-02, -1.2521e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.4126e-02, -1.1409e-02,  2.7147e-03],\n",
       "           [ 2.0843e-02,  2.4396e-02,  3.2438e-02],\n",
       "           [ 6.7365e-03,  5.6153e-03, -2.3449e-03]],\n",
       " \n",
       "          [[-5.9201e-03, -3.1239e-02, -6.9459e-03],\n",
       "           [-6.7473e-03, -1.4400e-02, -3.5719e-02],\n",
       "           [ 1.6081e-02, -9.6824e-03, -3.8183e-02]],\n",
       " \n",
       "          [[ 1.1518e-02,  3.5559e-02,  1.3280e-03],\n",
       "           [-5.0112e-04,  1.2819e-02,  4.9537e-03],\n",
       "           [ 7.9658e-04,  3.7727e-03, -2.0951e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.8156e-04, -1.0853e-02,  4.4098e-03],\n",
       "           [-6.3978e-03, -2.0281e-02, -4.0628e-02],\n",
       "           [ 1.6921e-02, -4.1891e-03,  1.0142e-02]],\n",
       " \n",
       "          [[-1.9372e-02,  6.5160e-02, -1.5538e-02],\n",
       "           [-1.3482e-02,  2.4779e-03, -3.3352e-02],\n",
       "           [ 3.0378e-02, -3.8185e-03, -4.0025e-02]],\n",
       " \n",
       "          [[-2.5827e-02, -5.2011e-03,  2.9945e-02],\n",
       "           [-1.6844e-02,  1.7380e-03, -2.9631e-02],\n",
       "           [ 1.3596e-02, -8.1900e-03,  4.0030e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.2020e-02,  1.7934e-02,  3.5276e-02],\n",
       "           [ 1.7446e-02,  1.2726e-02,  7.9015e-03],\n",
       "           [ 2.7677e-04, -3.1385e-03,  4.3325e-02]],\n",
       " \n",
       "          [[-1.7879e-02,  2.8933e-02,  4.3150e-03],\n",
       "           [-8.7237e-03, -4.0734e-02, -1.8791e-02],\n",
       "           [-1.7798e-02, -4.0865e-02,  5.8690e-03]],\n",
       " \n",
       "          [[-3.8254e-03, -6.9043e-04,  2.2977e-02],\n",
       "           [-3.1566e-02,  1.6668e-02, -1.7045e-02],\n",
       "           [ 1.9159e-02, -1.0460e-02, -3.7842e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.4830e-02, -8.5367e-03,  3.3032e-03],\n",
       "           [ 7.9915e-04, -1.3851e-02, -1.2386e-02],\n",
       "           [-2.1078e-02, -1.9308e-02,  5.9157e-02]],\n",
       " \n",
       "          [[ 1.6909e-02, -3.8096e-02, -1.4605e-02],\n",
       "           [-5.3155e-02,  7.4769e-03, -3.6422e-03],\n",
       "           [ 3.7052e-02,  1.0877e-02,  7.7968e-03]],\n",
       " \n",
       "          [[-2.6054e-02, -8.9425e-03,  1.4495e-02],\n",
       "           [ 1.1752e-03,  1.9092e-02,  3.0509e-02],\n",
       "           [ 8.8037e-03, -1.7048e-02, -8.5969e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.0770e-03, -2.0309e-02, -1.1478e-03],\n",
       "           [ 2.8929e-02, -1.8078e-02, -1.6630e-02],\n",
       "           [-6.0580e-03,  1.1777e-02, -5.2318e-03]],\n",
       " \n",
       "          [[-5.7931e-03,  4.6499e-02, -1.4119e-02],\n",
       "           [ 1.3035e-02,  6.4014e-03,  7.6719e-03],\n",
       "           [ 3.7400e-03,  3.4687e-03, -2.2088e-02]],\n",
       " \n",
       "          [[-2.9607e-02,  4.6132e-03,  8.6504e-03],\n",
       "           [ 2.5276e-02,  1.9063e-02,  6.5761e-04],\n",
       "           [-2.9988e-02,  6.3257e-03,  6.4259e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.3828e-02, -1.9585e-02,  3.0121e-02],\n",
       "           [-1.1501e-02, -8.9647e-03, -1.4283e-02],\n",
       "           [ 9.1358e-03, -7.6645e-03, -1.2254e-02]],\n",
       " \n",
       "          [[-2.6999e-02, -1.9118e-03,  2.4371e-02],\n",
       "           [-2.4590e-02,  2.0046e-02,  1.0951e-02],\n",
       "           [ 3.6958e-02, -1.5884e-02, -4.6278e-03]],\n",
       " \n",
       "          [[-7.3709e-03, -1.7508e-02, -1.0034e-03],\n",
       "           [-4.5367e-02, -5.3388e-03,  8.9237e-03],\n",
       "           [ 2.6826e-04,  4.1873e-02,  1.7250e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1644e-02, -1.2267e-02, -2.7030e-02],\n",
       "           [-3.5904e-02,  1.8805e-02, -1.3219e-02],\n",
       "           [-2.5328e-02,  1.4499e-02,  1.9361e-02]],\n",
       " \n",
       "          [[-1.0786e-02, -1.4680e-02, -3.9750e-02],\n",
       "           [-2.6840e-03, -9.7520e-03, -1.0177e-02],\n",
       "           [-1.7482e-02,  2.8903e-02, -2.7427e-02]],\n",
       " \n",
       "          [[-1.3904e-02, -1.9772e-02, -1.0533e-02],\n",
       "           [-1.8844e-02,  2.7131e-02, -1.8270e-02],\n",
       "           [ 3.0545e-03, -1.1459e-02,  1.8518e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1242e-02,  2.4163e-02, -1.6244e-02],\n",
       "           [ 1.7287e-02,  2.6678e-02, -6.7076e-03],\n",
       "           [ 1.5498e-02, -1.8408e-02, -3.5010e-03]],\n",
       " \n",
       "          [[-1.7351e-02,  8.6584e-03, -2.4157e-02],\n",
       "           [-2.6048e-02,  2.0790e-02,  2.2185e-03],\n",
       "           [ 3.0480e-02,  2.9685e-02,  3.7027e-03]],\n",
       " \n",
       "          [[ 5.0477e-02,  3.2396e-02,  2.9530e-02],\n",
       "           [-7.7902e-03,  3.2905e-02,  1.6774e-02],\n",
       "           [ 7.2595e-06,  7.0550e-03, -2.2954e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3517e-02, -5.6296e-04,  7.0488e-04],\n",
       "           [ 2.3820e-02, -2.6994e-03, -1.5063e-04],\n",
       "           [-2.6766e-02,  2.1848e-02, -1.7987e-02]],\n",
       " \n",
       "          [[-1.7070e-02,  1.7770e-02,  6.5371e-03],\n",
       "           [ 2.2551e-02, -3.2172e-02,  2.2507e-02],\n",
       "           [ 2.5157e-02,  2.4498e-02,  2.0650e-02]],\n",
       " \n",
       "          [[-3.3460e-02, -3.7161e-02, -2.9198e-02],\n",
       "           [-8.2037e-03, -1.9557e-02,  2.4960e-02],\n",
       "           [ 2.6394e-02, -1.4361e-02, -5.2024e-03]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.33.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.34.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.34.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.36.weight': Parameter containing:\n",
       " tensor([[[[-0.0118, -0.0245,  0.0145],\n",
       "           [ 0.0007, -0.0183,  0.0146],\n",
       "           [-0.0025, -0.0325,  0.0136]],\n",
       " \n",
       "          [[ 0.0052,  0.0075, -0.0256],\n",
       "           [ 0.0140,  0.0090, -0.0152],\n",
       "           [-0.0158, -0.0231, -0.0241]],\n",
       " \n",
       "          [[-0.0254, -0.0203,  0.0078],\n",
       "           [ 0.0376,  0.0027, -0.0021],\n",
       "           [-0.0078, -0.0061, -0.0358]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0139,  0.0229, -0.0329],\n",
       "           [ 0.0182, -0.0077, -0.0177],\n",
       "           [ 0.0051, -0.0300,  0.0098]],\n",
       " \n",
       "          [[-0.0086, -0.0104, -0.0085],\n",
       "           [-0.0135,  0.0169, -0.0223],\n",
       "           [ 0.0053,  0.0227, -0.0310]],\n",
       " \n",
       "          [[-0.0067,  0.0102, -0.0329],\n",
       "           [ 0.0155,  0.0188, -0.0336],\n",
       "           [ 0.0330,  0.0244,  0.0183]]],\n",
       " \n",
       " \n",
       "         [[[-0.0228, -0.0069, -0.0130],\n",
       "           [-0.0312, -0.0093, -0.0251],\n",
       "           [-0.0015,  0.0005, -0.0210]],\n",
       " \n",
       "          [[ 0.0443,  0.0037,  0.0155],\n",
       "           [ 0.0146, -0.0031,  0.0404],\n",
       "           [-0.0411,  0.0300,  0.0078]],\n",
       " \n",
       "          [[ 0.0179,  0.0172, -0.0274],\n",
       "           [ 0.0092,  0.0047, -0.0046],\n",
       "           [ 0.0285,  0.0155, -0.0034]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0015, -0.0108,  0.0048],\n",
       "           [-0.0031,  0.0250, -0.0362],\n",
       "           [-0.0128, -0.0278,  0.0004]],\n",
       " \n",
       "          [[ 0.0134, -0.0302, -0.0142],\n",
       "           [ 0.0031,  0.0077, -0.0423],\n",
       "           [-0.0134,  0.0015, -0.0019]],\n",
       " \n",
       "          [[-0.0126,  0.0245,  0.0055],\n",
       "           [-0.0031, -0.0045,  0.0104],\n",
       "           [-0.0260, -0.0187, -0.0190]]],\n",
       " \n",
       " \n",
       "         [[[-0.0019,  0.0009,  0.0090],\n",
       "           [ 0.0002,  0.0098,  0.0115],\n",
       "           [-0.0056,  0.0245, -0.0050]],\n",
       " \n",
       "          [[ 0.0042, -0.0089,  0.0106],\n",
       "           [ 0.0337,  0.0008,  0.0239],\n",
       "           [-0.0138,  0.0213,  0.0016]],\n",
       " \n",
       "          [[ 0.0286,  0.0039, -0.0217],\n",
       "           [-0.0347,  0.0358,  0.0135],\n",
       "           [ 0.0539,  0.0028, -0.0167]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0063,  0.0115, -0.0300],\n",
       "           [-0.0005,  0.0097,  0.0046],\n",
       "           [-0.0183,  0.0037, -0.0284]],\n",
       " \n",
       "          [[ 0.0116, -0.0431, -0.0124],\n",
       "           [-0.0212, -0.0418, -0.0219],\n",
       "           [-0.0401, -0.0417,  0.0103]],\n",
       " \n",
       "          [[-0.0225, -0.0047, -0.0076],\n",
       "           [ 0.0375,  0.0295, -0.0148],\n",
       "           [-0.0021, -0.0328, -0.0411]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0039, -0.0192, -0.0127],\n",
       "           [-0.0191,  0.0097, -0.0021],\n",
       "           [ 0.0188,  0.0056,  0.0004]],\n",
       " \n",
       "          [[-0.0048,  0.0011, -0.0015],\n",
       "           [-0.0119,  0.0365,  0.0258],\n",
       "           [ 0.0305,  0.0047,  0.0011]],\n",
       " \n",
       "          [[ 0.0325, -0.0202, -0.0178],\n",
       "           [ 0.0092,  0.0237, -0.0153],\n",
       "           [ 0.0056,  0.0194, -0.0031]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0193,  0.0736, -0.0002],\n",
       "           [-0.0069, -0.0094,  0.0019],\n",
       "           [-0.0158,  0.0137,  0.0135]],\n",
       " \n",
       "          [[-0.0231, -0.0120,  0.0467],\n",
       "           [ 0.0151, -0.0099, -0.0064],\n",
       "           [ 0.0143, -0.0176,  0.0342]],\n",
       " \n",
       "          [[ 0.0321, -0.0670, -0.0190],\n",
       "           [-0.0056, -0.0484,  0.0009],\n",
       "           [ 0.0419,  0.0254,  0.0106]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0071, -0.0068,  0.0023],\n",
       "           [ 0.0356, -0.0134,  0.0076],\n",
       "           [-0.0239, -0.0159, -0.0212]],\n",
       " \n",
       "          [[ 0.0112, -0.0057,  0.0019],\n",
       "           [-0.0030,  0.0054, -0.0186],\n",
       "           [ 0.0038,  0.0168, -0.0061]],\n",
       " \n",
       "          [[-0.0128, -0.0065, -0.0128],\n",
       "           [ 0.0357,  0.0125, -0.0274],\n",
       "           [ 0.0005,  0.0583,  0.0119]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0212,  0.0230, -0.0226],\n",
       "           [ 0.0215,  0.0030,  0.0032],\n",
       "           [-0.0035,  0.0192, -0.0282]],\n",
       " \n",
       "          [[-0.0152, -0.0042, -0.0146],\n",
       "           [-0.0224,  0.0198,  0.0210],\n",
       "           [ 0.0245,  0.0088,  0.0246]],\n",
       " \n",
       "          [[ 0.0016, -0.0076, -0.0018],\n",
       "           [ 0.0297,  0.0211, -0.0287],\n",
       "           [ 0.0151,  0.0058, -0.0078]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0223, -0.0033,  0.0070],\n",
       "           [-0.0104, -0.0185, -0.0305],\n",
       "           [ 0.0185, -0.0064,  0.0038]],\n",
       " \n",
       "          [[ 0.0088, -0.0124,  0.0191],\n",
       "           [-0.0286,  0.0044, -0.0083],\n",
       "           [-0.0301,  0.0180, -0.0050]],\n",
       " \n",
       "          [[-0.0262, -0.0203,  0.0043],\n",
       "           [-0.0009,  0.0150, -0.0004],\n",
       "           [-0.0181, -0.0134,  0.0128]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0040,  0.0330,  0.0227],\n",
       "           [-0.0195,  0.0160,  0.0273],\n",
       "           [-0.0493, -0.0282, -0.0283]],\n",
       " \n",
       "          [[ 0.0250,  0.0144, -0.0069],\n",
       "           [ 0.0144,  0.0054,  0.0039],\n",
       "           [ 0.0186, -0.0236, -0.0084]],\n",
       " \n",
       "          [[ 0.0016, -0.0264,  0.0041],\n",
       "           [-0.0056,  0.0384, -0.0448],\n",
       "           [ 0.0216, -0.0025,  0.0016]]]], device='cuda:0', requires_grad=True),\n",
       " 'module.features.36.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.37.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.37.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.40.weight': Parameter containing:\n",
       " tensor([[[[ 0.0229, -0.0268, -0.0071],\n",
       "           [ 0.0032, -0.0085, -0.0028],\n",
       "           [ 0.0067,  0.0074, -0.0020]],\n",
       " \n",
       "          [[ 0.0188, -0.0012,  0.0132],\n",
       "           [ 0.0479, -0.0146, -0.0092],\n",
       "           [ 0.0057,  0.0276,  0.0271]],\n",
       " \n",
       "          [[-0.0011,  0.0035, -0.0164],\n",
       "           [ 0.0052, -0.0513,  0.0352],\n",
       "           [-0.0090,  0.0271, -0.0015]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0131,  0.0111,  0.0123],\n",
       "           [ 0.0199,  0.0016,  0.0110],\n",
       "           [-0.0262, -0.0032,  0.0501]],\n",
       " \n",
       "          [[ 0.0009, -0.0086,  0.0249],\n",
       "           [ 0.0208,  0.0317,  0.0372],\n",
       "           [-0.0113, -0.0014,  0.0190]],\n",
       " \n",
       "          [[ 0.0175, -0.0284, -0.0095],\n",
       "           [ 0.0099,  0.0190, -0.0200],\n",
       "           [ 0.0148,  0.0312, -0.0140]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0455, -0.0065, -0.0505],\n",
       "           [ 0.0082, -0.0159,  0.0077],\n",
       "           [ 0.0185,  0.0219, -0.0288]],\n",
       " \n",
       "          [[-0.0667, -0.0239, -0.0452],\n",
       "           [ 0.0172,  0.0031, -0.0285],\n",
       "           [ 0.0056,  0.0174,  0.0033]],\n",
       " \n",
       "          [[-0.0051, -0.0216,  0.0216],\n",
       "           [-0.0007,  0.0170,  0.0193],\n",
       "           [-0.0080,  0.0073, -0.0117]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0416, -0.0254, -0.0349],\n",
       "           [-0.0067, -0.0208,  0.0008],\n",
       "           [ 0.0057, -0.0057, -0.0032]],\n",
       " \n",
       "          [[ 0.0443,  0.0091, -0.0087],\n",
       "           [ 0.0106,  0.0178,  0.0106],\n",
       "           [ 0.0042, -0.0063,  0.0320]],\n",
       " \n",
       "          [[ 0.0172,  0.0020, -0.0031],\n",
       "           [-0.0341,  0.0116,  0.0201],\n",
       "           [-0.0265, -0.0358, -0.0092]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0182,  0.0028,  0.0025],\n",
       "           [ 0.0200, -0.0391, -0.0289],\n",
       "           [-0.0294, -0.0039, -0.0026]],\n",
       " \n",
       "          [[ 0.0032,  0.0066,  0.0249],\n",
       "           [-0.0375, -0.0022,  0.0325],\n",
       "           [ 0.0090,  0.0064, -0.0251]],\n",
       " \n",
       "          [[-0.0301,  0.0225,  0.0062],\n",
       "           [-0.0007,  0.0180,  0.0188],\n",
       "           [ 0.0048, -0.0143, -0.0278]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0090,  0.0302,  0.0400],\n",
       "           [ 0.0234, -0.0047,  0.0018],\n",
       "           [ 0.0113, -0.0071, -0.0028]],\n",
       " \n",
       "          [[ 0.0205, -0.0300, -0.0277],\n",
       "           [-0.0047, -0.0077,  0.0046],\n",
       "           [ 0.0324,  0.0004,  0.0096]],\n",
       " \n",
       "          [[-0.0147, -0.0082,  0.0376],\n",
       "           [-0.0347, -0.0110, -0.0104],\n",
       "           [ 0.0046, -0.0172, -0.0344]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0326,  0.0048, -0.0096],\n",
       "           [ 0.0145, -0.0072,  0.0165],\n",
       "           [-0.0071,  0.0237,  0.0125]],\n",
       " \n",
       "          [[-0.0114, -0.0036, -0.0164],\n",
       "           [ 0.0075,  0.0050, -0.0029],\n",
       "           [ 0.0392,  0.0030, -0.0379]],\n",
       " \n",
       "          [[ 0.0100,  0.0124,  0.0333],\n",
       "           [ 0.0046, -0.0045, -0.0303],\n",
       "           [ 0.0105,  0.0137,  0.0142]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0380, -0.0120,  0.0075],\n",
       "           [ 0.0044,  0.0356,  0.0374],\n",
       "           [ 0.0019, -0.0161, -0.0060]],\n",
       " \n",
       "          [[-0.0090, -0.0183, -0.0107],\n",
       "           [ 0.0213, -0.0050, -0.0181],\n",
       "           [ 0.0240, -0.0169, -0.0058]],\n",
       " \n",
       "          [[ 0.0173,  0.0084, -0.0014],\n",
       "           [ 0.0059,  0.0129, -0.0123],\n",
       "           [ 0.0122,  0.0266, -0.0444]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0209, -0.0177, -0.0328],\n",
       "           [-0.0324, -0.0134,  0.0088],\n",
       "           [-0.0369,  0.0192, -0.0078]],\n",
       " \n",
       "          [[-0.0046, -0.0077, -0.0105],\n",
       "           [ 0.0003, -0.0281,  0.0226],\n",
       "           [ 0.0197, -0.0084, -0.0089]],\n",
       " \n",
       "          [[ 0.0423,  0.0531, -0.0026],\n",
       "           [-0.0061,  0.0269,  0.0097],\n",
       "           [-0.0219,  0.0074,  0.0083]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0066,  0.0187, -0.0231],\n",
       "           [ 0.0483, -0.0370, -0.0176],\n",
       "           [-0.0238, -0.0267, -0.0056]],\n",
       " \n",
       "          [[-0.0149,  0.0159, -0.0224],\n",
       "           [ 0.0232, -0.0247, -0.0174],\n",
       "           [-0.0128,  0.0015, -0.0152]],\n",
       " \n",
       "          [[ 0.0126, -0.0134, -0.0178],\n",
       "           [-0.0044,  0.0033, -0.0129],\n",
       "           [-0.0123,  0.0009,  0.0027]]],\n",
       " \n",
       " \n",
       "         [[[-0.0170,  0.0114,  0.0231],\n",
       "           [ 0.0204,  0.0201, -0.0092],\n",
       "           [ 0.0125,  0.0506,  0.0461]],\n",
       " \n",
       "          [[ 0.0160,  0.0098,  0.0145],\n",
       "           [ 0.0195,  0.0038, -0.0311],\n",
       "           [-0.0080,  0.0009, -0.0061]],\n",
       " \n",
       "          [[ 0.0182,  0.0385,  0.0011],\n",
       "           [ 0.0292, -0.0026,  0.0078],\n",
       "           [-0.0209,  0.0152, -0.0126]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0061,  0.0305, -0.0107],\n",
       "           [-0.0094, -0.0281, -0.0312],\n",
       "           [ 0.0251, -0.0048, -0.0231]],\n",
       " \n",
       "          [[-0.0102, -0.0071,  0.0407],\n",
       "           [ 0.0281, -0.0052, -0.0088],\n",
       "           [ 0.0104,  0.0016,  0.0114]],\n",
       " \n",
       "          [[-0.0039,  0.0100,  0.0287],\n",
       "           [-0.0265,  0.0141,  0.0035],\n",
       "           [-0.0082,  0.0016, -0.0385]]]], device='cuda:0', requires_grad=True),\n",
       " 'module.features.40.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.41.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.41.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.43.weight': Parameter containing:\n",
       " tensor([[[[-0.0018,  0.0028,  0.0186],\n",
       "           [-0.0323, -0.0084,  0.0216],\n",
       "           [-0.0062,  0.0286,  0.0053]],\n",
       " \n",
       "          [[-0.0112, -0.0125, -0.0107],\n",
       "           [ 0.0350, -0.0088, -0.0233],\n",
       "           [-0.0150,  0.0198,  0.0126]],\n",
       " \n",
       "          [[ 0.0273, -0.0199, -0.0392],\n",
       "           [ 0.0078, -0.0206,  0.0180],\n",
       "           [-0.0079, -0.0016, -0.0125]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0128, -0.0156, -0.0362],\n",
       "           [-0.0120,  0.0206, -0.0094],\n",
       "           [ 0.0162,  0.0131, -0.0405]],\n",
       " \n",
       "          [[ 0.0388,  0.0146, -0.0022],\n",
       "           [ 0.0089, -0.0259,  0.0621],\n",
       "           [ 0.0266,  0.0029,  0.0108]],\n",
       " \n",
       "          [[ 0.0121,  0.0290, -0.0118],\n",
       "           [ 0.0077,  0.0312,  0.0285],\n",
       "           [-0.0126,  0.0256,  0.0216]]],\n",
       " \n",
       " \n",
       "         [[[-0.0327, -0.0032,  0.0198],\n",
       "           [-0.0020,  0.0126,  0.0287],\n",
       "           [ 0.0186,  0.0152,  0.0219]],\n",
       " \n",
       "          [[ 0.0484, -0.0215, -0.0413],\n",
       "           [ 0.0015,  0.0146,  0.0106],\n",
       "           [-0.0221,  0.0157,  0.0232]],\n",
       " \n",
       "          [[-0.0087, -0.0103, -0.0148],\n",
       "           [-0.0065,  0.0012, -0.0296],\n",
       "           [-0.0109, -0.0029, -0.0393]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0074,  0.0041,  0.0188],\n",
       "           [ 0.0195,  0.0242,  0.0131],\n",
       "           [ 0.0132, -0.0003, -0.0042]],\n",
       " \n",
       "          [[ 0.0496, -0.0188, -0.0299],\n",
       "           [ 0.0304,  0.0155,  0.0103],\n",
       "           [ 0.0094, -0.0074, -0.0239]],\n",
       " \n",
       "          [[ 0.0113,  0.0152, -0.0010],\n",
       "           [ 0.0187,  0.0081, -0.0299],\n",
       "           [-0.0183,  0.0044, -0.0236]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0082, -0.0078,  0.0008],\n",
       "           [ 0.0252, -0.0057, -0.0067],\n",
       "           [-0.0366,  0.0335,  0.0150]],\n",
       " \n",
       "          [[-0.0109,  0.0251, -0.0055],\n",
       "           [ 0.0149, -0.0138, -0.0361],\n",
       "           [ 0.0031, -0.0219, -0.0197]],\n",
       " \n",
       "          [[ 0.0095, -0.0074, -0.0163],\n",
       "           [ 0.0112, -0.0023,  0.0148],\n",
       "           [ 0.0254, -0.0253,  0.0098]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0298,  0.0149, -0.0181],\n",
       "           [-0.0296, -0.0010, -0.0209],\n",
       "           [-0.0467,  0.0045,  0.0069]],\n",
       " \n",
       "          [[ 0.0193,  0.0009, -0.0475],\n",
       "           [ 0.0370, -0.0066, -0.0047],\n",
       "           [-0.0167,  0.0028,  0.0045]],\n",
       " \n",
       "          [[ 0.0224,  0.0333, -0.0014],\n",
       "           [-0.0283,  0.0248, -0.0020],\n",
       "           [-0.0215,  0.0151,  0.0330]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0126, -0.0098,  0.0266],\n",
       "           [-0.0057, -0.0244, -0.0613],\n",
       "           [ 0.0228, -0.0187,  0.0105]],\n",
       " \n",
       "          [[-0.0262, -0.0188,  0.0071],\n",
       "           [ 0.0282, -0.0080,  0.0201],\n",
       "           [-0.0085,  0.0049, -0.0114]],\n",
       " \n",
       "          [[ 0.0183,  0.0431,  0.0185],\n",
       "           [-0.0269,  0.0233,  0.0062],\n",
       "           [-0.0146,  0.0126, -0.0136]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0418, -0.0005,  0.0367],\n",
       "           [ 0.0242, -0.0052, -0.0250],\n",
       "           [ 0.0278,  0.0017, -0.0080]],\n",
       " \n",
       "          [[-0.0100, -0.0073,  0.0096],\n",
       "           [ 0.0106, -0.0181,  0.0156],\n",
       "           [ 0.0104, -0.0034, -0.0149]],\n",
       " \n",
       "          [[ 0.0415,  0.0166,  0.0117],\n",
       "           [ 0.0063, -0.0084,  0.0244],\n",
       "           [ 0.0027, -0.0014,  0.0067]]],\n",
       " \n",
       " \n",
       "         [[[-0.0159, -0.0190,  0.0176],\n",
       "           [ 0.0132,  0.0018, -0.0366],\n",
       "           [-0.0126,  0.0339, -0.0151]],\n",
       " \n",
       "          [[-0.0026,  0.0228,  0.0175],\n",
       "           [-0.0066,  0.0048,  0.0478],\n",
       "           [ 0.0145,  0.0332,  0.0169]],\n",
       " \n",
       "          [[-0.0262, -0.0216, -0.0075],\n",
       "           [-0.0033,  0.0122, -0.0407],\n",
       "           [-0.0248,  0.0008,  0.0073]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0014, -0.0029, -0.0122],\n",
       "           [ 0.0508,  0.0091,  0.0445],\n",
       "           [-0.0033, -0.0497,  0.0202]],\n",
       " \n",
       "          [[-0.0194,  0.0114, -0.0212],\n",
       "           [-0.0172, -0.0078, -0.0038],\n",
       "           [ 0.0072,  0.0133, -0.0253]],\n",
       " \n",
       "          [[ 0.0132,  0.0020,  0.0050],\n",
       "           [ 0.0095, -0.0551, -0.0263],\n",
       "           [ 0.0354,  0.0097, -0.0042]]],\n",
       " \n",
       " \n",
       "         [[[-0.0061, -0.0092,  0.0136],\n",
       "           [ 0.0253,  0.0065,  0.0109],\n",
       "           [-0.0166,  0.0329, -0.0146]],\n",
       " \n",
       "          [[ 0.0144, -0.0050,  0.0669],\n",
       "           [ 0.0228,  0.0333,  0.0074],\n",
       "           [-0.0533, -0.0130, -0.0040]],\n",
       " \n",
       "          [[-0.0176,  0.0124, -0.0115],\n",
       "           [ 0.0065,  0.0080, -0.0038],\n",
       "           [-0.0110,  0.0248, -0.0200]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0004, -0.0027,  0.0254],\n",
       "           [-0.0002,  0.0138, -0.0382],\n",
       "           [ 0.0239, -0.0140,  0.0112]],\n",
       " \n",
       "          [[-0.0213, -0.0088, -0.0010],\n",
       "           [ 0.0482, -0.0150, -0.0204],\n",
       "           [ 0.0095,  0.0064, -0.0150]],\n",
       " \n",
       "          [[-0.0091,  0.0180, -0.0041],\n",
       "           [-0.0026,  0.0389,  0.0189],\n",
       "           [-0.0104, -0.0280,  0.0187]]]], device='cuda:0', requires_grad=True),\n",
       " 'module.features.43.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.44.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.44.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.46.weight': Parameter containing:\n",
       " tensor([[[[-1.1372e-02, -2.3976e-02,  1.7262e-02],\n",
       "           [-7.1015e-03,  5.5880e-03,  5.9231e-03],\n",
       "           [-2.0783e-02, -1.6168e-02, -8.0162e-03]],\n",
       " \n",
       "          [[-7.9521e-03,  2.4367e-02, -1.4256e-02],\n",
       "           [ 4.4392e-03,  2.9455e-02,  1.5319e-02],\n",
       "           [ 9.9874e-03,  4.9965e-02, -7.5612e-04]],\n",
       " \n",
       "          [[-9.4844e-03,  2.2066e-02, -1.0003e-02],\n",
       "           [-1.4851e-02, -2.0970e-02,  1.2093e-02],\n",
       "           [ 3.8552e-02,  2.5560e-02,  2.7576e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.4680e-03, -2.8124e-02,  1.4416e-02],\n",
       "           [ 5.9335e-03, -1.7983e-02,  1.6219e-02],\n",
       "           [-2.1615e-02,  4.3176e-03, -2.6688e-02]],\n",
       " \n",
       "          [[ 1.2257e-02,  2.9762e-02,  1.1219e-02],\n",
       "           [-2.9771e-02,  4.4544e-02,  2.4362e-02],\n",
       "           [ 2.5573e-02, -1.3895e-02, -2.7866e-02]],\n",
       " \n",
       "          [[ 6.5589e-02,  1.8503e-02,  3.1176e-03],\n",
       "           [ 1.5471e-02,  8.0006e-03,  3.0037e-03],\n",
       "           [-1.4117e-02, -4.1985e-02, -2.3411e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.4739e-02, -2.3097e-02, -1.3653e-04],\n",
       "           [ 1.3114e-04, -1.8459e-02, -1.0848e-02],\n",
       "           [ 3.8575e-03, -2.2472e-03,  8.3770e-03]],\n",
       " \n",
       "          [[ 5.5279e-03, -1.4461e-02, -3.0352e-02],\n",
       "           [ 3.9164e-03, -4.0845e-02, -1.9849e-03],\n",
       "           [-3.4695e-02, -2.6717e-04,  2.0733e-04]],\n",
       " \n",
       "          [[-4.0964e-02,  3.0527e-02, -1.1369e-02],\n",
       "           [-4.3024e-04,  6.4521e-03,  2.0008e-03],\n",
       "           [-4.7853e-03, -3.4888e-03, -6.2408e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0199e-02, -1.2405e-02,  6.2023e-03],\n",
       "           [-2.6413e-02,  1.9779e-03,  2.3835e-02],\n",
       "           [ 2.1599e-02, -2.0483e-02,  2.4330e-02]],\n",
       " \n",
       "          [[-1.0351e-02,  1.1961e-02, -2.1510e-02],\n",
       "           [ 9.0342e-03, -1.9872e-02, -2.8266e-02],\n",
       "           [-2.3607e-02, -7.3885e-03, -1.5574e-02]],\n",
       " \n",
       "          [[ 3.1231e-02, -1.7975e-02,  8.6782e-03],\n",
       "           [ 1.8775e-02, -2.6340e-02, -4.5786e-03],\n",
       "           [-1.9780e-02, -5.6175e-02, -1.5544e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.8388e-02,  1.0525e-02,  2.7607e-02],\n",
       "           [ 3.6946e-03, -1.6386e-02, -2.2242e-02],\n",
       "           [ 8.3825e-03,  2.7244e-02,  3.8117e-02]],\n",
       " \n",
       "          [[-7.2820e-04,  2.0990e-02,  3.7265e-03],\n",
       "           [ 2.4203e-02, -5.1117e-04,  7.0046e-03],\n",
       "           [-1.5317e-02,  1.6783e-02,  1.5768e-02]],\n",
       " \n",
       "          [[-3.3484e-03,  1.6129e-02, -6.5140e-03],\n",
       "           [-1.6039e-02, -9.1716e-03,  4.2806e-02],\n",
       "           [-2.1971e-02,  3.4065e-02,  4.3932e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.5918e-03, -1.8037e-02,  1.4932e-02],\n",
       "           [-1.9655e-02,  1.4711e-03, -1.6019e-03],\n",
       "           [-7.9086e-03, -6.5699e-03, -1.1456e-02]],\n",
       " \n",
       "          [[ 4.1379e-03, -3.6785e-02,  2.5591e-03],\n",
       "           [ 8.5875e-03,  1.0125e-02,  7.4905e-03],\n",
       "           [ 2.3903e-02, -2.7387e-03,  6.9184e-04]],\n",
       " \n",
       "          [[ 7.6837e-03, -2.2080e-02, -2.2308e-02],\n",
       "           [ 2.5845e-02,  7.4801e-04, -1.4457e-02],\n",
       "           [-3.6324e-02, -8.3950e-03,  1.9800e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.6955e-02, -4.1244e-02, -2.7727e-02],\n",
       "           [-3.9218e-04, -1.2390e-02, -3.9128e-03],\n",
       "           [ 1.1082e-02, -1.2196e-03,  9.0656e-03]],\n",
       " \n",
       "          [[-7.0615e-03,  1.4686e-02,  3.5989e-04],\n",
       "           [-2.0550e-02, -2.1162e-03, -4.0526e-03],\n",
       "           [-2.2599e-02,  2.8002e-04, -2.5481e-03]],\n",
       " \n",
       "          [[-7.0400e-03, -2.9008e-02, -4.1024e-04],\n",
       "           [ 1.8421e-04,  2.1790e-04, -5.1547e-03],\n",
       "           [ 2.2912e-03, -3.7869e-03, -1.3766e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.3272e-02, -5.2047e-03,  2.4319e-02],\n",
       "           [-3.1578e-02, -1.3452e-02, -3.2484e-02],\n",
       "           [ 3.2023e-04, -3.2215e-03,  5.0856e-03]],\n",
       " \n",
       "          [[-1.4252e-02,  1.9406e-03, -4.2336e-02],\n",
       "           [ 1.3427e-02,  1.5109e-02,  1.4220e-02],\n",
       "           [-1.6212e-03,  2.2406e-02,  2.6197e-02]],\n",
       " \n",
       "          [[-3.8598e-02,  2.7776e-02,  6.9267e-03],\n",
       "           [-1.0934e-02,  2.0220e-02, -1.7692e-02],\n",
       "           [-1.3129e-03,  5.9577e-04, -1.2435e-02]]],\n",
       " \n",
       " \n",
       "         [[[-9.0506e-06, -6.5246e-04, -5.1596e-03],\n",
       "           [-1.1917e-02, -2.4033e-02, -7.9969e-03],\n",
       "           [-4.0337e-02, -4.2490e-02,  1.9728e-02]],\n",
       " \n",
       "          [[ 9.7654e-03, -7.3473e-03, -4.6289e-02],\n",
       "           [ 1.0791e-02,  5.6381e-03, -2.3210e-02],\n",
       "           [ 1.6682e-02,  2.7194e-02,  6.8501e-03]],\n",
       " \n",
       "          [[ 2.2919e-02,  1.7026e-02,  2.6165e-02],\n",
       "           [-8.4058e-03,  1.2541e-02, -2.9087e-02],\n",
       "           [ 3.8091e-03, -4.6458e-03,  7.8787e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3586e-02,  1.2726e-02,  3.6504e-03],\n",
       "           [-1.7228e-02,  6.5079e-04,  4.8690e-03],\n",
       "           [-1.6498e-02, -2.6357e-03,  4.9948e-02]],\n",
       " \n",
       "          [[-2.9566e-03,  5.5689e-02,  4.6339e-03],\n",
       "           [ 3.7458e-02,  2.4698e-02, -1.0655e-02],\n",
       "           [-2.7472e-03, -8.0324e-03,  2.3378e-02]],\n",
       " \n",
       "          [[-2.8080e-02,  3.2075e-02,  4.8737e-03],\n",
       "           [ 3.2677e-03, -9.9466e-03, -2.6920e-02],\n",
       "           [-2.5717e-02, -4.8768e-02,  2.5635e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.1020e-03, -9.4812e-03, -8.8626e-03],\n",
       "           [ 2.0951e-02,  3.0937e-02, -3.0181e-02],\n",
       "           [ 3.4271e-02,  1.7643e-03,  8.0016e-03]],\n",
       " \n",
       "          [[-2.5603e-02,  1.6895e-02, -9.1488e-03],\n",
       "           [ 1.0359e-02,  2.7774e-02,  3.6153e-03],\n",
       "           [ 9.8142e-03,  3.4418e-02, -1.1607e-02]],\n",
       " \n",
       "          [[ 4.2466e-02,  5.1147e-03,  1.4405e-02],\n",
       "           [-5.7052e-02,  1.2876e-02, -2.1514e-02],\n",
       "           [-1.0330e-02,  2.2571e-03,  1.4078e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7410e-02,  1.3567e-02, -1.1929e-02],\n",
       "           [ 2.4245e-02, -6.7390e-03, -3.0790e-02],\n",
       "           [ 5.5704e-03, -2.2036e-02, -2.7380e-02]],\n",
       " \n",
       "          [[ 2.2387e-02, -3.4190e-02, -1.6930e-02],\n",
       "           [-2.0512e-03, -2.0688e-02, -2.2696e-02],\n",
       "           [ 1.3859e-02, -6.2631e-03, -3.7613e-02]],\n",
       " \n",
       "          [[-1.9976e-02,  1.7337e-03,  2.8297e-02],\n",
       "           [-1.6439e-02, -4.7114e-02, -2.1593e-02],\n",
       "           [-1.4962e-02,  1.4360e-02, -2.2642e-02]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " 'module.features.46.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.47.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.47.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.49.weight': Parameter containing:\n",
       " tensor([[[[ 0.0246, -0.0257, -0.0206],\n",
       "           [ 0.0106,  0.0329,  0.0065],\n",
       "           [-0.0113,  0.0092, -0.0133]],\n",
       " \n",
       "          [[-0.0038, -0.0036, -0.0050],\n",
       "           [ 0.0194, -0.0005, -0.0136],\n",
       "           [ 0.0145, -0.0198,  0.0352]],\n",
       " \n",
       "          [[ 0.0279, -0.0047,  0.0414],\n",
       "           [ 0.0098,  0.0015,  0.0191],\n",
       "           [-0.0231, -0.0112, -0.0008]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0408, -0.0201,  0.0165],\n",
       "           [-0.0049, -0.0109, -0.0095],\n",
       "           [-0.0234, -0.0304,  0.0068]],\n",
       " \n",
       "          [[-0.0574, -0.0222, -0.0356],\n",
       "           [-0.0336,  0.0083, -0.0192],\n",
       "           [ 0.0050, -0.0062, -0.0012]],\n",
       " \n",
       "          [[-0.0227, -0.0100, -0.0069],\n",
       "           [-0.0276,  0.0637,  0.0165],\n",
       "           [ 0.0232, -0.0234,  0.0184]]],\n",
       " \n",
       " \n",
       "         [[[-0.0074,  0.0135,  0.0400],\n",
       "           [ 0.0461,  0.0142,  0.0304],\n",
       "           [ 0.0098,  0.0212,  0.0006]],\n",
       " \n",
       "          [[-0.0293,  0.0201,  0.0195],\n",
       "           [ 0.0049, -0.0234,  0.0098],\n",
       "           [-0.0338,  0.0076, -0.0330]],\n",
       " \n",
       "          [[ 0.0176, -0.0117, -0.0032],\n",
       "           [-0.0350, -0.0228, -0.0151],\n",
       "           [ 0.0077,  0.0201,  0.0172]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0100, -0.0073, -0.0040],\n",
       "           [ 0.0177,  0.0008,  0.0047],\n",
       "           [ 0.0077, -0.0253, -0.0002]],\n",
       " \n",
       "          [[ 0.0231,  0.0001,  0.0154],\n",
       "           [ 0.0308,  0.0130,  0.0151],\n",
       "           [-0.0159,  0.0106, -0.0171]],\n",
       " \n",
       "          [[-0.0342,  0.0147,  0.0153],\n",
       "           [-0.0020, -0.0152,  0.0025],\n",
       "           [-0.0257,  0.0237,  0.0214]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0141,  0.0163,  0.0110],\n",
       "           [-0.0135, -0.0010, -0.0455],\n",
       "           [-0.0285, -0.0178,  0.0423]],\n",
       " \n",
       "          [[-0.0172, -0.0231,  0.0178],\n",
       "           [-0.0042, -0.0025,  0.0271],\n",
       "           [-0.0223, -0.0014, -0.0038]],\n",
       " \n",
       "          [[ 0.0205,  0.0077,  0.0045],\n",
       "           [-0.0026, -0.0112,  0.0183],\n",
       "           [ 0.0059, -0.0011, -0.0129]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0161,  0.0044, -0.0153],\n",
       "           [ 0.0392,  0.0010, -0.0041],\n",
       "           [-0.0071,  0.0017, -0.0343]],\n",
       " \n",
       "          [[ 0.0107, -0.0028, -0.0070],\n",
       "           [ 0.0008,  0.0426,  0.0115],\n",
       "           [-0.0365,  0.0167, -0.0084]],\n",
       " \n",
       "          [[ 0.0091,  0.0045,  0.0104],\n",
       "           [-0.0521,  0.0157,  0.0304],\n",
       "           [ 0.0022,  0.0143,  0.0343]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0069,  0.0143, -0.0087],\n",
       "           [ 0.0138, -0.0069,  0.0112],\n",
       "           [ 0.0033,  0.0025, -0.0218]],\n",
       " \n",
       "          [[-0.0360, -0.0052,  0.0245],\n",
       "           [-0.0192,  0.0101, -0.0171],\n",
       "           [-0.0058, -0.0022,  0.0172]],\n",
       " \n",
       "          [[ 0.0266,  0.0137,  0.0559],\n",
       "           [ 0.0122,  0.0056,  0.0475],\n",
       "           [-0.0153, -0.0389, -0.0188]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0091, -0.0099, -0.0154],\n",
       "           [ 0.0296,  0.0007, -0.0170],\n",
       "           [ 0.0137,  0.0028,  0.0279]],\n",
       " \n",
       "          [[ 0.0087, -0.0092, -0.0323],\n",
       "           [ 0.0019, -0.0390, -0.0278],\n",
       "           [ 0.0047, -0.0022,  0.0419]],\n",
       " \n",
       "          [[-0.0286,  0.0209, -0.0096],\n",
       "           [-0.0120,  0.0389,  0.0121],\n",
       "           [-0.0125, -0.0273, -0.0149]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0083, -0.0130,  0.0004],\n",
       "           [ 0.0153,  0.0254,  0.0089],\n",
       "           [-0.0257,  0.0168,  0.0114]],\n",
       " \n",
       "          [[-0.0323,  0.0037,  0.0155],\n",
       "           [ 0.0111, -0.0132,  0.0462],\n",
       "           [-0.0102,  0.0097,  0.0039]],\n",
       " \n",
       "          [[-0.0138,  0.0019,  0.0055],\n",
       "           [ 0.0060, -0.0268,  0.0386],\n",
       "           [ 0.0003,  0.0353,  0.0068]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0051,  0.0148,  0.0248],\n",
       "           [-0.0307, -0.0324, -0.0285],\n",
       "           [-0.0022,  0.0291,  0.0014]],\n",
       " \n",
       "          [[ 0.0145, -0.0158,  0.0030],\n",
       "           [ 0.0566,  0.0221,  0.0182],\n",
       "           [-0.0089,  0.0374,  0.0301]],\n",
       " \n",
       "          [[ 0.0285,  0.0224, -0.0078],\n",
       "           [ 0.0002, -0.0023, -0.0001],\n",
       "           [-0.0064,  0.0075, -0.0172]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0219, -0.0216, -0.0367],\n",
       "           [-0.0248,  0.0132,  0.0159],\n",
       "           [-0.0027, -0.0159, -0.0078]],\n",
       " \n",
       "          [[ 0.0314, -0.0265,  0.0074],\n",
       "           [-0.0070,  0.0005,  0.0250],\n",
       "           [-0.0033,  0.0200,  0.0222]],\n",
       " \n",
       "          [[-0.0114,  0.0258, -0.0094],\n",
       "           [-0.0144, -0.0047,  0.0275],\n",
       "           [ 0.0244,  0.0276, -0.0073]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0028,  0.0127,  0.0273],\n",
       "           [-0.0170, -0.0037, -0.0300],\n",
       "           [-0.0184, -0.0404, -0.0101]],\n",
       " \n",
       "          [[-0.0120,  0.0367,  0.0206],\n",
       "           [ 0.0084,  0.0067,  0.0285],\n",
       "           [-0.0008,  0.0065, -0.0052]],\n",
       " \n",
       "          [[ 0.0099,  0.0189, -0.0330],\n",
       "           [-0.0326, -0.0321,  0.0386],\n",
       "           [ 0.0458, -0.0021, -0.0078]]]], device='cuda:0', requires_grad=True),\n",
       " 'module.features.49.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.50.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.features.50.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.0.weight': Parameter containing:\n",
       " tensor([[-0.0036,  0.0103,  0.0114,  ...,  0.0012,  0.0053, -0.0139],\n",
       "         [ 0.0163,  0.0178,  0.0168,  ..., -0.0072, -0.0087, -0.0060],\n",
       "         [ 0.0034, -0.0132, -0.0035,  ...,  0.0014, -0.0033,  0.0134],\n",
       "         ...,\n",
       "         [ 0.0167,  0.0007, -0.0042,  ...,  0.0113, -0.0010, -0.0122],\n",
       "         [ 0.0020,  0.0094, -0.0107,  ..., -0.0023,  0.0062,  0.0070],\n",
       "         [ 0.0046,  0.0067,  0.0009,  ..., -0.0012,  0.0064, -0.0005]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.0.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.2.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.2.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.3.weight': Parameter containing:\n",
       " tensor([[ 0.0004,  0.0182, -0.0008,  ...,  0.0075,  0.0195,  0.0199],\n",
       "         [-0.0206, -0.0004, -0.0033,  ...,  0.0035, -0.0071,  0.0069],\n",
       "         [ 0.0084,  0.0026,  0.0043,  ..., -0.0075,  0.0015, -0.0206],\n",
       "         ...,\n",
       "         [-0.0062,  0.0099, -0.0041,  ..., -0.0038,  0.0029, -0.0075],\n",
       "         [ 0.0105,  0.0042, -0.0012,  ...,  0.0028,  0.0031,  0.0057],\n",
       "         [-0.0101, -0.0037, -0.0116,  ...,  0.0095,  0.0045, -0.0038]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.3.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.5.weight': Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.5.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.6.weight': Parameter containing:\n",
       " tensor([[ 0.0046, -0.0058,  0.0073,  ...,  0.0255,  0.0071,  0.0016],\n",
       "         [-0.0105,  0.0158, -0.0032,  ..., -0.0205, -0.0113,  0.0222],\n",
       "         [-0.0176, -0.0092, -0.0044,  ..., -0.0193,  0.0023, -0.0109],\n",
       "         ...,\n",
       "         [-0.0050,  0.0039, -0.0019,  ...,  0.0015,  0.0142, -0.0039],\n",
       "         [ 0.0002, -0.0058,  0.0093,  ..., -0.0102,  0.0147,  0.0068],\n",
       "         [-0.0038,  0.0031,  0.0042,  ...,  0.0095,  0.0123,  0.0056]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'module.classifier.6.bias': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
       "        requires_grad=True)}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Acc@1: 29.608 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.608386075949365"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input, target) in enumerate(train_loader):\n",
    "    target = target.cuda()\n",
    "    input_var = input.cuda()\n",
    "    target_var = target\n",
    "\n",
    "    # compute output\n",
    "    output = model(input_var)\n",
    "    loss = criterion(output, target_var)\n",
    "\n",
    "    # compute gradient and do SGD step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    output = output.float()\n",
    "    loss = loss.float()\n",
    "    # measure accuracy and record loss\n",
    "    prec1 = accuracy(output.data, target)[0]\n",
    "    losses.update(loss.item(), input.size(0))\n",
    "    top1.update(prec1.item(), input.size(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exp_3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66ee137d659de16edc0be2f6baf9f82a68fb03d8de339f7ab7e1a928f7f54d77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
