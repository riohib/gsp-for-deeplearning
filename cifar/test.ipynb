{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "import networks.load as load\n",
    "\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils_gsp.logger import Logger\n",
    "# from utils_gsp import sps_tools\n",
    "from gsp_model import GSP_Model\n",
    "import utils_gsp.gsp_general as gsp_gen\n",
    "import tools.ipynb_funcs as utilfuncs\n",
    "import tools.visualization as viz\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets.dataprep as dataprep\n",
    "import networks.torch_vgg as pt_vgg\n",
    "import networks.resnet as resnet\n",
    "\n",
    "from main import train, validate, accuracy, save_checkpoint, setup_experiment, gsp_sparse_training, AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    arch = 'vgg16'\n",
    "    dataset='cifar10'\n",
    "    workers = 4\n",
    "    epochs=160\n",
    "    start_epoch=0\n",
    "    batch_size = 128\n",
    "    lr = 0.1\n",
    "    momentum = 0.9\n",
    "    weight_decay=1e-4\n",
    "    print_freq = 50\n",
    "    resume = False\n",
    "    evaluate = False\n",
    "    pretrained = False\n",
    "    half = False\n",
    "    exp_name = 'gsp_test'\n",
    "\n",
    "    gpu=None\n",
    "    logdir = '/logdir'\n",
    "    gsp_training = True \n",
    "    gsp_sps = 0.8\n",
    "    scheduled_sps_run = True\n",
    "    proj_filters = False\n",
    "    proj_model = False\n",
    "    gsp_int = 150\n",
    "    gsp_start_ep = -1\n",
    "    finetune = False\n",
    "    finetune_sps = 0.9\n",
    "\n",
    "\n",
    "global args, best_acc1\n",
    "args = Args\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sparsity_schedule(epoch, start_sps< end_sps):\n",
    "\n",
    "np.linspace(0.4, 0.85, 10)\n",
    "\n",
    "\n",
    "# to find the exponential scaling coefficient\n",
    "x = 1 #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0.4\n",
    "final=0.9\n",
    "samples=100\n",
    "\n",
    "# def exp_sps(start=0.4, final=0.9, samples=100):\n",
    "\n",
    "translation = (1 - start)\n",
    "scale_coeff = np.log(final + translation)/x\n",
    "exp_sps_l = np.exp(x * scale_coeff) - translation\n",
    "    # return exp_sps_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff94239ab00>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0, 1, samples)\n",
    "translation = (1 - start)\n",
    "scale_coeff = np.log(final + translation)\n",
    "exp_sps_l = np.exp(x * scale_coeff) - translation\n",
    "\n",
    "plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "plt.plot(exp_sps_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.resume = './results/gspS0.9/gsp/model_best.pth.tar' # LOAD GSP MODEL\n",
    "\n",
    "# args.resume = './results/gspS0.80/fine_0.9/model_best.pth.tar'\n",
    "# args.finetune = True\n",
    "args.dataset='cifar100'\n",
    "# args.arch ='vgg19'\n",
    "args.arch ='resnet56'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " input logdir: ./results/gsp_test/logdir \n",
      "\n",
      "\n",
      " RETURNED FILE LOGGER! \n",
      "\n",
      "Preparing Cifar100 dataset!\n",
      "Files already downloaded and verified\n",
      "The sparsity of the model is: 0.24\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# Setup the experiment\n",
    "flogger = setup_experiment(args)\n",
    "args.logger.log_cmd_arguments(args)\n",
    "\n",
    "# model = torch.nn.DataParallel(resnet.__dict__[args.arch]())\n",
    "# model = VGG('D')\n",
    "# model = load.model(args.arch)\n",
    "if args.dataset == 'cifar10': num_classes = 10\n",
    "if args.dataset == 'cifar100': num_classes = 100\n",
    "if args.arch == 'vgg16':    model = pt_vgg.vgg16_bn(num_classes=num_classes)\n",
    "if args.arch == 'vgg19':    model = pt_vgg.vgg19_bn(num_classes=num_classes)\n",
    "\n",
    "if args.arch == 'resnet56':    model = resnet.resnet56(num_classes=num_classes)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "model_gsp = GSP_Model(model)\n",
    "\n",
    "if args.finetune:\n",
    "    flogger.info(15*\"*\" + \" Model will be finetuned!! \" + 15*\"*\")\n",
    "    model_gsp.prune_and_mask_model(sps=args.finetune_sps)\n",
    "    \n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        model_gsp.model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                .format(args.evaluate, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# ----------------------- Load DATA -----------------------\n",
    "train_loader, val_loader = dataprep.get_data_loaders(dataset=args.dataset, args=args)\n",
    "\n",
    "# ----------------------- Make a GSP Model -----------------------\n",
    "print(f\"The sparsity of the model is: {model_gsp.get_model_sps():.2f}\")\n",
    "args.writer = SummaryWriter(log_dir=f'results/{args.exp_name}/runs/{datetime.now().strftime(\"%m-%d_%H:%M\")}')\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "# ============================ Setup GSP model ============================\n",
    "if args.gsp_training:\n",
    "    gsp_sparse_training(model_gsp, train_loader, args)\n",
    "    flogger.info(15*\"*\" + \" Model will be trained with GSP Sparsity!! \" + 15*\"*\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, 4),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "]), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomCrop(size=(32, 32), padding=4)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# for name, layer in model.named_modules():\n",
    "#     if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "#         counter += 1\n",
    "#         print(f\"{[counter]} Name: {name} | shape: {layer.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = load.model('vgg19', num_classes=100)\n",
    "# import networks.torch_vgg as pt_vgg\n",
    "# model = pt_vgg.vgg19_bn(num_classes=100)\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(nn.Linear(512, 100)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "input, target = next(iter(train_loader))\n",
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.cuda()\n",
    "input_var = input.cuda()\n",
    "target_var = target\n",
    "\n",
    "# compute output\n",
    "output = model_gsp.model(input_var)\n",
    "loss = criterion(output, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, weight_l, shape_l, weight_d, layers_d = utilfuncs.get_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prune(self, sps=0.95):\n",
    "    for name, layer in model_gsp.model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            num = layer.weight.data.numel()\n",
    "            num_zero = int(round(num*sps))\n",
    "            indices = torch.randperm(num)[:num_zero]\n",
    "            layer.weight.data.flatten()[[indices]] = 0.\n",
    "            # print(layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.print_model_sps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor = weight_d[names[0]]\n",
    "\n",
    "n = mytensor.numel()\n",
    "m = int(round(n*0.6))\n",
    "indices = torch.randperm(n)[:m]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor.flatten()[[indices]] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.scheduled_sps_run = True\n",
    "model_gsp.total_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epoch = 10\n",
    "train(train_loader, model_gsp, criterion, optimizer, 0, args, gsp_mode=True)\n",
    "# validate(val_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gsp.get_model_sps()\n",
    "model_gsp.print_model_sps()\n",
    "model_gsp.proj_filters=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_gsp.prune_and_mask_model(sps=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global GSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_all_layers(self, sps):\n",
    "    layer_d = dict()\n",
    "    shape_d = dict()\n",
    "    ctr = 0\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            shape_d[name] = layer.weight.shape\n",
    "            layer_d[ctr] = layer.weight.data.detach().clone().flatten()\n",
    "            ctr+=1\n",
    "\n",
    "    xp_mat, ni_list = gsp_gen.GSP(layer_d, sps=sps)\n",
    "    out_layers = gsp_gen.unpad_output_mat(xp_mat, ni_list)\n",
    "\n",
    "    # rebuild_network\n",
    "    ctr = 0\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.weight.data = out_layers[ctr].reshape(shape_d[name])\n",
    "            ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_all_layers(model_gsp, sps=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_sparsity(matrix, ni_list):\n",
    "    \"\"\"\n",
    "    This Hoyer Sparsity Calculation is for matrices with the end of the columns that are padded. Hence,\n",
    "    it needs the information of how much of each columns are elements and how much of them are padded.\n",
    "    ni_list: Contains the number of values in each column (rest are padded with zero).\n",
    "    \"\"\"\n",
    "\n",
    "    ni = matrix.shape[0]\n",
    "    device = matrix.device\n",
    "    ni_tensor = torch.tensor(ni_list).to(device)\n",
    "\n",
    "    # Get Indices of all zero vector columns.\n",
    "    zero_col_ind = (abs(matrix.sum(0) - 0) < 2.22e-16).nonzero().view(-1)  \n",
    "    spx_c = (torch.sqrt(ni_tensor) - torch.norm(matrix,1, dim=0) / torch.norm(matrix,2, dim=0)) / (torch.sqrt(ni_tensor) - 1)\n",
    "    if len(zero_col_ind) != 0:\n",
    "        spx_c[zero_col_ind] = 1  # Sparsity = 1 if column already zero vector.\n",
    "    \n",
    "    if matrix.dim() > 1:   \n",
    "        sps_avg = spx_c.mean()\n",
    "    elif matrix.dim() == 1:  # If not a matrix but a column vector!\n",
    "        sps_avg =  spx_c    \n",
    "    return sps_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, weight_l, shape_l, weight_d, layers_d = utilfuncs.get_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_d[names[0]].weight.data.detach().device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz.plot_weight_dist(model, title='Resnet20 Distribution', arch='resnet20', \n",
    "#                     filename='./results/gspS0.80/fine_0.9/w_dist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gsp_prune(model_gsp, sps=0.8):\n",
    "    model_gsp.force_apply_gsp(sps)\n",
    "    print(f\"SPS after gsp application: {model_gsp.get_model_sps():.2f}\")\n",
    "    \n",
    "    model_gsp.prune_and_mask_model(sps)\n",
    "    print(f\"SPS after pruning: {model_gsp.get_model_sps():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_gsp_prune(model_gsp, sps=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomg Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.ones((3,3,2,2))\n",
    "# a[0,1,:,:] = 2\n",
    "# a[0,2,:,:] = 3\n",
    "\n",
    "# a[1,0,:,:] = 4\n",
    "# a[1,1,:,:] = 5\n",
    "# a[1,2,:,:] = 6\n",
    "\n",
    "# a[2,0,:,:] = 7\n",
    "# a[2,1,:,:] = 8\n",
    "# a[2,2,:,:] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.dataprep as dp \n",
    "\n",
    "train_loader, val_loader = dp.get_data_loaders(dataset='cifar100', args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('explore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b48ef9cd6c3a227564a862e6e288e1f6d7b13430b2b60ea5e9df9856239395d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
